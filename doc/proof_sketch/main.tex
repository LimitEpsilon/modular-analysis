%! TEX program = xelatex
\documentclass{article}
\usepackage{geometry}
\geometry{
  a4paper,
  total={170mm,257mm},
  left=20mm,
  top=20mm,
}
\usepackage{setspace}
\usepackage{graphicx}
\usepackage{xcolor}
\usepackage{kotex}
\usepackage{csquotes}

%%% Typesetting for listings
\usepackage{listings}

\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{ltblue}{rgb}{0,0.4,0.4}
\definecolor{dkviolet}{rgb}{0.3,0,0.5}

%%% lstlisting coq style (inspired from a file of Assia Mahboubi)
\lstdefinelanguage{Coq}{ 
    % Anything betweeen $ becomes LaTeX math mode
    mathescape=true,
    % Comments may or not include Latex commands
    texcl=false, 
    % Vernacular commands
    morekeywords=[1]{Section, Module, End, Require, Import, Export,
        Variable, Variables, Parameter, Parameters, Axiom, Hypothesis,
        Hypotheses, Notation, Local, Tactic, Reserved, Scope, Open, Close,
        Bind, Delimit, Definition, Let, Ltac, Fixpoint, CoFixpoint, Add,
        Morphism, Relation, Implicit, Arguments, Unset, Contextual,
        Strict, Prenex, Implicits, Inductive, CoInductive, Record,
        Structure, Canonical, Coercion, Context, Class, Global, Instance,
        Program, Infix, Theorem, Lemma, Corollary, Proposition, Fact,
        Remark, Example, Proof, Goal, Save, Qed, Defined, Hint, Resolve,
        Rewrite, View, Search, Show, Print, Printing, All, Eval, Check,
        Projections, inside, outside, Def},
    % Gallina
    morekeywords=[2]{forall, exists, exists2, fun, fix, cofix, struct,
        match, with, end, as, in, return, let, if, is, then, else, for, of,
        nosimpl, when},
    % Sorts
    morekeywords=[3]{Type, Prop, Set, true, false, option},
    % Various tactics, some are std Coq subsumed by ssr, for the manual purpose
    morekeywords=[4]{pose, set, move, case, elim, apply, clear, hnf,
        intro, intros, generalize, rename, pattern, after, destruct,
        induction, using, refine, inversion, injection, rewrite, congr,
        unlock, compute, ring, field, fourier, replace, fold, unfold,
        change, cutrewrite, simpl, have, suff, wlog, suffices, without,
        loss, nat_norm, assert, cut, trivial, revert, bool_congr, nat_congr,
        symmetry, transitivity, auto, split, left, right, autorewrite},
    % Terminators
    morekeywords=[5]{by, done, exact, reflexivity, tauto, romega, omega,
        assumption, solve, contradiction, discriminate},
    % Control
    morekeywords=[6]{do, last, first, try, idtac, repeat},
    % Comments delimiters, we do turn this off for the manual
    morecomment=[s]{(*}{*)},
    % Spaces are not displayed as a special character
    showstringspaces=false,
    % String delimiters
    morestring=[b]",
    morestring=[d],
    % Size of tabulations
    tabsize=3,
    % Enables ASCII chars 128 to 255
    extendedchars=false,
    % Case sensitivity
    sensitive=true,
    % Automatic breaking of long lines
    breaklines=false,
    % Default style fors listings
    basicstyle=\small,
    % Position of captions is bottom
    captionpos=b,
    % flexible columns
    columns=[l]flexible,
    % Style for (listings') identifiers
    identifierstyle={\ttfamily\color{black}},
    % Style for declaration keywords
    keywordstyle=[1]{\ttfamily\color{dkviolet}},
    % Style for gallina keywords
    keywordstyle=[2]{\ttfamily\color{dkgreen}},
    % Style for sorts keywords
    keywordstyle=[3]{\ttfamily\color{ltblue}},
    % Style for tactics keywords
    keywordstyle=[4]{\ttfamily\color{dkblue}},
    % Style for terminators keywords
    keywordstyle=[5]{\ttfamily\color{dkred}},
    %Style for iterators
    %keywordstyle=[6]{\ttfamily\color{dkpink}},
    % Style for strings
    stringstyle=\ttfamily,
    % Style for comments
    commentstyle={\ttfamily\color{dkgreen}},
    %moredelim=**[is][\ttfamily\color{red}]{/&}{&/},
    literate=
    {\\forall}{{\color{dkgreen}{$\forall\;$}}}1
    {\\exists}{{$\exists\;$}}1
    {\le -}{{$\leftarrow\;$}}1
    {=>}{{$\Rightarrow\;$}}1
    {==}{{\code{==}\;}}1
    {==>}{{\code{==>}\;}}1
    %    {:>}{{\code{:>}\;}}1
    {->}{{$\rightarrow\;$}}1
    {\le ->}{{$\leftrightarrow\;$}}1
    {\le ==}{{$\leq\;$}}1
    {\#}{{$^\star$}}1 
    {\\o}{{$\circ\;$}}1 
    {\@}{{$\cdot$}}1 
    {\/\\}{{$\wedge\;$}}1
    {\\\/}{{$\vee\;$}}1
    {++}{{\code{++}}}1
    {~}{{\ }}1
    {\@\@}{{$@$}}1
    {\\mapsto}{{$\mapsto\;$}}1
    {\\hline}{{\rule{\linewidth}{0.5pt}}}1
    %
}[keywords,comments,strings]

%%% Math settings
\usepackage{amssymb,amsmath,amsthm,mathtools}
\usepackage[math-style=TeX,bold-style=TeX]{unicode-math}
\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]
\newtheorem{example}{Example}[section]
\newtheorem{lem}{Lemma}[section]
\newtheorem{thm}{Theorem}[section]
\newtheorem{cor}{Corollary}[section]
\newtheorem{clm}{Claim}[section]

%%% Font settings
\setmainfont{Libertinus Serif}
\setsansfont{Libertinus Sans}[Scale=MatchUppercase]
\setmonofont{JuliaMono}[Scale=MatchLowercase]
\setmathfont{Libertinus Math} % Before set*hangulfont
\setmathfont{TeX Gyre Pagella Math}[range={\lbrace,\rbrace},Scale=1.1]
\setmainhangulfont{Noto Serif CJK KR}
\setmonohangulfont{D2Coding}

%%% PL constructs
\usepackage{galois}
\usepackage{ebproof}
\ebproofset{left label template=\textsc{[\inserttext]}}
\ebproofset{center=false}

%%% Custom commands
\newcommand*{\vbar}{|}
\newcommand*{\finto}{\xrightarrow{\text{\textrm{fin}}}}
\newcommand*{\istype}{\mathrel{â©´}}
\newcommand*{\ortype}{\mathrel{|}}
\newcommand*{\cons}{::}
\newcommand*{\pset}{\mathscr{P}}

\def\ovbarw{1.2mu}
\def\ovbarh{1}
\newcommand*{\ovbar}[1]{\mkern \ovbarw\overline{\mkern-\ovbarw{\smash{#1}\scalebox{1}[\ovbarh]{\vphantom{i}}}\mkern-\ovbarw}\mkern \ovbarw}
\newcommand*{\A}[1]{\ovbar{#1}}
\newcommand*{\Abs}[1]{{#1}^{\#}}
\newcommand*{\Expr}{\text{Expr}}
\newcommand*{\ExprVar}{\text{Var}}
\newcommand*{\Module}{\text{Module}}
\newcommand*{\ModVar}{\text{ModVar}}
\newcommand*{\Time}{\mathbb{T}}
\newcommand*{\ATime}{\A{\Time}}
\newcommand*{\Ctx}{\text{Ctx}}
\newcommand*{\Value}{\text{Val}}
\newcommand*{\Mem}{\text{Mem}}
\newcommand*{\Left}{\text{Left}}
\newcommand*{\Right}{\text{Right}}
\newcommand*{\Sig}{\text{Sig}}
\newcommand*{\mem}{m}
\newcommand*{\AMem}{\A{\text{Mem}}}
\newcommand*{\State}{\text{State}}
\newcommand*{\AState}{\A{\text{State}}}
\newcommand*{\Result}{\text{Result}}
\newcommand*{\AResult}{\A{\text{Result}}}
\newcommand*{\Tick}{\text{Tick}}
\newcommand*{\lfp}{\mathsf{lfp}}
\newcommand*{\Step}{\mathsf{Step}}
\newcommand*{\semarrow}{\rightsquigarrow}
\newcommand*{\asemarrow}{\A{\rightsquigarrow}}
\newcommand*{\synlink}{\rtimes}
\newcommand*{\semlink}{\mathbin{\rotatebox[origin=c]{180}{$\propto$}}}
\newcommand*{\link}[2]{{#1}\rtimes{#2}}
\newcommand*{\mt}{\mathsf{empty}}
\newcommand*{\valid}{\mathsf{valid}}
\newcommand*{\Path}{\text{Path}}

\newcommand*{\doubleplus}{\ensuremath{\mathbin{+\mkern-3mu+}}}
\newcommand*{\project}{\text{\texttt{:>} }}
\newcommand*{\Exp}{\mathsf{Exp}}
\newcommand*{\Imp}{\mathsf{Imp}}
\newcommand*{\Fin}{\mathsf{Fin}}
\newcommand*{\Link}{\mathsf{Link}}
\newcommand*{\sembracket}[1]{\lBrack{#1}\rBrack}
\newcommand*{\fin}[2]{{#1}\xrightarrow{\text{fin}}{#2}}
\newcommand*{\addr}{\mathsf{addr}}
\newcommand*{\tick}{\mathsf{tick}}
\newcommand*{\modctx}{\mathsf{ctx}}
\newcommand*{\mapinject}[2]{{#2}[{#1}]}
\newcommand*{\inject}[2]{{#2}\langle{#1}\rangle}
\newcommand*{\deletepre}[2]{{#2}\overline{\doubleplus}{#1}}
\newcommand*{\deletemap}[2]{{#1}\overline{[{#2}]}}
\newcommand*{\delete}[2]{{#2}{\langle{#1}\rangle}^{-1}}
\newcommand*{\filter}{\mathsf{filter}}
\newcommand*{\Let}{\mathtt{let}}

\title{(Sketches of) Proofs for Modular Analysis}
\author{Joonhyup Lee}
\begin{document}
\maketitle

\section{Part I: Semantics that Allow Open Code to be Closed Fractionally}

We make the following observations:
\begin{itemize}
  \item Most code that static analyzers deal with is \emph{open code} that uses external values.
  \item Those external values are defined in a different \emph{scope} from the code of interest.
  \item The different scopes are organized in term of \emph{modules}.
  \item The modules are usually bound to \emph{module names}.
\end{itemize}
Therefore, experts who write realistic analyzers are immediately faced with the problem of \emph{closing} open code.
Especially, in the case when external values are not defined in the same language, the semantics of such values must be \emph{modelled}, either by the analysis expert or by the user of the analyzer.
Since we cannot possibly model all such cases in one try, attempts to close open code must be a never-ending race of fractional advances.

If we force the analyzers to output results only in the fortunate case that all external values has already been modelled, we end up unnecessarily recomputing each time we fail to close completely.
We claim that this is undesirable: the analyzer, upon meeting an open term, may just ``cache'' what has been computed already and ``pick up'' from there when that open term is resolved.
No doubt, there may already be program analyzers that perform such caching, but how can we model such a computation \emph{mathematically}?
Therefore, we aim to define semantics for terms that have been fractionally closed, and prove that closing the \emph{fractionally closed semantics} is equal to the \emph{closed semantics}.

To illustrate what will be proven, say that $e$ is an open term, $S_2$ is the set of contexts that close $e$ fractionally, and $S_1$ is another set of contexts that aim to fill in the blanks.
What we aim to show is:
\[\sembracket{e}(S_1\rhd S_2)=S_1\semlink\sembracket{e}S_2\]
when $S_1\semlink\sembracket{e}S_2$ closes the fractionally closed $\sembracket{e}S_2$ and $\sembracket{e}(S_1\rhd S_2)$ starts from the filled-in states.

In this section, we will define:
\begin{enumerate}
  \item The \emph{abstract syntax} of a model language with modules that can be bound to names.
  \item The \emph{semantics} of the language that is defined regardless of openness.
\end{enumerate}
and sketch how to design an analysis that allows fractional specification.
\subsection{Abstract Syntax}
The language is basically an extension of untyped lambda calculus with modules and the linking construct.
$\link{e_1}{e_2}$ means that $e_1$ is a module that is evaluated first to a \emph{context}, and that $e_2$ is evaluated under the exported context.

\begin{figure}[htb]
  \centering
  \begin{tabular}{rrcll}
    Identifiers & $x,M$ & $\in$         & $\ExprVar$                              \\
    Expression  & $e$   & $\rightarrow$ & $x$                & value identifier   \\
                &       & $\vbar$       & $\lambda x.e$      & function           \\
                &       & $\vbar$       & $e$ $e$            & application        \\
                &       & $\vbar$       & $\link{e}{e}$      & linked expression  \\
                &       & $\vbar$       & $\varepsilon$      & empty module       \\
                &       & $\vbar$       & $M$                & module identifier  \\
                &       & $\vbar$       & $\Let$ $x$ $e$ $e$ & binding expression \\
                &       & $\vbar$       & $\Let$ $M$ $e$ $e$ & binding module     \\
  \end{tabular}
  \caption{Abstract syntax of the simple module language.}
  \label{fig:syntax}
\end{figure}
\subsection{Operational Semantics}
\begin{figure}[h!]
  \centering
  \begin{tabular}{rrcll}
    Environment/Context          & $C$ & $\in$         & $\Ctx$                                                      \\
    Value of expressions         & $v$ & $\in$         & $\Value \subseteq \Expr\times\Ctx$                          \\
    Value of expressions/modules & $V$ & $\in$         & $\Value\Ctx\triangleq\Value\uplus\Ctx$                      \\
    Context                      & $C$ & $\rightarrow$ & []                                     & empty stack        \\
                                 &     & $\vbar$       & $(x,v)\cons C$                         & expression binding \\
                                 &     & $\vbar$       & $(M,C)\cons C$                         & module binding     \\
    Value of expressions         & $v$ & $\rightarrow$ & $\langle \lambda x.e, C \rangle$       & closure
  \end{tabular}
  \caption{Definition of the semantic domains.}
  \label{fig:simpdom}
\end{figure}

\begin{figure}[h!]
  \begin{flushright}
    \fbox{$(e,C)\semarrow V\text{ or }(e',C')$}
  \end{flushright}
  \centering
  \vspace{0pt} % -0.75em}
  \[
    \begin{prooftree}
      \hypo{v=C(x)}
      \infer[left label=ExprID]1{
      (x, C)
      \semarrow
      v
      }
    \end{prooftree}\qquad
    \begin{prooftree}
      \infer[left label=Fn]0{
      (\lambda x.e, C)
      \semarrow
      \langle\lambda x.e, C\rangle
      }
    \end{prooftree}\qquad
    \begin{prooftree}
      \infer[left label={AppL}]0{
      (e_{1}\:e_{2}, C)
      \semarrow
      (e_{1},C)
      }
    \end{prooftree}\qquad
    \begin{prooftree}
      \hypo{
        \begin{matrix}
          (e_{1}, C)
          \semarrow
          \langle\lambda x.e_{\lambda}, C_{\lambda}\rangle
        \end{matrix}
      }
      \infer[left label={AppR}]1{
      (e_{1}\:e_{2}, C)
      \semarrow
      (e_{2}, C)
      }
    \end{prooftree}
  \]

  \[
    \begin{prooftree}
      \hypo{
        \begin{matrix}
          (e_{1}, C)
          \semarrow
          \langle\lambda x.e_{\lambda}, C_{\lambda}\rangle \\
          (e_{2}, C)
          \semarrow
          v
        \end{matrix}
      }
      \infer[left label={AppBody}]1{
      (e_{1}\:e_{2}, C)
      \semarrow
      (e_{\lambda}, (x, v)\cons C_{\lambda})
      }
    \end{prooftree}\qquad
    \begin{prooftree}
      \hypo{
        \begin{matrix}
          (e_{1}, C)
          \semarrow
          \langle\lambda x.e_{\lambda}, C_{\lambda}\rangle \\
          (e_{2}, C)
          \semarrow
          v                                                \\
          (e_{\lambda}, (x, v)\cons C_{\lambda})
          \semarrow
          v'
        \end{matrix}
      }
      \infer[left label={App}]1{
      (e_{1}\:e_{2}, C)
      \semarrow
      v'
      }
    \end{prooftree}
  \]

  \[
    \begin{prooftree}
      \infer[left label=LinkL]0{
      (\link{e_{1}}{e_{2}}, C)
      \semarrow
      (e_{1}, C)
      }
    \end{prooftree}\qquad
    \begin{prooftree}
      \hypo{
        \begin{matrix}
          (e_{1}, C)
          \semarrow
          C'
        \end{matrix}
      }
      \infer[left label=LinkR]1{
      (\link{e_{1}}{e_{2}}, C)
      \semarrow
      (e_{2}, C')
      }
    \end{prooftree}\qquad
    \begin{prooftree}
      \hypo{
        \begin{matrix}
          (e_{1}, C)
          \semarrow
          C' \\
          (e_{2}, C')
          \semarrow
          V
        \end{matrix}
      }
      \infer[left label=Link]1{
      (\link{e_{1}}{e_{2}}, C)
      \semarrow
      V
      }
    \end{prooftree}
  \]

  \[
    \begin{prooftree}
      \infer[left label=Empty]0{
      (\varepsilon, C)
      \semarrow
      C
      }
    \end{prooftree}\qquad
    \begin{prooftree}
      \hypo{C'=C(M)}
      \infer[left label=ModID]1{
      (M, C)
      \semarrow
      C'
      }
    \end{prooftree}
  \]

  \[
    \begin{prooftree}
      \infer[left label=LetEL]0{
      (\mathtt{let}\:x\:e_1\:e_2, C)
      \semarrow
      (e_{1}, C)
      }
    \end{prooftree}\quad
    \begin{prooftree}
      \hypo{
        \begin{matrix}
          (e_{1}, C)
          \semarrow
          v
        \end{matrix}
      }
      \infer[left label=LetER]1{
      (\mathtt{let}\:x\:e_1\:e_2, C)
      \semarrow
      (e_{2}, (x, v)\cons C)
      }
    \end{prooftree}\quad
    \begin{prooftree}
      \hypo{
        \begin{matrix}
          (e_{1}, C)
          \semarrow
          v \\
          (e_{2}, (x, v)\cons C)
          \semarrow
          C'
        \end{matrix}
      }
      \infer[left label=LetE]1{
      (\mathtt{let}\:x\:e_1\:e_2, C)
      \semarrow
      C'
      }
    \end{prooftree}
  \]

  \[
    \begin{prooftree}
      \infer[left label=LetML]0{
      (\mathtt{let}\:M\:e_{1}\:e_{2}, C)
      \semarrow
      (e_{1}, C)
      }
    \end{prooftree}\quad
    \begin{prooftree}
      \hypo{
        \begin{matrix}
          (e_{1}, C)
          \semarrow
          C'
        \end{matrix}
      }
      \infer[left label=LetMR]1{
      (\mathtt{let}\:M\:e_{1}\:e_{2}, C)
      \semarrow
      (e_{2}, (M, C')\cons C)
      }
    \end{prooftree}\quad
    \begin{prooftree}
      \hypo{
        \begin{matrix}
          (e_{1}, C)
          \semarrow
          C' \\
          (e_{2}, (M, C')\cons C)
          \semarrow
          C''
        \end{matrix}
      }
      \infer[left label=LetM]1{
      (\mathtt{let}\:M\:e_{1}\:e_{2}, C)
      \semarrow
      C''
      }
    \end{prooftree}
  \]
  \caption{The concrete one-step transition relation.}
  \label{fig:simpreach}
\end{figure}
We present the operational semantics $\semarrow$ for our language.
The semantic domains are given in Figure \ref{fig:simpdom} and the operational semantics is defined in Figure \ref{fig:simpreach}.

Our semantics relate an element $\ell$ of $\Left\triangleq\Expr\times\Ctx$ with an element $\rho$ of $\Right\triangleq\Left\uplus\Value\Ctx$.
Note that $C(x)$ pops the highest value that is associated with $x$ from the stack $C$ and $C(M)$ pops the highest context associated with $M$ from $C$.
The relation $\semarrow$ is unorthodox in that unlike normal big-step operaional semantics, the relation $\semarrow$ relates a configuration not only to its final result but also to intermediate configurations of which its values are required to compute the final result.
Why it is defined as such is because defining a \emph{collecting semantics} becomes much simpler.

\subsection{Collecting Semantics}
To define a semantics that is computable, we must formulate the collecting semantics as a least fixed point of a monotonic function that maps an element of some CPO $D$ to $D$.
In our case, $D\triangleq\pset(\Sigma)$ when $\Sigma\triangleq\semarrow\uplus\Right$ and $\pset(S)$ is the powerset of $S$.
The semantics of an expression $e$ starting from initial states in $S\subseteq\Ctx$ is the collection of $\ell\semarrow\rho$ and $\rho$ derivable from initial configurations $(e,C)$ with $C\in S$.
Defining the transfer function is straightforward from the definition of the transition relation.

\begin{definition}[Transfer function]
  Given $A\in D$, define
  \[
    \mathsf{Step}(A)\triangleq
    \left\{\ell\semarrow\rho, \rho\middle|
    \begin{prooftree}[center=true]
      \hypo{A'}\infer1{\ell\semarrow\rho}
    \end{prooftree}\wedge
    A'\subseteq A\wedge\ell\in A
    \right\}
  \]
\end{definition}

The $\mathsf{Step}$ function is naturally monotonic, as a ``cache'' $A$ that remembers more about the intermediate proof tree will derive more results than a cache that remembers less.
Now, because of Tarski's fixpoint theorem, we can formulate the collecting semantics in fixpoint form.
\begin{definition}[Collecting semantics]
  Given $e\in\Expr$ and $S\subseteq\Ctx$, define:
  \[
    \sembracket{e}S\triangleq\lfp(\lambda X.\mathsf{Step}(X)\cup\{(e,C)|C\in S\})
  \]
\end{definition}
Note that the above definition can be defined without qualms for situations when the $C$ in $(e,C)$ does not close $e$.
Then the collecting semantics will store the proof tree only up to the point the first free variable is evaluated.

\subsection{Injection and Linking}
We first define what it means to \emph{fill in the blanks} of an individual $V_2\in\Value\Ctx$ with a $C_1\in\Ctx$:
\[
  \inject{C_{1}}{V_{2}}\triangleq
  \begin{cases}
    C_1                                           & V_{2}=[]                        \\
    (x, \inject{C_1}{v})\cons\inject{C_{1}}{C}    & V_{2}=(x,v)\cons C              \\
    (M, \inject{C_{1}}{C})\cons\inject{C_{1}}{C'} & V_{2}=(M,C)\cons C'             \\
    \langle\lambda x.e,\inject{C_1}{C}\rangle     & V_2=\langle\lambda x.e,C\rangle
  \end{cases}
\]
This does indeed ``fill in the blanks'', since:
\begin{clm}[Fill in the Blanks]
  For all $C_1,C_2\in\Ctx$, for each expression variable $x$,
  \[
    C_2(x)=v\Rightarrow\inject{C_1}{C_2}(x)=\inject{C_1}{v}\text{ and }C_2(x)=\bot\Rightarrow\inject{C_1}{C_2}(x)=C_1(x)
  \]
  and for each module variable $M$,
  \[
    C_2(M)=C\Rightarrow\inject{C_1}{C_2}(x)=\inject{C_1}{C}\text{ and }C_2(M)=\bot\Rightarrow\inject{C_1}{C_2}(M)=C_1(M)
  \]
\end{clm}
\begin{proof}[Sketch]
  Induction on $C_2$.
\end{proof}

Moreover, filling in the blanks preserves the evaluation relation $\semarrow$.
When we define $\inject{C_1}{\ell}$ for $C_1\in\Ctx,\ell=(e,C_2)\in\Left$ as $(e,\inject{C_1}{C_2})$, we have:
\begin{clm}[Injection Preserves Evaluation]
  For all $\ell\in\Left$, $\rho\in\Right$, $\ell\semarrow\rho\Rightarrow\inject{C}{\ell}\semarrow\inject{C}{\rho}$. More explicity,
  \[(\ell,\rho)\in\Sigma\Rightarrow(\inject{C}{\ell},\inject{C}{\rho})\in\Sigma\]
\end{clm}
\begin{proof}[Sketch]
  Induction on $\semarrow$.
\end{proof}

Thus, we can define $\rhd$ that injects a \emph{set} of contexts $S$ into a subset $A$ of $D$ and a semantic linking operation $\semlink$ that does the rest of the computation:
\begin{definition}[Injection]
  For $S\subseteq\Ctx$ and $A\in D$, define:
  \[S\rhd A\triangleq\{\inject{C}{\rho}|C\in S\wedge\rho\in A\}\cup\{\inject{C}{\ell}\semarrow\inject{C}{\rho}|C\in S\wedge\ell\semarrow\rho\in A\}\]
\end{definition}
\begin{definition}[Semantic Linking]
  For $S\subseteq\Ctx$ and $A\in D$, define:
  \[S\semlink A\triangleq\lfp(\lambda X.\Step(X)\cup(S\rhd A))\]
\end{definition}

Thus we reach the main theorem that allows ``fractional closures'' to be soundly defined:
\begin{clm}[Advance]
  For all $e\in\Expr$ and $S_1,S_2\subseteq\Ctx$,
  \[\sembracket{e}(S_1\rhd S_2)=S_1\semlink\sembracket{e}S_2\]
\end{clm}
\begin{proof}
  Let $A$ be $\{(e,C)|C\in S_1\rhd S_2\}$, and let $B$ be $S_1\rhd\sembracket{e}S_2$.
  Note that $A\subseteq B$ by the definition of $\sembracket{e}S_2$.

  Also, let $X_A$ be $\lfp(\lambda X.\Step(X)\cup A)=\sembracket{e}(S_1\rhd S_2)$ and let $X_B$ be $\lfp(\lambda X.\Step(X)\cup B)=S_1\semlink\sembracket{e}S_2$.
  By the previous lemma, we have that $B\subseteq X_A$.

  Then first, $X_A$ is a fixed point of $\lambda X.\Step(X)\cup B$, since
  \[X_A=X_A\cup B=(\Step(X_A)\cup A)\cup B=\Step(X_A)\cup(A\cup B)=\Step(X_A)\cup B\]
  . Then since $X_B$ is the least fixed point, $X_B\subseteq X_A$.

  Also, note that $X_B$ is a pre-fixed point of $\lambda X.\Step(X)\cup A$, since
  \[\Step(X_B)\cup A\subseteq\Step(X_B)\cup B=X_B\]
  . $D$ is a complete lattice, so by Tarski's fixpoint theorem, $X_A$ is the least of all pre-fixed points.
  Thus, $X_A\subseteq X_B$.

  Since $X_B\subseteq X_A$ and $X_A\subseteq X_B$, we have that $X_A=X_B$.
\end{proof}

\subsection{Skeleton of a Static Analysis}
Since we have defined a semantics that fully embrace \emph{incomplete computations}, we only have to abstract our semantic operators to obtain a sound static analysis.

We require a CPO $\Abs{D}$ that is Galois connected with $D$ by abstraction $\alpha$ and concretization $\gamma$:
\[\pset(\Sigma)=D\galois{\alpha}{\gamma}\Abs{D}\]
and semantic operators $\Abs\Step$ and $\Abs\rhd$ that satisfies:
\[\Step\circ\gamma\subseteq\gamma\circ\Abs\Step\qquad\rhd\circ(\gamma,\gamma)\subseteq\gamma\circ\Abs\rhd\]
. Then we define $\Abs{\sembracket{e}}$ and $\Abs\semlink$ as:
\[
  \Abs{\sembracket{e}}\Abs{S}\triangleq\lfp(\lambda\Abs{X}.\Abs\Step(\Abs{X})\Abs\cup\alpha\{(e,C)|C\in\gamma\Abs{S}\})\qquad
  \Abs{S}\Abs\semlink\Abs{A}\triangleq\lfp(\lambda\Abs{X}.\Abs\Step(\Abs{X})\Abs\cup(\Abs{S}\Abs\rhd\Abs{A}))
\]
which, by definition and Tarski's fixpoint theorem satisfies:
\[\sembracket{e}\circ\gamma\subseteq\gamma\circ\Abs{\sembracket{e}}\qquad\semlink\circ(\gamma,\gamma)\subseteq\gamma\circ\Abs\semlink\]
. Then we can soundly approximate fractional specifications by:
\begin{align*}
  S_1\semlink\sembracket{e}S_2 & \subseteq S_1\semlink\gamma(\Abs{\sembracket{e}}\alpha(S_2))                 & (\because\sembracket{e}\subseteq\gamma\circ\Abs{\sembracket{e}}\circ\alpha\text{ and monotonicity of }\semlink) \\
                               & \subseteq \gamma(\alpha(S_1))\semlink\gamma(\Abs{\sembracket{e}}\alpha(S_2)) & (\because\text{id}\subseteq\gamma\circ\alpha\text{ and monotonicity of }\semlink)                               \\
                               & \subseteq\gamma(\alpha(S_1)\Abs\semlink\Abs{\sembracket{e}}\alpha(S_2))      & (\because\semlink\circ(\gamma,\gamma)\subseteq\gamma\circ\Abs\semlink)
\end{align*}

\section{Part II: A Simple Method to Derive Sound Analyzers}

All that is left is to present an abstraction for the semantics in the previous section.
Since the ``depth'' of the context $C$ is unbound due to entries $(x,v)$ also containing $C$ in the environment part of $v$, we need to abstract $S\subseteq\Ctx$ to finitely compute an overapproximation.
However, devising such an abstraction is not immediately obvious, since such abstractions must support operations satisfying $\{C(x)|C\in\gamma(\Abs{C})\}\subseteq\gamma(\Abs{C}(x))$, when the operation $\Abs{C}(x)$ reads abstract closures bound to $x$ from the abstract context, which then again must contain abstract closures.

To break this recursive structure, we employ the common technique of introducing addresses and a memory.
Thus, we extend the operational semantics of the previous section to a sematics that involve choosing a \emph{time} domain $\Time$ to use as addresses,
and an \emph{abstract time domain} $\A\Time$ that allow easy abstraction of the semantics via a \emph{single} function $\A\alpha:\Time\rightarrow\A\Time$.

\subsection{Semantic Domains}
\begin{figure}[h!]
  \centering
  \begin{tabular}{rrcll}
    Time                         & $t$    & $\in$         & $\Time$                                                                  \\
    Environment/Context          & $C$    & $\in$         & $\Ctx$                                                                   \\
    Value of expressions         & $v$    & $\in$         & $\Value \subseteq \Expr\times\Ctx$                                       \\
    Value of expressions/modules & $V$    & $\in$         & $\Value\Ctx\triangleq\Value\uplus\Ctx$                                   \\
    Memory                       & $\mem$ & $\in$         & $\Mem \triangleq \fin{\Time}{\Value}$                                    \\
    State                        & $s$    & $\in$         & $\State \subseteq \Ctx\times\Mem\times\Time$                             \\
    Result                       & $r$    & $\in$         & $\Result \subseteq \Value\Ctx\times\Mem\times\Time$                      \\
    Context                      & $C$    & $\rightarrow$ & []                                                  & empty stack        \\
                                 &        & $\vbar$       & $(x,t)\cons C$                                      & expression binding \\
                                 &        & $\vbar$       & $(M,C)\cons C$                                      & module binding     \\
    Value of expressions         & $v$    & $\rightarrow$ & $\langle \lambda x.e, C \rangle$                    & closure
  \end{tabular}
  \caption{Definition of the semantic domains in the concrete case.}
  \label{fig:concdom}
\end{figure}

The domains for defining the operational semantics is extended to include the \emph{concrete time} and \emph{memory}.
Compared with Figure \ref{fig:simpdom}, Figure \ref{fig:concdom} defines four more sets, $\Time$, $\Mem$, $\State$, and $\Result$ to streamline the presentation.
A $s=(C,\mem,t)\in\State$ corresponds to a $C$ in Figure \ref{fig:simpdom}, as the pair $(C,\mem)$ cooperates to represent the recursively defined $C$ in the original representation without memory.
Similarly, a $r=(V,\mem,t)\in\Result$ corresponds to a $V$ in Figure \ref{fig:simpdom}, as the pair $(V,\mem)$ cooperates to represent the recursively defined $V$.

Note that a heavy burden has been cast upon the \emph{time} component.
The time component is responsible for providing \emph{fresh} addresses to write to in the memory, and it is also an indicator of the execution \emph{history} up to that point.
Hence, the policy for incrementing the timestamps of states decides what events are recorded in the timestamps, and the abstraction of this policy must select what events are preserved in the abstract semantics.
We name this policy $\tick$ in our framework.
The \emph{type} of $\tick$ can be freely chosen, since it may choose to record any event that occurs during execution, but in this section we choose the type $\Time\rightarrow\Time$, the simplest possible option.

\subsection{Operational Semantics}
\begin{figure}[h!]
  \begin{flushright}
    \fbox{$(e,C,\mem,t)\semarrow(V,\mem',t')\text{ or }(e',C',\mem',t')$}
  \end{flushright}
  \centering
  \vspace{0pt} % -0.75em}
  \[
    \begin{prooftree}
      \hypo{t_{x}={C}(x)}
      \hypo{v=\mem(t_{x})}
      \infer[left label=ExprID]2{
      (x, C, \mem, t)
      \semarrow
      (v, \mem, t)
      }
    \end{prooftree}\qquad
    \begin{prooftree}
      \infer[left label=Fn]0{
      (\lambda x.e, C, \mem, t)
      \semarrow
      (\langle\lambda x.e, C\rangle, \mem, t)
      }
    \end{prooftree}
  \]

  \[
    \begin{prooftree}
      \infer[left label={AppL}]0{
      (e_{1}\:e_{2}, C, \mem, t)
      \semarrow
      (e_{1},C, \mem,t)
      }
    \end{prooftree}\qquad
    \begin{prooftree}
      \hypo{
        \begin{matrix}
          (e_{1}, C, \mem, t)
          \semarrow
          (\langle\lambda x.e_{\lambda}, C_{\lambda}\rangle, \mem_{\lambda}, t_{\lambda})
        \end{matrix}
      }
      \infer[left label={AppR}]1{
      (e_{1}\:e_{2}, C, \mem, t)
      \semarrow
      (e_{2}, C, \mem_{\lambda}, t_{\lambda})
      }
    \end{prooftree}
  \]

  \[
    \begin{prooftree}
      \hypo{
        \begin{matrix}
          (e_{1}, C, \mem, t)
          \semarrow
          (\langle\lambda x.e_{\lambda}, C_{\lambda}\rangle, \mem_{\lambda}, t_{\lambda}) \\
          (e_{2}, C, \mem_{\lambda}, t_{\lambda})
          \semarrow
          (v, \mem_{a}, t_{a})
        \end{matrix}
      }
      \infer[left label={AppBody}]1{
      (e_{1}\:e_{2}, C, \mem, t)
      \semarrow
      (e_{\lambda}, (x, \tick(t_{a}))\cons C_{\lambda}, \mem_{a}[\tick(t_{a})\mapsto v], \tick(t_a))
      }
    \end{prooftree}
  \]

  \[
    \begin{prooftree}
      \hypo{
        \begin{matrix}
          (e_{1}, C, \mem, t)
          \semarrow
          (\langle\lambda x.e_{\lambda}, C_{\lambda}\rangle, \mem_{\lambda}, t_{\lambda}) \\
          (e_{2}, C, \mem_{\lambda}, t_{\lambda})
          \semarrow
          (v, \mem_{a}, t_{a})                                                            \\
          (e_{\lambda}, (x, \tick(t_{a}))\cons C_{\lambda}, \mem_{a}[\tick(t_{a})\mapsto v], \tick(t_a))
          \semarrow
          (v', \mem',t')
        \end{matrix}
      }
      \infer[left label={App}]1{
      (e_{1}\:e_{2}, C, \mem, t)
      \semarrow
      (v', \mem',t')
      }
    \end{prooftree}
  \]

  \[
    \begin{prooftree}
      \infer[left label=LinkL]0{
      (\link{e_{1}}{e_{2}}, C, \mem, t)
      \semarrow
      (e_{1}, C, \mem, t)
      }
    \end{prooftree}\qquad
    \begin{prooftree}
      \hypo{
        \begin{matrix}
          (e_{1}, C, \mem, t)
          \semarrow
          (C', \mem', t')
        \end{matrix}
      }
      \infer[left label=LinkR]1{
      (\link{e_{1}}{e_{2}}, C, \mem, t)
      \semarrow
      (e_{2}, C', \mem', t')
      }
    \end{prooftree}
  \]

  \[
    \begin{prooftree}
      \hypo{
        \begin{matrix}
          (e_{1}, C, \mem, t)
          \semarrow
          (C', \mem', t') \\
          (e_{2}, C', \mem', t')
          \semarrow
          (V, \mem'', t'')
        \end{matrix}
      }
      \infer[left label=Link]1{
      (\link{e_{1}}{e_{2}}, C, \mem, t)
      \semarrow
      (V, \mem'', t'')
      }
    \end{prooftree}\qquad
    \begin{prooftree}
      \infer[left label=Empty]0{
      (\varepsilon, C, \mem, t)
      \semarrow
      (C, \mem, t)
      }
    \end{prooftree}\qquad
    \begin{prooftree}
      \hypo{C'={C}(M)}
      \infer[left label=ModID]1{
      (M, C, \mem, t)
      \semarrow
      (C', \mem, t)
      }
    \end{prooftree}
  \]

  \[
    \begin{prooftree}
      \infer[left label=LetEL]0{
      (\mathtt{let}\:x\:e_1\:e_2, C, \mem, t)
      \semarrow
      (e_{1}, C, \mem, t)
      }
    \end{prooftree}
  \]

  \[
    \begin{prooftree}
      \hypo{
        \begin{matrix}
          (e_{1}, C, \mem, t)
          \semarrow
          (v, \mem', t')
        \end{matrix}
      }
      \infer[left label=LetER]1{
      (\mathtt{let}\:x\:e_1\:e_2, C, \mem, t)
      \semarrow
      (e_{2}, (x, \tick(t'))\cons C, \mem'[\tick(t')\mapsto v], \tick(t'))
      }
    \end{prooftree}
  \]

  \[
    \begin{prooftree}
      \infer[left label=LetML]0{
      (\mathtt{let}\:M\:e_{1}\:e_{2}, C, \mem, t)
      \semarrow
      (e_{1}, C, \mem, t)
      }
    \end{prooftree}\qquad
    \begin{prooftree}
      \hypo{
        \begin{matrix}
          (e_{1}, C, \mem, t)
          \semarrow
          (C', \mem', t')
        \end{matrix}
      }
      \infer[left label=LetMR]1{
      (\mathtt{let}\:M\:e_{1}\:e_{2}, C, \mem, t)
      \semarrow
      (e_{2}, (M, C')\cons C, \mem', t')
      }
    \end{prooftree}
  \]

  \[
    \begin{prooftree}
      \hypo{
        \begin{matrix}
          (e_{1}, C, \mem, t)
          \semarrow
          (v, \mem', t') \\
          (e_{2}, (x, \tick(t'))\cons C, \mem'[\tick(t')\mapsto v], \tick(t'))
          \semarrow
          (C', \mem'', t'')
        \end{matrix}
      }
      \infer[left label=LetE]1{
      (\mathtt{let}\:x\:e_1\:e_2, C, \mem, t)
      \semarrow
      (C', \mem'', t'')
      }
    \end{prooftree}\:
    \begin{prooftree}
      \hypo{
        \begin{matrix}
          (e_{1}, C, \mem, t)
          \semarrow
          (C', \mem', t') \\
          (e_{2}, (M, C')\cons C, \mem', t')
          \semarrow
          (C'', \mem'', t'')
        \end{matrix}
      }
      \infer[left label=LetM]1{
      (\mathtt{let}\:M\:e_{1}\:e_{2}, C, \mem, t)
      \semarrow
      (C'', \mem'', t'')
      }
    \end{prooftree}
  \]
  \caption{The concrete one-step transition relation.}
  \label{fig:concreach1}
\end{figure}

The operational semantics with memory is defined in Figure \ref{fig:concreach1}.
One must first note that there is a problem with the definition of $\semarrow$ as it is.
There are no restrictions on $\tick$ and the states $(C,\mem,t)$, thus a write to the address $t$ may overwrite an existing value that may be used for future computations.
That is, $\tick(t)\not\in\mathsf{supp}(C,\mem)$ must be guaranteed, when $\mathsf{supp}(C,\mem)$ is the set of timestamps reachable from $(C,\mem)$.
To enforce this invariant upon all \emph{valid} concrete executions defined by the relation $\semarrow$, we enforce that there be a \emph{total order} on $\Time$.
Then our criteria can be guaranteed by first enforcing $C\le t$ and $\mem\le t$, when
\[
  \begin{array}{cc}
    C \le  t\triangleq
    \begin{cases}
      \mathsf{True}              & C=[]              \\
      t' \le  t\wedge C' \le  t  & C=(x,t')\cons C'  \\
      C' \le  t\wedge C'' \le  t & C=(M,C')\cons C''
    \end{cases}
     &
    \begin{array}{l}
      V \le  t\triangleq
      \begin{cases}
        C \le  t & V=\langle\_,C\rangle \\
        C \le  t & V=C
      \end{cases} \\
      \mem \le  t\triangleq\forall t'\in\mathsf{dom}(\mem):t'\le t\wedge\mem(t') \le  t
    \end{array}
  \end{array}
\]
. Then the criteria that $\tick(t)$ must be fresh is formalized by demanding that:
\[t < \tick(t)\]
for all $t$.
This condition is not as restrictive as it seems, as we can conversely think of a $\tick$ generating fresh timestamps as \emph{inducing} a total order on $\Time$.
Also, these constraints match with the physical intuition of causality.
Now, to allow only such valid transitions, we define:
\[
  \State\triangleq\{(C,\mem,t)|C\le t\wedge\mem\le t\}\qquad
  \Result\triangleq\{(V,\mem,t)|V\le t\wedge\mem\le t\}
\]
as the set of \emph{valid} states that enable $\tick$ to behave nicely.
It is almost trivial that the set $\Left\times\Right$, when $\Left\triangleq\Expr\times\State$ and $\Right\triangleq\Left\uplus\Result$, is \emph{closed} under the inductive definition of $\semarrow$.
That is,
\begin{clm}[Valid States Transition to Valid States]
  For all $\ell\in\Left$ and $\rho$, if $\ell\semarrow\rho$ according to the inductive rules, $\rho\in\Right$.
\end{clm}
\begin{proof}[Sketch]
  Induction on the derivation of $\semarrow$.
\end{proof}

\subsection{Collecting Semantics}
The definition for the collecting semantics of the language is equal to the collecting semantics in the previous section.
That is, when we let $D\triangleq\pset(\Sigma)$ where $\Sigma\triangleq\Right\uplus\semarrow$,
\begin{definition}[Transfer function]
  Given $A\in D$, define
  \[
    \mathsf{Step}(A)\triangleq
    \left\{\ell\semarrow\rho, \rho\middle|
    \begin{prooftree}[center=true]
      \hypo{A'}\infer1{\ell\semarrow\rho}
    \end{prooftree}\wedge
    A'\subseteq A\wedge\ell\in A
    \right\}
  \]
\end{definition}
and
\begin{definition}[Collecting semantics]
  Given $e\in\Expr$ and $S\subseteq\State$, define:
  \[
    \sembracket{e}S\triangleq\lfp(\lambda X.\mathsf{Step}(X)\cup\{(e,s)|s\in S\})
  \]
\end{definition}

\subsection{Abstract Semantics}
\begin{figure}[h!]
  \centering
  \begin{tabular}{rrcll}
    Abstract Time                & $\A{t}$     & $\in$         & $\A{\Time}$                                                                                            \\
    Environment/Context          & $\A{C}$     & $\in$         & $\A{\Ctx}$                                                                                             \\
    Value of expressions         & $\A{v}$     & $\in$         & $\A{\Value} \subseteq \Expr\times\A{\Ctx}$                                                             \\
    Value of expressions/modules & $\A{V}$     & $\in$         & $\A{\Value\Ctx}\triangleq\A{\Value}\uplus\A{\Ctx}$                                                     \\
    Abstract Memory              & $\A{\mem}$  & $\in$         & $\A{\Mem} \triangleq \fin{\A{\Time}}{\pset(\A{\Value})}$                                               \\
    Abstract State               & $\A{s}$     & $\in$         & $\A{\State} \triangleq \A{\Ctx}\times\A{\Mem}\times\A{\Time}$                                          \\
    Abstract Result              & $\A{r}$     & $\in$         & $\A{\Result} \triangleq \A{\Value\Ctx}\times\A{\Mem}\times\A{\Time}$                                   \\
    Abstract Tick                & $\A{\tick}$ & $\in$         & $\A{\Tick}\triangleq\A{\State}\times\ExprVar\times\A{\Value}\rightarrow\A{\Time}$                      \\
    Context                      & $\A{C}$     & $\rightarrow$ & []                                                                                & empty stack        \\
                                 &             & $\vbar$       & $(x,\A{t})\cons \A{C}$                                                            & expression binding \\
                                 &             & $\vbar$       & $(M,\A{C})\cons \A{C}$                                                            & module binding     \\
    Value of expressions         & $\A{v}$     & $\rightarrow$ & $\langle \lambda x.e, \A{C} \rangle$                                              & closure
  \end{tabular}
  \caption{Definition of the semantic domains in the abstract case.}
  \label{fig:absdom}
\end{figure}
As promised, we present a way to simply abstract the concrete semantics via a finite abstraction of the time component.
For this purpose, we choose a finite \emph{abstract time} domain $\A\Time$ that is connected to the concrete time domain via an auxiliary function $\A\alpha:\Time\rightarrow\A\Time$.
Since the policy to update the timestamp must also be compatible with respect to $\A\alpha$, we require the $\A\tick:\A\Time\rightarrow\A\Time$ function to satisfy $\A\alpha\circ\tick=\A\tick\circ\A\alpha$.

Then the operational semantics can be abstracted directly, with modifications only in the \emph{update} of the memory and \emph{reads} from the memory.
The memory update operation is defined as a weak update, that is:
\[
  \A{\mem}[\A{t}\A{\mapsto}\A{v}](\A{t'})\triangleq
  \begin{cases}
    \A{\mem}(\A{t})\cup\{\A{v}\} & (\A{t'}=\A{t})     \\
    \A{\mem}(\A{t'})             & (\text{otherwise})
  \end{cases}
\]
and the read from the memory returns a set of closures with abstract addresses, allowing transitions to any value within that set.
The full definition for the abstract version of the operational semantics $\A\semarrow$ is in Figure \ref{fig:absreach1}.
$\A\semarrow\subseteq\A\Left\times\A\Right$, when $\A\Left\triangleq\Expr\times\A\State$ and $\A\Right\triangleq\A\Left\uplus\A\Result$.

\begin{figure}[h!]
  \begin{flushright}
    \fbox{$(e,\A{C},\A\mem,\A{t})\A\semarrow(\A{V},\A{\mem'},\A{t'})\text{ or }(e',\A{C'},\A{\mem'},\A{t'})$}
  \end{flushright}
  \vspace{0pt} % -0.75em}
  \[
    \begin{prooftree}
      \hypo{\A{t_x}=\A{C}(x)}
      \hypo{\A{v}\in\A\mem(\A{t_x})}
      \infer[left label=ExprID]2{
      (x, \A{C}, \A\mem, \A{t})
      \A\semarrow
      (\A{v}, \A\mem, \A{t})
      }
    \end{prooftree}\qquad
    \begin{prooftree}
      \infer[left label=Fn]0{
      (\lambda x.e, \A{C}, \A\mem, \A{t})
      \A\semarrow
      (\langle\lambda x.e, \A{C}\rangle, \A\mem, \A{t})
      }
    \end{prooftree}
  \]

  \[
    \begin{prooftree}
      \infer[left label={AppL}]0{
      (e_{1}\:e_{2}, \A{C}, \A\mem, \A{t})
      \A\semarrow
      (e_{1},\A{C}, \A\mem,\A{t})
      }
    \end{prooftree}\qquad
    \begin{prooftree}
      \hypo{
        \begin{matrix}
          (e_{1}, \A{C}, \A\mem, \A{t})
          \A\semarrow
          (\langle\lambda x.e_{\lambda}, \A{C}_{\lambda}\rangle, \A\mem_{\lambda}, \A{t_\lambda})
        \end{matrix}
      }
      \infer[left label={AppR}]1{
      (e_{1}\:e_{2}, \A{C}, \A\mem, \A{t})
      \A\semarrow
      (e_{2}, \A{C}, \A\mem_{\lambda}, \A{t_\lambda})
      }
    \end{prooftree}
  \]

  \[
    \begin{prooftree}
      \hypo{
        \begin{matrix}
          (e_{1}, \A{C}, \A\mem, \A{t})
          \A\semarrow
          (\langle\lambda x.e_{\lambda}, \A{C}_{\lambda}\rangle, \A\mem_{\lambda}, \A{t_\lambda}) \\
          (e_{2}, \A{C}, \A\mem_{\lambda}, \A{t_\lambda})
          \A\semarrow
          (v, \A\mem_{a}, \A{t_a})
        \end{matrix}
      }
      \infer[left label={AppBody}]1{
      (e_{1}\:e_{2}, \A{C,} \A\mem, \A{t})
      \A\semarrow
      (e_{\lambda}, (x, \A\tick(\A{t_a}))\cons \A{C}_{\lambda}, \A\mem_{a}[\A\tick(\A{t_a})\A\mapsto \A{v}], \A\tick(\A{t_a}))
      }
    \end{prooftree}
  \]

  \[
    \begin{prooftree}
      \hypo{
        \begin{matrix}
          (e_{1}, \A{C}, \A\mem, \A{t})
          \A\semarrow
          (\langle\lambda x.e_{\lambda}, \A{C}_{\lambda}\rangle, \A\mem_{\lambda}, \A{t_\lambda}) \\
          (e_{2}, \A{C}, \A\mem_{\lambda}, \A{t_\lambda})
          \A\semarrow
          (\A{v}, \A\mem_{a}, \A{t_a})                                                            \\
          (e_{\lambda}, (x, \A\tick(\A{t_a}))\cons \A{C}_{\lambda}, \A\mem_{a}[\A\tick(\A{t_a})\A\mapsto \A{v}], \A\tick(\A{t_a}))
          \A\semarrow
          (\A{v'}, \A{\mem'},\A{t'})
        \end{matrix}
      }
      \infer[left label={App}]1{
      (e_{1}\:e_{2}, \A{C}, \A\mem, \A{t})
      \A\semarrow
      (\A{v'}, \A{\mem'},\A{t'})
      }
    \end{prooftree}
  \]

  \[
    \begin{prooftree}
      \infer[left label=LinkL]0{
      (\link{e_{1}}{e_{2}}, \A{C}, \A\mem, \A{t})
      \A\semarrow
      (e_{1}, \A{C}, \A\mem, \A{t})
      }
    \end{prooftree}\qquad
    \begin{prooftree}
      \hypo{
        \begin{matrix}
          (e_{1}, \A{C}, \A\mem, \A{t})
          \A\semarrow
          (\A{C'}, \A{\mem'}, \A{t'})
        \end{matrix}
      }
      \infer[left label=LinkR]1{
      (\link{e_{1}}{e_{2}}, \A{C}, \A\mem, \A{t})
      \A\semarrow
      (e_{2}, \A{C'}, \A{\mem'}, \A{t'})
      }
    \end{prooftree}
  \]

  \[
    \begin{prooftree}
      \hypo{
        \begin{matrix}
          (e_{1}, \A{C}, \A\mem, \A{t})
          \A\semarrow
          (\A{C'}, \A{\mem'}, \A{t'}) \\
          (e_{2}, \A{C'}, \A{\mem'}, \A{t'})
          \A\semarrow
          (\A{V}, \A{\mem''}, \A{t''})
        \end{matrix}
      }
      \infer[left label=Link]1{
      (\link{e_{1}}{e_{2}}, \A{C}, \A\mem, \A{t})
      \A\semarrow
      (\A{V}, \A{\mem''}, \A{t''})
      }
    \end{prooftree}\qquad
    \begin{prooftree}
      \infer[left label=Empty]0{
      (\varepsilon, \A{C}, \A\mem, \A{t})
      \A\semarrow
      (\A{C}, \A\mem, \A{t})
      }
    \end{prooftree}
  \]

  \[
    \begin{prooftree}
      \hypo{\A{C'}=\A{C}(M)}
      \infer[left label=ModID]1{
      (M, \A{C}, \A\mem, \A{t})
      \A\semarrow
      (\A{C'}, \A\mem, \A{t})
      }
    \end{prooftree}\qquad
    \begin{prooftree}
      \infer[left label=LetEL]0{
      (\mathtt{let}\:x\:e_1\:e_2, \A{C}, \A\mem, \A{t})
      \A\semarrow
      (e_{1}, \A{C}, \A\mem, \A{t})
      }
    \end{prooftree}
  \]

  \[
    \begin{prooftree}
      \hypo{
        \begin{matrix}
          (e_{1}, \A{C}, \A\mem, \A{t})
          \A\semarrow
          (\A{v}, \A{\mem'}, \A{t'})
        \end{matrix}
      }
      \infer[left label=LetER]1{
      (\mathtt{let}\:x\:e_1\:e_2, \A{C}, \A\mem, \A{t})
      \A\semarrow
      (e_{2}, (x, \A\tick(\A{t'}))\cons \A{C}, \A{\mem'}[\A\tick(\A{t'})\A\mapsto \A{v}], \A\tick(\A{t'}))
      }
    \end{prooftree}
  \]

  \[
    \begin{prooftree}
      \infer[left label=LetML]0{
      (\mathtt{let}\:M\:e_{1}\:e_{2}, \A{C}, \A\mem, \A{t})
      \A\semarrow
      (e_{1}, \A{C}, \A\mem, \A{t})
      }
    \end{prooftree}\quad
    \begin{prooftree}
      \hypo{
        \begin{matrix}
          (e_{1}, \A{C}, \A\mem, \A{t})
          \A\semarrow
          (\A{C'}, \A{\mem'}, \A{t'})
        \end{matrix}
      }
      \infer[left label=LetMR]1{
      (\mathtt{let}\:M\:e_{1}\:e_{2}, \A{C}, \A\mem, \A{t})
      \A\semarrow
      (e_{2}, (M, \A{C'})\cons \A{C}, \A{\mem'}, \A{t'})
      }
    \end{prooftree}
  \]

  \[
    \begin{prooftree}
      \hypo{
        \begin{matrix}
          (e_{1}, \A{C}, \A\mem, \A{t})
          \A\semarrow
          (\A{v}, \A{\mem'}, \A{t'}) \\
          (e_{2}, (x, \A\tick(\A{t'}))\cons \A{C}, \A{\mem'}[\A\tick(\A{t'})\A\mapsto \A{v}], \A\tick(\A{t'}))
          \A\semarrow
          (\A{C'}, \A{\mem''}, \A{t''})
        \end{matrix}
      }
      \infer[left label=LetE]1{
      (\mathtt{let}\:x\:e_1\:e_2, \A{C}, \A\mem, \A{t})
      \A\semarrow
      (\A{C'}, \A{\mem''}, \A{t''})
      }
    \end{prooftree}
  \]

  \[
    \begin{prooftree}
      \hypo{
        \begin{matrix}
          (e_{1}, \A{C}, \A\mem, \A{t})
          \A\semarrow
          (\A{C'}, \A{\mem'}, \A{t'}) \\
          (e_{2}, (M, \A{C'})\cons \A{C}, \A{\mem'}, \A{t'})
          \A\semarrow
          (\A{C''}, \A{\mem''}, \A{t''})
        \end{matrix}
      }
      \infer[left label=LetM]1{
      (\mathtt{let}\:M\:e_{1}\:e_{2}, \A{C}, \A\mem, \A{t})
      \A\semarrow
      (\A{C''}, \A{\mem''}, \A{t''})
      }
    \end{prooftree}
  \]
  \caption{The abstract one-step transition relation.}
  \label{fig:absreach1}
\end{figure}

We note that the abstract operational semantics is a sound approximation of the concrete semantics in the operational sense, since if we extend $\A\alpha$ as:
\[
  \begin{array}{cc}
    \A{\alpha}(C)\triangleq
    \begin{cases}
      []                                  & C=[]              \\
      (x,\A{\alpha}(t))::\A{\alpha}(C')   & C=(x,t)\cons C'   \\
      (M,\A{\alpha}(C'))::\A{\alpha}(C'') & C=(M,C')\cons C''
    \end{cases}
     &
    \begin{array}{l}
      \A{\alpha}(V)\triangleq
      \begin{cases}
        \langle e,\A{\alpha}(C)\rangle & V=\langle e,C\rangle \\
        \A{\alpha}(C)                  & V=C
      \end{cases} \\
      \A{\alpha}(\mem)\triangleq\lambda\A{t}.\{\A\alpha(\mem(t))|\A\alpha(t)=\A{t}\wedge t\in\mathsf{dom}(\mem)\}
    \end{array}
  \end{array}
\]
and define $\A\alpha(r)$ for $r\in\Result$ by mapping over each component, we have:
\begin{clm}[Operational Soundness]
  For all $\ell\in\Left$ and $\rho\in\Right$, if $\ell\semarrow\rho$ then $\A\alpha(\ell)\A\semarrow\A\alpha(\rho)$.
\end{clm}
\begin{proof}[Sketch]
  Induction on $\semarrow$.
\end{proof}

Then if we define $\Abs{D}\triangleq\pset(\A\Sigma)$, when $\A\Sigma\triangleq\A\Right\uplus\A\semarrow$, we can establish a Galois connection between $D$ and $\Abs{D}$.
The abstraction and concretization functions are given by:
\begin{definition}[Abstraction and Concretization]
  Define $\alpha:D\rightarrow\Abs{D}$ and $\gamma:\Abs{D}\rightarrow D$ by:
  \[
    \alpha(A)\triangleq\{\A\alpha(\ell)\asemarrow\A\alpha(\rho)|\ell\semarrow\rho\in A\}\cup\{\A\alpha(\rho)|\rho\in A\}
  \]
  \[
    \gamma(\Abs{A})\triangleq\{\ell\semarrow\rho|\A\alpha(\ell)\asemarrow\A\alpha(\rho)\in\Abs{A}\}\cup\{\rho|\A\alpha(\rho)\in\Abs{A}\}
  \]
\end{definition}

Then it is straightforward to see that:
\begin{clm}[Galois Connection]
  $\pset(\Sigma)=D\galois{\alpha}{\gamma}\Abs{D}=\pset(\A\Sigma)$. That is, $\forall A\in D,\Abs{A}\in\Abs{D}:\alpha(A)\subseteq\Abs{A}\Leftrightarrow A\subseteq\gamma(\Abs{A})$.
\end{clm}
\begin{proof}[Sketch]
  Straightforward from the definitions of $\alpha$ and $\gamma$.
\end{proof}

The definition for the abstract fixpoint semantics is naturally connected soundly with the collecting semantics.
\begin{definition}[Abstract transfer function]
  Given $\Abs{A}\in\Abs{D}$, define
  \[
    \Abs{\mathsf{Step}}(\Abs{A})\triangleq
    \left\{\A\ell\A\semarrow\A\rho, \A\rho\middle|
    \begin{prooftree}[center=true]
      \hypo{\Abs{A'}}\infer1{\A\ell\A\semarrow\A\rho}
    \end{prooftree}\wedge
    \Abs{A'}\subseteq \Abs{A}\wedge\A\ell\in\Abs{A}
    \right\}
  \]
\end{definition}
\begin{definition}[Abstract semantics]
  Given $e\in\Expr$ and $\Abs{S}\subseteq\A\State$, define:
  \[
    \Abs{\sembracket{e}}\Abs{S}\triangleq\lfp(\lambda \Abs{X}.\Abs{\mathsf{Step}}(\Abs{X})\cup\{(e,\A{s})|\A{s}\in \Abs{S}\})
  \]
\end{definition}
Then we can prove that:
\begin{clm}[Soundness of $\Abs\Step$]
  $\Step\circ\gamma\subseteq\gamma\circ\Abs\Step$
\end{clm}
\begin{proof}
  From operational soundness, $\alpha\circ\Step\subseteq\Abs\Step\circ\alpha$.
  Thus, $\alpha\circ\Step\circ\gamma\subseteq\Abs\Step\circ\alpha\circ\gamma$.
  Since $\alpha\circ\gamma\subseteq\mathsf{id}$ by Galois connection and $\Abs\Step$ is monotonic, we have that $\alpha\circ\Step\circ\gamma\subseteq\Abs\Step$.
  By Galois connection, this is equivalent to $\Step\circ\gamma\subseteq\gamma\circ\Abs\Step$.
\end{proof}

\subsection{Computability of the Abstract Semantics}
Now we can say that $\Abs{\sembracket{e}}\alpha(S)$ is a sound abstraction of $\sembracket{e}S$.
However, is it true that $\Abs{\sembracket{e}}\alpha(S)$ is finitely computable?
Note that conceptually, all reachable configurations are derived from some closed expression $e$ evaluated from the empty context $[]$ and empty memory $\varnothing$.
We claim that in such situations, when the abstract semantics is computed from a finite set $\Abs{S}$ of initial states, the resulting computation $\Abs{\sembracket{e}}\Abs{S}$ has finite cardinality.

Since $\ATime$ is finite, all we have to prove is that all reachable \emph{signatures} are finite.
What we mean by a \emph{signature} is a context that is stripped of all timestamps.
Explicitly, we mean an element of an inductively defined set $\Sig$ given by $X\rightarrow []\:|\:x::X\:|\:(M,X)::X$.
Then we may inductively define $\lfloor C\rfloor$ and $\lfloor \A{C}\rfloor$ to be the signatures that are obtained by stripping all timestamps from $C$ and $\A{C}$.
Moreover, we may define $\lfloor m\rfloor\triangleq\{\lfloor C\rfloor|\exists t:\langle\_,C\rangle=m(t)\}$ and $\lfloor\A{m}\rfloor\triangleq\{\lfloor\A{C}\rfloor|\exists\A{t}:\langle\_,\A{C}\rangle\in\A{m}(\A{t})\}$ to be all signatures in a memory.
Finally, we may define $\lfloor\rho\rfloor$ as the union of $\lfloor C\rfloor$ and $\lfloor m\rfloor$, when $C$ is the context component and $m$ is the memory component of $\rho=(V,\mem,t)$ or $(e,C,\mem,t)$.
$\lfloor\A\rho\rfloor$ can be analogously defined.

If we can prove that for all $e$ and $\A{s}$, there exists a finite set $X\subseteq\Sig$ that bounds $\bigcup_{(e,\A{s})\A\semarrow^*\A\rho}\lfloor\A\rho\rfloor\subseteq X$, we can show that all reachable $\A\rho$s are finite, since $\ATime$ is finite.
It turns out, since the signature of the modules that are pushed into the stack $C$ can be accurately inferred from the definition of the operational semantics, we can \emph{compute} such an $X$.
Thus we have:
\begin{clm}[Computability of the Abstract Semantics]
  If $\Abs{S}$ is finite, $\Abs{\sembracket{e}}\Abs{S}$ is finite.
\end{clm}
\begin{proof}[Sketch]
  By existence of a function that computes all reachable signatures and by induction on $\asemarrow$.

  To elaborate, let this function be called $f:\A\Right\rightarrow\pset(\Sig)$.
  We need two lemmas, the first being $\forall\A\rho:\lfloor\A\rho\rfloor\subseteq f(\A\rho)$ and the second being $\forall\A\ell,\A\rho:\A\ell\A\semarrow\A\rho\Rightarrow f(\A\rho)\subseteq f(\A\ell)$.

  If we have the lemmas, then for all $\A\rho$ such that $(e,\A{s})\A\semarrow^*\A\rho$, $\lfloor\A\rho\rfloor\subseteq f(\A\rho)\subseteq f(e,\A{s})$, thus all signatures in $\Abs{\sembracket{e}}\Abs{S}$ can be bound by $X\triangleq\bigcup_{\A{s}\in\Abs{s}}f(e,\A{s})$, which is finite.
  The lemmas are formalized in Coq.
\end{proof}

We stress that this is a nontrivial result, since our definition of $C$ allows contexts to be pushed onto the stack.
The result holds only because the shape of the stack can be deterministically inferred according to the semantics of our language.
Thus, in languages which can be annotated with explicit signatures, this property will hold, even with features such as functors or first-class modules.

\section{Part III: Linking in the Semantics with Memory}
Now we need to define an injection operation that fills in the blanks of a $r=(V,\mem,t)\in\Result$ with a $s=(C',\mem',t')\in\State$.
Recall the definition for injection in the semantics without memory.
$\inject{C}{V}$ enables access to values that were previously not available in $V$ by filling in the bottom of the stack with $C$.
Thus, we must mimic this by filling in all contexts in $r$ with the context part of $s$.
Also, to retain all information stored in the memory, the memory part of $r$ must be merged with the memory of $s$.

It is at this point that a problem occurs.
When merging the two memories $\mem$ and $\mem'$, we may encounter overlapping addresses.
Thus, we must require that all reachable addresses from $(C,\mem)$ does not overlap with reachable addresses in $(C',\mem')$.
Then again, this requirement may be lifted if we allow linking of semantics that use \emph{different} time domains as addresses.
After all, we can only \emph{read} values from $C$ in $\inject{C}{V}$; why not preserve addresses that were used in $s$ before injection and never allow writing to those addresses?
Thus, in this section we first define $\inject{s_1}{r_2}$, when $s_1$ uses $\Time_1$ as addresses and $r_2$ uses $\Time_2$ as addresses.
Then $\inject{s_1}{r_2}$ must live in a version of $\Result$ that uses $\Time_1+\Time_2$ as addresses.
From now on, variables with subscripts $1$ or $2$ are to be understood to be using $\Time_i(i=1,2)$ as addresses, and variables with the subscript $+$ are to be understood to be the linked version.

Defining linking between different time domains demand that $\tick$, $\A\Time$, $\A\alpha$, and $\A\tick$ also be linked.
Concretely, we demand that the linked $\tick_+$ preserves the condition that $\A\alpha_+\circ\tick_+=\A\tick_+\circ\A\alpha_+$.
Also, we need to link $\tick$ well so that for all valid transitions $\ell_2\semarrow\rho_2$ under $\tick_2$, $\inject{s_1}{\ell_2}\semarrow\inject{s_1}{\rho_2}$ is also a valid transition under $\tick_+$.
This is to ensure that injection into the collecting semantics is well-defined.
For the rest of this section, we define linking for all semantic domains and prove that the requirements laid out in the skeleton for static analysis hold.

\subsection{$\tick_+$, $\A\alpha_+$, $\A\tick$}
We must first define $\tick_+$, $\A\alpha_+$, and $\A\tick_+$ that satisfies the condition that $t_+\le \tick_+(t_+)$ and $\A\alpha_+\circ\tick_+=\A\tick_+\circ\A\alpha_+$.
But wait, what must be the order on $\Time_1+\Time_2$?
We define $\le_+$ to be the \emph{lexicographic} order on $\Time_1+\Time_2$, when an element $t_1$ of $\Time_1$ is lifted to $(0,t_1)$ and an element $t_2$ of $\Time_2$ is lifted to $(1,t_2)$.
Then if we define:
\[
  \tick_+(t)\triangleq
  \begin{cases}
    \tick_1(t) & t\in\Time_1 \\
    \tick_2(t) & t\in\Time_2
  \end{cases}\qquad
  \A\alpha_+(t)\triangleq
  \begin{cases}
    \A\alpha_1(t) & t\in\Time_1 \\
    \A\alpha_2(t) & t\in\Time_2
  \end{cases}\qquad
  \A\tick_+(\A{t})\triangleq
  \begin{cases}
    \A\tick_1(\A{t}) & \A{t}\in\A\Time_1 \\
    \A\tick_2(\A{t}) & \A{t}\in\A\Time_2
  \end{cases}
\]
it is easy to check that all requirements are satisfied.

\subsection{Injection}
Now we define injection between $s_1\in\State_1$ and $r_2\in\Result_2$.
\begin{figure}[h!]
  \[
    \begin{array}{cc}
      \inject{C_{1}}{V_{2}}\triangleq
      \begin{cases}
        C_1                                           & V_{2}=[]                            \\
        (x, t)\cons\inject{C_{1}}{C}                  & V_{2}=(x,t)\cons C                  \\
        (M, \inject{C_{1}}{C})\cons\inject{C_{1}}{C'} & V_{2}=(M,C)\cons C'                 \\
        \langle\lambda x.e,\inject{C_1}{C_2}\rangle   & V_{2}=\langle\lambda x.e,C_2\rangle
      \end{cases} &
      \begin{array}{l}
        \inject{C_1}{\mem_2}\triangleq
        \displaystyle\bigcup_{t\in\mathsf{dom}(\mem_2)}[t\mapsto\inject{C_1}{\mem_2(t)}] \\ \\
        \inject{s_1}{r_2}\triangleq
        (\inject{C_1}{V_2},\mem_1\cup\inject{C_1}{\mem_2},t_2)
      \end{array}
    \end{array}
  \]
  \caption{Definition of the injection operator.
    In the definition of $\inject{s_1}{r_2}$, $s_1=(C_1,\mem_1,t_1)$ and $r_2=(V_2,\mem_2,t_2)$.}
  \label{fig:concinject}
\end{figure}

As is expected, injecting $s_1$ into $r_2$ involves injecting $C_1$ in every context in $r_2$ and merging the memories.
This definition is exactly what we were searching for, since it respects all requirements laid out in the introduction to this section.
First, the time-boundedness of $\inject{s_1}{r_2}$ is guaranteed with respect to the ordering $\le_+$, thus $\inject{s_1}{r_2}$ is safely in $\Result_+$.
Also, if we define $\inject{s_1}{\ell_2}$ when $\ell_2=(e,s_2)$ by $(e,\inject{s_1}{s_2})$, we can show that injection preserves valid transitions. That is,
\begin{clm}[Injection Preserves Evaluation]
  For all $s_1\in\State_1$, $\ell_2\in\Left_2$ and $\rho_2\in\Right_2$,
  if $\ell_2\semarrow\rho_2$ under $\tick_2$, then $\inject{s_1}{\ell_2}\semarrow\inject{s_1}{\rho_2}$ under $\tick_+$.
\end{clm}
\begin{proof}[Sketch]
  Induction on $\semarrow$ under $\tick_2$.
  We use the equality $\inject{C}{\mem[t\mapsto v]}=\inject{C}{\mem}[t\mapsto\inject{C}{v}]$ and other such equalities that allow commutativity of injection and semantic operations.
\end{proof}

Thus we can define $\rhd$ and $\semlink$ that satisfies the desired property.
\begin{definition}[Injection]
  For $S_1\subseteq\State_1$ and $A_2\in D_2$, define:
  \[
    S_1\rhd A_2\triangleq\{\inject{s_1}{\rho_2}|s_1\in S_1\wedge\rho_2\in A_2\}\cup\{\inject{s_1}{\ell_2}\semarrow\inject{s_1}{\rho_2}|s_1\in S_1\wedge\ell_2\semarrow\rho_2\in A_2\}
  \]
\end{definition}
\begin{definition}[Semantic Linking]
  For $S_1\subseteq\State_1$ and $A_2\in D_2$, define:
  \[
    S_1\semlink A_2\triangleq\lfp(\lambda X.\Step(X)\cup(S_1\rhd A_2))
  \]
\end{definition}
\begin{clm}[Advance]
  For all $e\in\Expr$ and $S_1\subseteq\State_1$, $S_2\subseteq\State_2$,
  \[
    \sembracket{e}(S_1\rhd S_2)=S_1\semlink\sembracket{e}S_2
  \]
\end{clm}
\subsection{Checking Soundness for Analysis}
We can define injection and linking in the abstract semantics in the same way as the concrete semantics.
Only the definition of $\inject{\A{C}_1}{\A\mem_2}$ in Figure \ref{fig:concinject} has to be adapted to account for the fact that $\A\mem_2(\A{t})$ is now a \emph{set} of closures and thus injection of $\A{C}_1$ must be mapped over all elements.
Then we can show that:
\begin{clm}[Injection Preserves Abstract Evaluation]
  For all $\A{s}_1\in\A\State_1$, $\A\ell_2\in\A\Left_2$ and $\A\rho_2\in\A\Right_2$, if $\A\ell_2\A\semarrow\A\rho_2$ under $\A\tick_2$,
  then $\inject{\A{s}_1}{\A\ell_2}\A\semarrow\inject{\A{s}_1}{\A\rho_2}$ under $\A\tick_+$.
\end{clm}
\begin{proof}[Sketch]
  Induction on $\A\semarrow$ under $\A\tick_2$.
\end{proof}
and thus we can define:
\begin{definition}[Abstract Injection]
  For $\Abs{S}_1\subseteq\A\State_1$ and $\A{A}_2\in\Abs{D}_2$, define:
  \[
    \Abs{S}_1\Abs\rhd\Abs{A}_2\triangleq\{\inject{\A{s}_1}{\A\rho_2}|\A{s}_1\in\Abs{S}_1\wedge\A\rho_2\in\Abs{A}_2\}\cup\{\inject{\A{s}_1}{\A\ell_2}\A\semarrow\inject{\A{s}_1}{\A\rho_2}|\A{s}_1\in\Abs{S}_1\wedge\A\ell_2\A\semarrow\A\rho_2\in\Abs{A}_2\}
  \]
\end{definition}
\begin{definition}[Abstract Linking]
  For $\Abs{S}_1\subseteq\A\State_1$ and $\Abs{A}_2\in\Abs{D}_2$, define:
  \[
    \Abs{S}_1\Abs\semlink\Abs{A}_2\triangleq\lfp(\lambda\Abs{X}.\Abs\Step(\Abs{X})\cup(\Abs{S}_1\Abs\rhd\Abs{A}_2))
  \]
\end{definition}
so that the \emph{best possible result} is achieved:
\begin{clm}[Abstract Advance]
  For all $e\in\Expr$ and $\Abs{S}_1\subseteq\A\State_1$, $\Abs{S}_2\subseteq\A\State_2$,
  \[
    \Abs{\sembracket{e}}(\Abs{S}_1\Abs\rhd\Abs{S}_2)=\Abs{S}_1\Abs\semlink\Abs{\sembracket{e}}\Abs{S}_2
  \]
\end{clm}
Since we have that
\[
  \alpha_+(S_1\rhd A_2)=\alpha_1(S_1)\Abs\rhd\alpha_2(A_2)
\]
due to $\alpha_+(\inject{s_1}{r_2})=\inject{\alpha_1(s_1)}{\alpha(r_2)}$, the above claim directly leads to overapproximation by:
\begin{align*}
  S_1\semlink\sembracket{e}S_2 & =\sembracket{e}(S_1\rhd S_2)                                          & (\because\text{Advance})                                           \\
                               & \subseteq\gamma_+(\Abs{\sembracket{e}}\alpha_+(S_1\rhd S_2))          & (\because\text{Galois connection})                                 \\
                               & =\gamma_+(\Abs{\sembracket{e}}(\alpha_1(S_1)\Abs\rhd\alpha_2(S_2)))   & (\because\alpha_+(S_1\rhd A_2)=\alpha_1(S_1)\Abs\rhd\alpha_2(A_2)) \\
                               & =\gamma_+(\alpha_1(S_1)\Abs\semlink\Abs{\sembracket{e}}\alpha_2(S_2)) & (\because\text{Abstract advance})
\end{align*}
\section{Part IV: A Criteria for Reusing Analysis Results}
In this section, we define what it means for semantics that use different timestamps to be \emph{equivalent}.
Our framework hinges heavily on the definition of equivalence, since when we link semantics that use two different timestamps, we end up with a semantics that uses a totally different $\Time$ and $\tick$.
Even in the case without linking, we need to justify why no matter our choice of $(\Time,\le,\ATime,\A\alpha)$, the analysis overapproximates a \emph{compatible} notion of execution.

In this section, we assume a pair of semantics, each parametrized with $(\Time,\le,\ATime,\A\alpha)$ and $(\Time',\le',\ATime',\A\alpha')$.
\subsection{Motivation}
Assume that we have a cached analysis result that uses the abstract timestamps $\{0,1\}$.
Unfortunately, 

\subsection{Definitions}
We first define what it means for two states $s\in\State$ and $s'\in\State'$ to be equivalent.
Note that $s=(C,\mem,t)$ and $s'=(C',\mem',t')$ for some contexts $C,C'$, some memories $\mem,\mem'$, and some times $t,t'$.
The choice of $t$ and $t'$ is ``not special'' in the sense that as long as they bound the context and memory, $\tick$ will continue producing fresh addresses.
Thus, the notion of equivalence is defined by how the ``information extractable'' from the $C$ and $\mem$ components are ``same''.

Note that the information that is extractable are only accessed through a sequence of names $x$ and $M$.
Thus, one may imagine access ``paths'' with names on the edges and information sources($C$ and $t$) on the nodes.
Also, given a $\varphi\in\Time\rightarrow\Time'$, we can define how access paths that use timestamps in $\Time$ are translated to access paths in $\Time'$.
The definitions are given in \ref{fig:accpath}.
\begin{figure}[h!]
  \centering
  \begin{tabular}{rclr}
    $p$ & $\rightarrow$ & $\epsilon$                   & (empty path)     \\
        & $|$           & $\xrightarrow{x}t\:p$        & (address access) \\
        & $|$           & $\xrightarrow{M}p$           & (module access)  \\
        & $|$           & $\xrightarrow{\lambda x.e}p$ & (value access)
  \end{tabular}\:
  $
    \varphi(p)\triangleq
    \begin{cases}
      \epsilon                               & p=\epsilon                    \\
      \xrightarrow{x}\varphi(t)\:\varphi(p') & p=\xrightarrow{x}t\:p'        \\
      \xrightarrow{M}\varphi(p')             & p=\xrightarrow{M}p'           \\
      \xrightarrow{\lambda x.e}\varphi(p')   & p=\xrightarrow{\lambda x.e}p'
    \end{cases}
  $
  \caption{Definition for access paths and how translation of timestamps are mapped over access paths.}
  \label{fig:accpath}
\end{figure}
From now on, we shall write $\Path$ for the set of access paths that use timestamps in $\Time$, and $\Path'$ for the set of access paths that use timestamps in $\Time'$.

Then given an access path, we can define a predicate $\valid\in(\Ctx\uplus\Time)\times\Mem\times\Path\rightarrow\mathsf{Prop}$.
Given $r\in\Ctx\uplus\Time,\mem\in\Mem,p\in\Path$, $\valid(r,\mem,p)$ is true iff all access edges in the path are valid, when starting from $r$.
\[
  \valid(r,\mem,p)\triangleq
  \begin{cases}
    \mathsf{True}                                                       & p=\epsilon                             \\
    t=C(x)\land\valid(t,\mem,p')                                        & r=C\land p=\xrightarrow{x}t\:p'        \\
    \exists C_M:C_M=C(M)\wedge\valid(C_M,\mem,p')                       & r=C\land p=\xrightarrow{M}p'           \\
    \exists C:\langle\lambda x.e,C\rangle=\mem(t)\land\valid(C,\mem,p') & r=t\land p=\xrightarrow{\lambda x.e}p' \\
    \mathsf{False}                                                      & \text{otherwise}
  \end{cases}
\]

Likewise, we can define a predicate $\A\valid\in(\A\Ctx\uplus\A\Time)\times\A\Mem\times\A\Path\rightarrow\mathsf{Prop}$.
Given $\A{r}\in\A\Ctx\uplus\A\Time,\A\mem\in\A\Mem,\A{p}\in\A\Path$, $\A\valid(\A{r},\A\mem,\A{p})$ is true iff all access edges in the path are valid, when starting from $\A{r}$.
\[
  \A\valid(\A{r},\A\mem,\A{p})\triangleq
  \begin{cases}
    \mathsf{True}                                                                                   & \A{p}=\epsilon                                         \\
    \A{t}=\A{C}(x)\land\A\valid(\A{t},\A\mem,\A{p'})                                                & \A{r}=\A{C}\land \A{p}=\xrightarrow{x}\A{t}\:\A{p'}    \\
    \exists \A{C_M}:\A{C_M}=\A{C}(M)\wedge\A\valid(\A{C_M},\A\mem,\A{p'})                           & \A{r}=\A{C}\land \A{p}=\xrightarrow{M}\A{p'}           \\
    \exists \A{C}:\langle\lambda x.e,\A{C}\rangle\in\A\mem(\A{t})\land\A\valid(\A{C},\A\mem,\A{p'}) & \A{r}=\A{t}\land \A{p}=\xrightarrow{\lambda x.e}\A{p'} \\
    \mathsf{False}                                                                                  & \text{otherwise}
  \end{cases}
\]

Now we can give a straightforward definitions of equivalence.
\begin{definition}[Equivalent Concrete States]
  Let $s=(C,\mem,t)\in\State$ and $s'=(C',\mem',t')\in\State'$.
  We say $s$ is \emph{equivalent} to $s'$ and write $s\cong s'$ when there exists a $\varphi:\Time\rightarrow\Time'$ and $\varphi^{-1}:\Time'\rightarrow\Time$ such that:
  \begin{enumerate}
    \item For all $p\in\Path$, if $\valid(C,\mem,p)$ then $\valid(C',\mem',\varphi(p))$ and $p=\varphi^{-1}(\varphi(p))$.
    \item For all $p'\in\Path'$, if $\valid(C',\mem',p')$ then $\valid(C,\mem,\varphi^{-1}(p'))$ and $p'=\varphi(\varphi^{-1}(p'))$.
  \end{enumerate}
\end{definition}
\begin{definition}[Equivalent Abstract States]
  Let $\A{s}=(\A{C},\A\mem,\A{t})\in\AState$ and $\A{s}'=(\A{C}',\A\mem',\A{t}')\in\AState'$.
  We say $\A{s}$ is \emph{equivalent} to $\A{s}'$ and write $\A{s}\A\cong\A{s}'$ when there exists a $\A\varphi:\ATime\rightarrow\ATime'$ and $\A\varphi^{-1}:\ATime'\rightarrow\ATime$ such that:
  \begin{enumerate}
    \item For all $\A{p}\in\A\Path$, if $\A\valid(\A{C},\A\mem,\A{p})$ then $\A\valid(\A{C'},\A{\mem'},\A\varphi(p))$ and $\A{p}=\A\varphi^{-1}(\A\varphi(\A{p}))$.
    \item For all $\A{p'}\in\A{\Path'}$, if $\A\valid(\A{C'},\A{\mem'},\A{p'})$ then $\valid(\A{C},\A{\mem},\A\varphi^{-1}(p'))$ and $\A{p'}=\A\varphi(\A\varphi^{-1}(\A{p'}))$.
  \end{enumerate}
\end{definition}

We also define equivalence between results $r=(V,\mem.t)\in\Result$ and $r'=(V',\mem',t')\in\Result'$ by the conjunction of the equality between the expression part of $V$ and equivalence between .
Also, equivalence between $\ell=(e,s)\in\Left$ and $\ell'=(e',s')\in\Left'$ can be similarly defined as $e=e'\wedge s\cong s'$.
Thus equivalence between $\rho\in\Right$ and $\rho'\in\Right'$ is defined, as either $\rho\in\Left$ or $\rho\in\Result$.

Then the equivalence between elements of $D$ and $D'$, the CPOs, can be defined as:
\begin{definition}[Equivalence between Elements of $D$ and $D'$]
  Let $A\in D$ and $A'\in D'$. We say that $A$ and $A'$ are equivalent and write $A\cong A'$ iff:
  \begin{enumerate}
    \item $\forall\ell,\rho:\ell\semarrow\rho\in A\Rightarrow\exists\ell',\rho':\ell'\semarrow\rho'\in A'\wedge\ell\cong\ell'\wedge\rho\cong\rho'$
    \item $\forall\ell',\rho':\ell'\semarrow\rho'\in A'\Rightarrow\exists\ell,\rho:\ell\semarrow\rho\in A\wedge\ell\cong\ell'\wedge\rho\cong\rho'$
    \item $\forall\rho:\rho\in A\Rightarrow\exists\rho':\rho'\in A'\wedge\rho\cong\rho'$
    \item $\forall\rho':\rho'\in A'\Rightarrow\exists\rho:\rho\in A\wedge\rho\cong\rho'$
  \end{enumerate}
\end{definition}

Likewise, we can define equivalence between elements of $\Abs{D}$ and $\Abs{D'}$.
\begin{definition}[Equivalence between Elements of $\Abs{D}$ and $\Abs{D'}$]
  Let $\Abs{A}\in\Abs{D}$ and $\Abs{A'}\in\Abs{D'}$. We say that $\Abs{A}$ and $\Abs{A'}$ are equivalent and write $\Abs{A}\Abs\cong \Abs{A'}$ iff:
  \begin{enumerate}
    \item $\forall\A\ell,\A\rho:\A\ell\A\semarrow\A\rho\in \Abs{A}\Rightarrow\exists\A\ell',\A\rho':\A\ell'\semarrow\A\rho'\in \Abs{A'}\wedge\A\ell\A\cong\A\ell'\wedge\A\rho\A\cong\A\rho'$
    \item $\forall\A\ell',\A\rho':\A\ell'\A\semarrow\A\rho'\in \Abs{A'}\Rightarrow\exists\A\ell,\A\rho:\A\ell\semarrow\A\rho\in \Abs{A}\wedge\A\ell\A\cong\A\ell'\wedge\A\rho\A\cong\A\rho'$
    \item $\forall\A\rho:\A\rho\in \Abs{A}\Rightarrow\exists\A\rho':\A\rho'\in A'\wedge\A\rho\A\cong\A\rho'$
    \item $\forall\A\rho':\A\rho'\in \Abs{A'}\Rightarrow\exists\A\rho:\A\rho\in A\wedge\A\rho\A\cong\A\rho'$
  \end{enumerate}
\end{definition}
\subsection{Proof Sketches}
\subsubsection{Evaluation Preserves Equivalence}
To prove if we actually did define equivalence sensibly, we must show that the operational semantics preserves equivalence.
That is, we need to prove that starting from equivalent configurations, we end up in equivalent configurations.
\begin{clm}[Evaluation Preserves Equivalence]
  For all $\ell\in\Left$, $\rho\in\Right$, $\ell'\in\Left'$,
  \[\ell\semarrow\rho\wedge\ell\cong\ell'\Rightarrow\exists\rho':\ell'\semarrow\rho'\wedge\rho\cong\rho'\]
  Thus, if $S\subseteq\State$ and $S'\subseteq\State'$ are equivalent, $\sembracket{e}S\cong\sembracket{e}S'$.
\end{clm}
\begin{proof}[Sketch]
  To perform induction on $\semarrow$, we need to strengthen the claim.
  For convenience, we write $(\rho,\varphi)\cong(\rho',\varphi^{-1})$ to emphasize that the equivalence is given by $\varphi$.

  Then we can strengthen the claim.
  \[
    \begin{array}{l}
      \forall\ell,\rho,\ell',\varphi,\varphi^{-1}:\ell\semarrow\rho\wedge(\ell,\varphi)\cong(\ell',\varphi^{-1})\Rightarrow              \\
      \exists\rho',\phi,\phi^{-1}:\ell'\semarrow\rho'\wedge(\rho,\phi)\cong(\rho',\phi^{-1})\wedge\varphi|_{\le t}=\phi|_{\le t} \\
      \text{when }t\text{ is the time component of }\ell
    \end{array}
  \]
  The important part here is that $\phi$ is an \emph{extension} of $\varphi$.
  Thus the induction hypothesis will push through.
\end{proof}

\subsubsection{Concretization Preserves Equivalence}
For the definition of equivalence to be compatible with analysis, we want to show that if the abstract initial states are equivalent, so are the concretization of those states.
If this is true, we can obtain an overapproximation of an equivalent semantics by $\sembracket{e}\gamma(\Abs{S})\cong\sembracket{e}\gamma'(\Abs{S'})\subseteq\gamma'(\Abs{\sembracket{e}}\Abs{S'})$ from $\Abs{S}\Abs\cong\Abs{S'}$.
The first $\cong$ is from the fact that evaluation preserves equivalence and concretization preserves equivalence.
The second $\subseteq$ is from the fact that $\Abs\Step$ is a sound approximation of $\Step$.
The claim we want to prove is: If $\Abs{S}\Abs\cong\Abs{S'}$, then $\gamma(\Abs{S})\cong\gamma'(\Abs{S'})$.

\begin{clm}[Concretization Preserves Equivalence]
  For all $\Abs{S}\subseteq\AState$ and $\Abs{S'}\subseteq\AState'$, $\Abs{S}\Abs\cong\Abs{S'}$ implies $\gamma(\Abs{S})\cong\gamma'(\Abs{S'})$.
\end{clm}
\begin{proof}[Sketch]
  We want to prove:
  \[\forall s\in\State,\A{s}'\in\AState':\A\alpha(s)\A\cong\A{s}'\Rightarrow\exists s'\in\AState':s\cong s'\wedge\A\alpha'(s')=\A{s}'\]
  If this is true, $\forall s\in\gamma(\Abs{s}):\exists s'\in\gamma(\Abs{s'}):s\cong s'$.

  Proving the same statement in the opposite side leads to $\forall s'\in\gamma(\Abs{s'}):\exists s\in\gamma(\Abs{s}):s\cong s'$, so that $\gamma(\Abs{S})\cong\gamma'(\Abs{S'})$.
  The proof of the above statement involves constructing such a $s'$ by traversal over reachable subparts $n$ of $s$, (1) translating $n$ to a reachable part $\A{n}'$ of $\A{s}'$ by $\A\varphi\circ\A\alpha$(when $\A\varphi$ gives the equivalence between $\A\alpha(s)$ and $\A{s}'$) and (2) lifting $\A{n}'$ to a reachable part $n'$ of $s'$ while tabulating the graph isomorphism $\varphi$ between $s$ and $s'$.
  Finally, (3) the unreachable parts of $s'$ are filled in with dummy values that translate to the unfilled parts of $\A{s}'$.
\end{proof}

\end{document}
%%% Local Variables: 
%%% coding: utf-8
%%% mode: latex
%%% TeX-engine: xetex
%%% End:
