%! TEX program = xelatex
\documentclass[acmsmall,review]{acmart}\settopmatter{printfolios=true,printccs=false,printacmref=false}

%%% Typesetting for listings
\usepackage{listings}
\setmonofont{JuliaMono}[Scale=MatchLowercase]

\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{ltblue}{rgb}{0,0.4,0.4}
\definecolor{dkviolet}{rgb}{0.3,0,0.5}

%%% lstlisting coq style (inspired from a file of Assia Mahboubi)
\lstdefinelanguage{Coq}{ 
    % Anything betweeen $ becomes LaTeX math mode
    mathescape=true,
    % Comments may or not include Latex commands
    texcl=false, 
    % Vernacular commands
    morekeywords=[1]{Section, Module, End, Require, Import, Export,
        Variable, Variables, Parameter, Parameters, Axiom, Hypothesis,
        Hypotheses, Notation, Local, Tactic, Reserved, Scope, Open, Close,
        Bind, Delimit, Definition, Let, Ltac, Fixpoint, CoFixpoint, Add,
        Morphism, Relation, Implicit, Arguments, Unset, Contextual,
        Strict, Prenex, Implicits, Inductive, CoInductive, Record,
        Structure, Canonical, Coercion, Context, Class, Global, Instance,
        Program, Infix, Theorem, Lemma, Corollary, Proposition, Fact,
        Remark, Example, Proof, Goal, Save, Qed, Defined, Hint, Resolve,
        Rewrite, View, Search, Show, Print, Printing, All, Eval, Check,
        Projections, inside, outside, Def},
    % Gallina
    morekeywords=[2]{forall, exists, exists2, fun, fix, cofix, struct,
        match, with, end, as, in, return, let, if, is, then, else, for, of,
        nosimpl, when},
    % Sorts
    morekeywords=[3]{Type, Prop, Set, true, false, option},
    % Various tactics, some are std Coq subsumed by ssr, for the manual purpose
    morekeywords=[4]{pose, set, move, case, elim, apply, clear, hnf,
        intro, intros, generalize, rename, pattern, after, destruct,
        induction, using, refine, inversion, injection, rewrite, congr,
        unlock, compute, ring, field, fourier, replace, fold, unfold,
        change, cutrewrite, simpl, have, suff, wlog, suffices, without,
        loss, nat_norm, assert, cut, trivial, revert, bool_congr, nat_congr,
        symmetry, transitivity, auto, split, left, right, autorewrite},
    % Terminators
    morekeywords=[5]{by, done, exact, reflexivity, tauto, romega, omega,
        assumption, solve, contradiction, discriminate},
    % Control
    morekeywords=[6]{do, last, first, try, idtac, repeat},
    % Comments delimiters, we do turn this off for the manual
    morecomment=[s]{(*}{*)},
    % Spaces are not displayed as a special character
    showstringspaces=false,
    % String delimiters
    morestring=[b]",
    morestring=[d],
    % Size of tabulations
    tabsize=3,
    % Enables ASCII chars 128 to 255
    extendedchars=false,
    % Case sensitivity
    sensitive=true,
    % Automatic breaking of long lines
    breaklines=false,
    % Default style fors listings
    basicstyle=\small,
    % Position of captions is bottom
    captionpos=b,
    % flexible columns
    columns=[l]flexible,
    % Style for (listings') identifiers
    identifierstyle={\ttfamily\color{black}},
    % Style for declaration keywords
    keywordstyle=[1]{\ttfamily\color{dkviolet}},
    % Style for gallina keywords
    keywordstyle=[2]{\ttfamily\color{dkgreen}},
    % Style for sorts keywords
    keywordstyle=[3]{\ttfamily\color{ltblue}},
    % Style for tactics keywords
    keywordstyle=[4]{\ttfamily\color{dkblue}},
    % Style for terminators keywords
    keywordstyle=[5]{\ttfamily\color{dkred}},
    %Style for iterators
    %keywordstyle=[6]{\ttfamily\color{dkpink}},
    % Style for strings
    stringstyle=\ttfamily,
    % Style for comments
    commentstyle={\ttfamily\color{dkgreen}},
    %moredelim=**[is][\ttfamily\color{red}]{/&}{&/},
    literate=
    {\\forall}{{\color{dkgreen}{$\forall\;$}}}1
    {\\exists}{{$\exists\;$}}1
    {<-}{{$\leftarrow\;$}}1
    {=>}{{$\Rightarrow\;$}}1
    {==}{{\code{==}\;}}1
    {==>}{{\code{==>}\;}}1
    %    {:>}{{\code{:>}\;}}1
    {->}{{$\rightarrow\;$}}1
    {<->}{{$\leftrightarrow\;$}}1
    {<==}{{$\leq\;$}}1
    {\#}{{$^\star$}}1 
    {\\o}{{$\circ\;$}}1 
    {\@}{{$\cdot$}}1 
    {\/\\}{{$\wedge\;$}}1
    {\\\/}{{$\vee\;$}}1
    {++}{{\code{++}}}1
    {~}{{\ }}1
    {\@\@}{{$@$}}1
    {\\mapsto}{{$\mapsto\;$}}1
    {\\hline}{{\rule{\linewidth}{0.5pt}}}1
    %
}[keywords,comments,strings]

%%% Citation style
\citestyle{acmauthoryear}

%%% Math settings
\usepackage{amsthm,mathtools}
\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]
\newtheorem{example}{Example}[section]
\newtheorem{lem}{Lemma}[section]
\newtheorem{thm}{Theorem}[section]

%%% PL constructs
\usepackage{galois}
\usepackage{ebproof}
\ebproofset{left label template=\textsc{[\inserttext]}}
\ebproofset{center=false}

%%% Custom commands
\newcommand*{\vbar}{|}
\newcommand*{\finto}{\xrightarrow{\text{\textrm{fin}}}}
\newcommand*{\istype}{\mathrel{â©´}}
\newcommand*{\ortype}{\mathrel{|}}
\newcommand*{\cons}{::}

\def\ovbarw{1.2mu}
\def\ovbarh{1}
\newcommand*{\ovbar}[1]{\mkern \ovbarw\overline{\mkern-\ovbarw{\smash{#1}\scalebox{1}[\ovbarh]{\vphantom{i}}}\mkern-\ovbarw}\mkern \ovbarw}
\newcommand*{\A}[1]{{#1}^{\#}}
\newcommand*{\Expr}{\text{Expr}}
\newcommand*{\ExprVar}{\text{ExprVar}}
\newcommand*{\Module}{\text{Module}}
\newcommand*{\ModVar}{\text{ModVar}}
\newcommand*{\Time}{\mathbb{T}}
\newcommand*{\ATime}{\A{\Time}}
\newcommand*{\Ctx}[1]{\text{Ctx}({#1})}
\newcommand*{\Value}[1]{\text{Val}({#1})}
\newcommand*{\Mem}[1]{\text{Mem}({#1})}
\newcommand*{\mem}{m}
\newcommand*{\AMem}[1]{\A{\text{Mem}}({#1})}
\newcommand*{\State}[1]{\text{State}({#1})}
\newcommand*{\AState}[1]{\A{\text{State}}({#1})}
\newcommand*{\Result}[1]{\text{Result}({#1})}
\newcommand*{\AResult}[1]{\A{\text{Result}}({#1})}
\newcommand*{\link}[2]{{#1}\mathtt{!}{#2}}

\newcommand*{\doubleplus}{\ensuremath{\mathbin{+\mkern-3mu+}}}
\newcommand*{\project}{\text{\texttt{:>} }}
\newcommand*{\Exp}{\mathsf{Exp}}
\newcommand*{\Imp}{\mathsf{Imp}}
\newcommand*{\Fin}{\mathsf{Fin}}
\newcommand*{\Link}{\mathsf{Link}}
\newcommand*{\sembracket}[1]{\lBrack{#1}\rBrack}
\newcommand*{\fin}[2]{{#1}\xrightarrow{\text{fin}}{#2}}
\newcommand*{\addr}{\mathsf{addr}}
\newcommand*{\tick}{\mathsf{tick}}
\newcommand*{\modctx}{\mathsf{ctx}}
\newcommand*{\mapinject}[2]{{#1}[{#2}]}
\newcommand*{\inject}[2]{{#1}\langle{#2}\rangle}
\newcommand*{\deletepre}[2]{{#2}\overline{\doubleplus}{#1}}
\newcommand*{\deletemap}[2]{{#1}\overline{[{#2}]}}
\newcommand*{\delete}[2]{{#1}\overline{\langle{#2}\rangle}}
\newcommand*{\filter}{\mathsf{filter}}
\newcommand*{\Let}{\mathtt{let}}

\title{A Syntax-Guided Framework for Modular Analysis}
\author{Joonhyup Lee}
\begin{document}
\maketitle

\section{Abstract Syntax}

In this section we define the abstract syntax for a simple language that captures the essence of modules and linking.
The language is basically an extension of untyped lambda calculus with modules and the linking construct.

\begin{figure}[htb]
  \centering
  \footnotesize
  \begin{tabular}{rccll}
    Expression Identifier & $x$ & $\in$         & $\ExprVar$                                   \\
    Module Identifier     & $M$ & $\in$         & $\ModVar$                                    \\
    Expression            & $e$ & $\in$         & $\Expr$                                      \\
    Expression            & $e$ & $\rightarrow$ & $x$                & identifier, expression  \\
                          &     & $\vbar$       & $\lambda x.e$      & function                \\
                          &     & $\vbar$       & $e$ $e$            & application             \\
                          &     & $\vbar$       & $\link{e}{e}$      & linked expression       \\
                          &     & $\vbar$       & $\varepsilon$      & empty module            \\
                          &     & $\vbar$       & $M$                & identifier, module      \\
                          &     & $\vbar$       & $\Let$ $x$ $e$ $e$ & let-binding, expression \\
                          &     & $\vbar$       & $\Let$ $M$ $e$ $e$ & let-binding, module     \\
  \end{tabular}
  \caption{Abstract syntax of the simple module language.}
\end{figure}
\subsection{Rationale for the design of the simple language}

There are no recursive modules, first-class modules, or functors in the simple language that is defined.
Also, note that the nonterminals for the modules and expressions are not separated. Why is this so?

The rationale for the exclusion of recursive modules/first-class modules/functors is because we want to enforce static scoping.
That is, we need to be able to statically determine where variables were bound when using them.
To enforce static scoping when function applications might return modules, we need to employ signatures to project the dynamically computed modules onto a statically known context.
Concretely, we need to define signatures $S$ where $\lambda M\project S.e$ statically resolves the context when $M$ is used in the body $e$, and $(e_1\:e_2)\project S$ enforces that a dynamic computation is resolved into one static form.
To simplify the presentation, we first consider the case that does not require signatures.

The rationale for not separating modules and expressions in the syntax is because we want to utilize the linking construct to link both modules to expressions and modules to modules.
That is, we want expressions to be parsed as $(m_1!m_2)!e$.
$\link{m_1}{m_2}$ links a module with a module, and $(m_1!m_2)!e$ links a module with an expression.
Why this is convenient will be clear when we explain separate analysis; we want to link modules with modules as well as expressions.

\section{Concrete Semantics}

In this section, we present the dynamics of the simple language presented in the previous section.

\subsection{Structural Operational Semantics}

First, we give the operational semantics for the dynamic execution of the module language.
The one-step reachability relation $\rightsquigarrow$ will relate a configuration(expression and state) either to (1) another configuration of which its results are used for the evaluation of the first configuration, or to (2) the returned result from the configuration.

Prior to defining this relation, the semantic domains must be set up.
As is common in defining dynamics for call-by-value lambda calculus, one must define \emph{environments} to record what values were bound to variables.
For the ease of program analysis, this environment is divided again into (1) a context $C$ that binds variables in scope to the \emph{time} those variables were bound, and (2) a memory $\mem$ which records which values were bound at what time.

The representation of the context $C$ is a stack that records variables \emph{in the order} they were bound.
In the spirit of de Bruijn, to access the value of a variable $x$, one has to read off the closest binding time from $C$ and consult the memory to determine what value was bound at that time.
In contrast, to access the exported context from a variable $M$, one has to look up the exported context from $C$, not from the memory.

This separation between where we store modules and where we store closures emphasizes the fact that \emph{where} the variables are bound is guided by syntax.
The only thing that is dynamic is \emph{when} the variables are bound, which is represented by the time component.

Now, we start by defining what we mean by \emph{time} and \emph{context}, which is the essence of our model.

\subsubsection{Time and Context}

We first define sets that are parametrized by our choice of the time domain, namely the \emph{value}, \emph{memory}, and \emph{context} domains.
Also, we present the notational conventions used in this paper to represent members of each domain.

\begin{figure}[htb]
  \centering
  \footnotesize
  \begin{tabular}{rccll}
    Time                         & $t$    & $\in$         & $\Time$                                                                                                  \\
    Environment/Context          & $C$    & $\in$         & $\Ctx\Time$                                                                                              \\
    Value of expressions         & $v$    & $\in$         & $\Value\Time \triangleq \Expr\times\Ctx\Time$                                                            \\
    Value of expressions/modules & $V$    & $\in$         & $\Value{\Time}+\Ctx{\Time}$                                                                              \\
    Memory                       & $\mem$ & $\in$         & $\Mem{\Time} \triangleq \fin{\Time}{\Value{\Time}}$                                                      \\
    State                        & $s$    & $\in$         & $\State{\Time} \triangleq \Ctx{\Time}\times\Mem{\Time}\times\Time$                                       \\
    Result                       & $r$    & $\in$         & $\Result{\Time} \triangleq (\Value{\Time}+\Ctx{\Time})\times\Mem{\Time}\times\Time$                      \\
    Context                      & $C$    & $\rightarrow$ & []                                                                                  & empty stack        \\
                                 &        & $\vbar$       & $(x,t)\cons C$                                                                      & expression binding \\
                                 &        & $\vbar$       & $(M,C)\cons C$                                                                      & module binding     \\
    Value of expressions         & $v$    & $\rightarrow$ & $\langle \lambda x.e, C \rangle$                                                    & closure
  \end{tabular}
  \caption{Definition of the semantic domains.}
\end{figure}

Above, there are no constraints placed upon the set $\Time$.
Now we give the conditions that the concrete time domain must satisfy.

\begin{definition}[Concrete time]
  $(\Time, \le, \tick)$ is a \emph{concrete time} when
  \begin{enumerate}
    \item $(\Time, \le)$ is a total order.
    \item $\tick : \Ctx{\Time}\rightarrow\Mem{\Time}\rightarrow\Time\rightarrow\ExprVar\rightarrow\Value{\Time}\rightarrow\Time$ satisfies:
          \[\forall t\in\Time: t < \tick\:\_\:\_\:t\:\_\:\_\]
  \end{enumerate}
\end{definition}
The time $\tick\:C\:\mem\:t\:x\:v$ is the time that is incremented when the value $v$ is bound to a variable $x$ at time $t$ under context $C$ and memory $m$.

Why must the $\tick$ function for the concrete time take in $C, m, t, x, v$?
This is for the purpose of program analysis.
For program analysis, the analysis designer must think of an \emph{abstract} tick operator that \emph{simulates} its concrete counterpart.
If the concrete tick function is not able to take into account the environment that the time is incremented, the abstraction of the tick function will not be able to hold much information about the execution of the program.

Now for the auxiliary operators that is used when defining the evaluation relation.
We define the function that extracts the address for an $\ExprVar$,
and the function that looks up the dynamic context bound to a $\ModVar$ $M$.

\begin{figure}[h!]
  \centering
  \footnotesize
  \[
    \addr(C,x)\triangleq
    \begin{cases}
      \bot         & C=[]                              \\
      t            & C=(x, t)\cons C'                  \\
      \addr(C',x)  & C=(x', t)\cons C' \wedge x'\neq x \\
      \addr(C'',x) & C=(M, C')\cons C''
    \end{cases}
    \quad
    \modctx(C,M)\triangleq
    \begin{cases}
      \bot           & C=[]                               \\
      C'             & C=(M, C')\cons C''                 \\
      \modctx(C'',M) & C=(M', C')\cons C''\wedge M'\neq M \\
      \modctx(C',M)  & C=(x, t)\cons C'
    \end{cases}
  \]
  \caption{Definitions for the $\addr$ and $\modctx$ operators.}
\end{figure}

\subsubsection{The Relation}

Now we are in a position to define the one-step reachability relation.
The relation $\rightsquigarrow$ relates $(e,C,\mem,t)\in\Expr\times\State{\Time}$ with either
$(V,\mem,t)\in\Result{\Time}$ or $(e',C',\mem',t')$.
Note that we constrain whether an expression returns $v$ or $C$ by the definition of $\rightsquigarrow$.

\begin{figure}[h!]
  \begin{flushright}
    \fbox{$(e,C,\mem,t)\rightsquigarrow(V,\mem',t')/(e',C',\mem',t')$}
  \end{flushright}
  \vspace{0pt} % -0.75em}
  \footnotesize
  \[
    \begin{prooftree}
      \hypo{t_{x}=\addr(C,x)}
      \hypo{v=\mem(t_{x})}
      \infer[left label=ExprID]2{
      (x, C, \mem, t)
      \rightsquigarrow
      (v, \mem, t)
      }
    \end{prooftree}\qquad
    \begin{prooftree}
      \infer[left label=Fn]0{
      (\lambda x.e, C, \mem, t)
      \rightsquigarrow
      (\langle\lambda x.e, C\rangle, \mem, t)
      }
    \end{prooftree}
  \]

  \[
    \begin{prooftree}
      \infer[left label={AppL}]0{
      (e_{1}\:e_{2}, C, \mem, t)
      \rightsquigarrow
      (e_{1},C, \mem,t)
      }
    \end{prooftree}\qquad
    \begin{prooftree}
      \hypo{
        \begin{matrix}
          (e_{1}, C, \mem, t)
          \rightsquigarrow
          (\langle\lambda x.e_{\lambda}, C_{\lambda}\rangle, \mem_{\lambda}, t_{\lambda})
        \end{matrix}
      }
      \infer[left label={AppR}]1{
      (e_{1}\:e_{2}, C, \mem, t)
      \rightsquigarrow
      (e_{2}, C, \mem_{\lambda}, t_{\lambda})
      }
    \end{prooftree}
  \]

  \[
    \begin{prooftree}
      \hypo{
        \begin{matrix}
          (e_{1}, C, \mem, t)
          \rightsquigarrow
          (\langle\lambda x.e_{\lambda}, C_{\lambda}\rangle, \mem_{\lambda}, t_{\lambda}) \\
          (e_{2}, C, \mem_{\lambda}, t_{\lambda})
          \rightsquigarrow
          (v, \mem_{a}, t_{a})
        \end{matrix}
      }
      \infer[left label={AppBody}]1{
      (e_{1}\:e_{2}, C, \mem, t)
      \rightsquigarrow
      (e_{\lambda}, (x, t_{a})\cons C_{\lambda}, \mem_{a}[t_{a}\mapsto v], \tick\:C\:\mem_{a}\:t_{a}\:x\:v)
      }
    \end{prooftree}
  \]

  \[
    \begin{prooftree}
      \hypo{
        \begin{matrix}
          (e_{1}, C, \mem, t)
          \rightsquigarrow
          (\langle\lambda x.e_{\lambda}, C_{\lambda}\rangle, \mem_{\lambda}, t_{\lambda}) \\
          (e_{2}, C, \mem_{\lambda}, t_{\lambda})
          \rightsquigarrow
          (v, \mem_{a}, t_{a})                                                            \\
          (e_{\lambda}, (x, t_{a})\cons C_{\lambda}, \mem_{a}[t_{a}\mapsto v], \tick\:C\:\mem_{a}\:t_{a}\:x\:v)
          \rightsquigarrow
          (v', \mem',t')
        \end{matrix}
      }
      \infer[left label={App}]1{
      (e_{1}\:e_{2}, C, \mem, t)
      \rightsquigarrow
      (v', \mem',t')
      }
    \end{prooftree}
  \]

  \[
    \begin{prooftree}
      \infer[left label=LinkL]0{
      (\link{e_{1}}{e_{2}}, C, \mem, t)
      \rightsquigarrow
      (e_{1}, C, \mem, t)
      }
    \end{prooftree}\qquad
    \begin{prooftree}
      \hypo{
        \begin{matrix}
          (e_{1}, C, \mem, t)
          \rightsquigarrow
          (C', \mem', t')
        \end{matrix}
      }
      \infer[left label=LinkR]1{
      (\link{e_{1}}{e_{2}}, C, \mem, t)
      \rightsquigarrow
      (e_{2}, C', \mem', t')
      }
    \end{prooftree}
  \]

  \[
    \begin{prooftree}
      \hypo{
        \begin{matrix}
          (e_{1}, C, \mem, t)
          \rightsquigarrow
          (C', \mem', t') \\
          (e_{2}, C', \mem', t')
          \rightsquigarrow
          (V, \mem'', t'')
        \end{matrix}
      }
      \infer[left label=Link]1{
      (\link{e_{1}}{e_{2}}, C, \mem, t)
      \rightsquigarrow
      (V, \mem'', t'')
      }
    \end{prooftree}\qquad
    \begin{prooftree}
      \infer[left label=Empty]0{
      (\varepsilon, C, \mem, t)
      \rightsquigarrow
      (C, \mem, t)
      }
    \end{prooftree}\qquad
    \begin{prooftree}
      \hypo{C'=\modctx(C,M)}
      \infer[left label=ModID]1{
      (M, C, \mem, t)
      \rightsquigarrow
      (C', \mem, t)
      }
    \end{prooftree}
  \]

  \[
    \begin{prooftree}
      \infer[left label=LetEL]0{
      (\mathtt{let}\:x\:e_1\:e_2, C, \mem, t)
      \rightsquigarrow
      (e_{1}, C, \mem, t)
      }
    \end{prooftree}
  \]

  \[
    \begin{prooftree}
      \hypo{
        \begin{matrix}
          (e_{1}, C, \mem, t)
          \rightsquigarrow
          (v, \mem', t')
        \end{matrix}
      }
      \infer[left label=LetER]1{
      (\mathtt{let}\:x\:e_1\:e_2, C, \mem, t)
      \rightsquigarrow
      (e_{2}, (x, t')\cons C, \mem'[t'\mapsto v], \tick\:C\:\mem'\:t'\:x\:v)
      }
    \end{prooftree}
  \]

  \[
    \begin{prooftree}
      \infer[left label=LetML]0{
      (\mathtt{let}\:M\:e_{1}\:e_{2}, C, \mem, t)
      \rightsquigarrow
      (e_{1}, C, \mem, t)
      }
    \end{prooftree}\qquad
    \begin{prooftree}
      \hypo{
        \begin{matrix}
          (e_{1}, C, \mem, t)
          \rightsquigarrow
          (C', \mem', t')
        \end{matrix}
      }
      \infer[left label=LetMR]1{
      (\mathtt{let}\:M\:e_{1}\:e_{2}, C, \mem, t)
      \rightsquigarrow
      (e_{2}, (M, C')\cons C, \mem', t')
      }
    \end{prooftree}
  \]

  \[
    \begin{prooftree}
      \hypo{
        \begin{matrix}
          (e_{1}, C, \mem, t)
          \rightsquigarrow
          (v, \mem', t') \\
          (e_{2}, (x, t')\cons C, \mem'[t'\mapsto v], \tick\:C\:\mem'\:t'\:x\:v)
          \rightsquigarrow
          (C', \mem'', t'')
        \end{matrix}
      }
      \infer[left label=LetE]1{
      (\mathtt{let}\:x\:e_1\:e_2, C, \mem, t)
      \rightsquigarrow
      (C', \mem'', t'')
      }
    \end{prooftree}\quad
    \begin{prooftree}
      \hypo{
        \begin{matrix}
          (e_{1}, C, \mem, t)
          \rightsquigarrow
          (C', \mem', t') \\
          (e_{2}, (M, C')\cons C, \mem', t')
          \rightsquigarrow
          (C'', \mem'', t'')
        \end{matrix}
      }
      \infer[left label=LetM]1{
      (\mathtt{let}\:M\:e_{1}\:e_{2}, C, \mem, t)
      \rightsquigarrow
      (C'', \mem'', t'')
      }
    \end{prooftree}
  \]
  \caption{The concrete one-step reachability relation.}
  \label{fig:concreach}
\end{figure}

The complete definition for the relation is given in Fig. \ref{fig:concreach}.
Also, the equivalence of the relation with a reference interpreter is formalized in Coq.

\subsection{Collecting Semantics}

For program analysis, we need to define a collecting semantics that captures the strongest property we want to model.
In the case of modular analysis, we need to collect \emph{all} intermediate nodes in the proof tree when trying to prove what the initial configuration evaluates to.
Consider the case when $\link{e_1}{e_2}$ is evaluated under state $s$.
Since $e_2$ has free variables that are exported by $e_1$, separately analyzing $e_2$ will result in an incomplete proof tree.
What it means to separately analyze, then link two expressions $e_1$ and $e_2$ is to (1) compute what $e_1$ will export to $e_2$ (2) partially compute the proof tree for $e_2$, and (3) inject the exported context into the partial proof to complete the execution.

What should be the \emph{type} of the collecting semantics?
The analysis must keep track of all configurations that were reached along with the results computed from the intermediate configurations, thus it must be a set that collects all those elements.
Concretely, the collecting semantics $\sembracket{e}(s)$ of an expression $e$ evaluated under initial state $s$ must be a \emph{subset} of $(L\times R)\cup R$, when $L=\Expr\times\State{\Time}$ is the \textbf{l}eft-hand-side of $\rightsquigarrow$, and $R=L\cup\Result{\Time}$ is the \textbf{r}ight-hand-side.
Later on, when we link a context in $\Time_1$ with the semantics in $\Time_2$, we shall write $L_i$ for $\Expr\times\State{\Time_i}$, and $R_i$ for $L_i\cup\Result{\Time_i}$.
Also, we shall write $\ell$ for an element of $L$, and $\rho$ for an element of $R$.

\subsubsection{Formulating semantics in terms of a fixpoint}

To define a semantics that is computable, we must formulate the collecting semantics as a least fixed point of a monotonic function that maps an element of some CPO $D$ to $D$.
In our case, $D=\wp((L\times R)\cup R)$ as defined previously.
Defining the transfer function is straightforward from the definition of the reachability relation.

\begin{definition}[Transfer function]
  Given $A\subseteq (L\times R)\cup R$, define
  \[
    \mathsf{Step}(A)\triangleq
    \left\{\ell\rightsquigarrow\rho, \rho|
    A'\subseteq A\wedge\ell\in A\wedge
    \begin{prooftree}[center=true]
      \hypo{A'}\infer1{\ell\rightsquigarrow \rho}
    \end{prooftree}\right\}
  \]
\end{definition}

The $\mathsf{Step}$ function is naturally monotonic, as a ``cache'' $A$ that remembers more about the intermediate proof tree will derive more results than a cache that remembers less.
Now, because of Tarski's fixpoint theorem, we can formulate the collecting semantics in fixpoint form.
\begin{definition}[Concrete semantics]
  \[
    \sembracket{e}(s)\triangleq\mathsf{lfp}(\lambda X.\mathsf{Step}(X)\cup\{(e,s)\})
  \]
\end{definition}
For convenience, we shall write $\sembracket{e}(t)$ instead of $\sembracket{e}([],\varnothing,t)$.
\section{Concrete linking}

To prepare for modular analysis, we need to be able to paste together the semantics of $e_1$ and $e_2$ to obtain the semantics of $\link{e_1}{e_2}$.
Why do we need to define linking on the level of the concrete semantics?
This is because for separate analysis, $e_1$ and $e_2$ must be analyzed in separate abstract time domains $\ATime_1$ and $\ATime_2$, which are sound approximations of \emph{concrete} $\Time_1$ and $\Time_2$ domains.
To elaborate, since the abstract tick must be a sound approximation of the concrete tick, for the analysis to be sound the \emph{initial time} must approximate the concrete initial time.
If a single abstract time and concrete time domain is used, it means that the analysis of $e_2$ must start from an abstract time that approximates the time that $e_1$ exports to $e_2$.
This is against the idea of separate analysis; we want to analyze the behavior of $e_2$ without running $e_1$ beforehand.
Therefore, we need to define a way to link the concrete time domains that allows the analysis of $e_1$ and $e_2$ to approximate the concrete execution without looking at the final time of $e_1$.

Now assume that we have computed $\sembracket{e_1}(0_1)$ and $\sembracket{e_2}(0_2)$, when $0_i$ are the initial times in $\Time_i$.
What we want to define is a $\tick_+$ function on $\Time_1\times\Time_2$ that:
\begin{enumerate}
  \item Increments $(0_1,0_2)$ up to $(t_1,0_2)$, when $t_1\in\Time_1$ is the final timestamp of $\sembracket{e_1}(0_1)$.
  \item Increments $(t_1,0_2)$ up to $(t_1,t_2)$, when $t_2\in\Time_2$ is the largest timestamp that can be computed \emph{without} knowing about what $e_1$ exports to $e_2$.
\end{enumerate}

To satisfy the above constraints, the $\tick_+$ function has to use the $\tick_1$ function to increment the first timestamp when the first timestamp is less than $t_1$.
Also, in the case that the first timestamp is greater or equal to $t_1$, the second timestamp is incremented by $\tick_2$ under the context and memory that is \emph{removed} of the exported context.

What does it mean that the exported context should be \emph{removed}?
The second timestamp is assumed to be incremented separately, using $\tick_2$, under the empty context.
However, under the linked time $\Time_1\times\Time_2$, first $(e_1,[],\varnothing,(0_1,0_2))\rightsquigarrow(C_1,\mem_1,(t_1,0_2))$ is computed, and only then is $0_2$ incremented under $C_1,\mem_1$.
For $\tick_+$ to produce the same timestamps produced by $\tick_2$ under the empty initial conditions, $C_1$ has to be dug out from the bottom of the stack and $\mem_1$ must be filtered out.
Filtering out $\mem_2$ is easy to do; just ignore addresses with a timestamp different from $t_1$ in the first time component.
Digging out $C_2$ from the stack needs more consideration.

To determine what parts of the stack should be deleted, we need to be able to describe what $C$ will look like if it started from $C_2$, not from $[]$.
That is, we need to determine the injection operator $\inject{C_1}{C}$ that satisfies:
if $(e_2,0_2)\rightsquigarrow^*(e,C,\mem,t)$, then $(e_2,C_1,\varnothing,0_2)\rightsquigarrow^*(e,\inject{C_1}{C},\inject{C_1}{\mem},t)$ with $\tick_+$, when $\rightsquigarrow^*$ is the reflexive and transitive closure of $\rightsquigarrow$.
The notation $\inject{C_1}{\mem}$ means that the context $C_1$ is injected into all closures in $\mem$.

\begin{figure}[h!]
  \footnotesize
  \[
    \mapinject{C_{1}}{C_{2}}\triangleq
    \begin{cases}
      []                                                 & C_{2}=[]              \\
      (x, t)\cons\mapinject{C_{1}}{C'}                   & C_{2}=(x,t)\cons C'   \\
      (M, \inject{C_{1}}{C'})\cons\mapinject{C_{1}}{C''} & C_{2}=(M,C')\cons C''
    \end{cases}
    \qquad
    \inject{C_{1}}{C_{2}}\triangleq \mapinject{C_{1}}{C_{2}}\doubleplus C_{1}
  \]
  \caption{Definition of the injection operator $\inject{C_1}{C_2}$.}
  \label{fig:concinject}
\end{figure}

The definition for the injection operator in our simple language is more complicated than expected.
This is because when modules are bound to module identifiers under some imported context, the context that is bound \emph{automatically} includes that imported context.
This is a consequence of the design choice to exclude signatures.
In a language where signatures designate what variable bindings should be exported, the definition of the injection operator would be simply the list append operator $\doubleplus$.
However, in our language when the injection has to \emph{map} over all module bindings, the injection operator is defined in a mutually recursive manner; one that maps the injection over all bindings($\mapinject{C_1}{C_2}$) and one that actually appends the stacks together($\inject{C_1}{C_2}$).

Now, the definition for the deletion operator that \emph{digs out} the exported context can be naturally defined as the inverse operations of injection.
\begin{figure}[h!]
  \footnotesize
  \[
    \deletepre{C_{1}}{C_{2}}\triangleq
    \begin{cases}
      \deletepre{C_{1}'}{C_{2}'} & (C_{1},C_{2})=(C_{1}'\doubleplus[(x,t)],C_{2}'\doubleplus[(x,t)]) \\
      \deletepre{C_{1}'}{C_{2}'} & (C_{1},C_{2})=(C_{1}'\doubleplus[(M,C)],C_{2}'\doubleplus[(M,C)]) \\
      C_{2}                      & \text{otherwise}
    \end{cases}
  \]

  \[
    \deletemap{C_{1}}{C_{2}}\triangleq
    \begin{cases}
      []                                                 & C_{2}=[]               \\
      (x,t)\cons\deletemap{C_{1}}{C'}                    & C_{2}=(x,t):: C'       \\
      (M, \delete{C_{1}}{C'})\cons\deletemap{C_{1}}{C''} & C_{2}=(M, C')\cons C''
    \end{cases}
    \qquad
    \delete{C_{1}}{C_{2}}\triangleq \deletemap{C_{1}}{\deletepre{C_{1}}{C_{2}}}
  \]
  \caption{Definition of the deletion operators.}
  \label{fig:concdelete}
\end{figure}

The deletion operators satisfy $\deletepre{C_1}{(C_2\doubleplus C_1)}=C_2$, $\deletemap{C_1}{\mapinject{C_1}{C_2}}=C_2$, and $\delete{C_1}{\inject{C_1}{C_2}}=C_2$.

Now only the filter operation has to be defined for the total definition of the $\tick_+$ function.
Note that the linked time domain only uses timestamps of the form $(t,0_2)$ and $(t_1,t)$.
Therefore, we are actually considering a linked time on a \emph{subset} of $\Time_1\times\Time_2$.
For notational convenience, we write this subset as $\underline{\Time_1}\uplus\underline{\Time_2}$, when $\underline{\Time_1}\triangleq(\Time_1-\{t_1\})\times\{0_2\}$ and $\underline{\Time_2}\triangleq\{t_1\}\times\Time_2$.
The filter operation in $\underline{\Time_1}\uplus\underline{\Time_2}$ must determine whether a timestamp is a member of $\underline{\Time_1}$ or $\underline{\Time_2}$, and project the timestamps onto the corresponding domains.
\begin{figure}[h!]
  \footnotesize
  \[
    \filter_i(C)\triangleq
    \begin{cases}
      []                                   & C=[]                                              \\
      (x,t.i)\cons\filter_i(C')            & C=(x,t)\cons C'\wedge t\in\underline{\Time_i}     \\
      \filter_i(C')                        & C=(x,t)\cons C'\wedge t\not\in\underline{\Time_i} \\
      (M,\filter_i(C'))\cons\filter_i(C'') & C=(M, C')\cons C''
    \end{cases}
  \]
  \caption{Definition for the filter operations ($i=1,2$).}
  \label{fig:concfilter}
\end{figure}

From now on, we assume that all $(C,\mem,t)\in\State{\Time}$ satisfy the property that timestamps in $C$ and $\mem$ are strictly less than $t$.
Now we can give the definition of the linked $\tick$ function:
\begin{definition}[Concrete linking of time domains]
  Given $(\Time_1,\le_1,\tick_1)$ and $(\Time_2,\le_2,\tick_2)$,

  \begin{itemize}
    \item Define $\le_+$ as the lexicographic order on $\Time_1\times\Time_2$.
    \item Given $s_1=(C_1,\mem_1,t_2)\in\State{\Time_1}$, define the ${\tick_{+}}({s_1})$ function as:
          \[
            \tick_{+}({s_1})({C},\mem,{t},x,{v})\triangleq
            \begin{cases}
              (\tick_1\:\filter_1(C,\mem,t,x,v), 0_2)                     & t\in\underline{\Time_1} \\
              (t_1,\tick_2\:\filter_2(\delete{{C_1}}{C,\mem, {t},x,{v}})) & t\in\underline{\Time_2}
            \end{cases}
          \]
          when all timestamps in $C_1$ are lifted to $\underline{\Time_1}\uplus\underline{\Time_2}$.
  \end{itemize}

  Then we call the concrete time $(\underline{\Time_1}\uplus\underline{\Time_2},\le_+,\tick_{+}({s_1}))$ the linked time when $s_1$ is exported.
\end{definition}

We must prove that $\tick_+(s_1)$ indeed satisfies the properties described in the start of this section.
To formulate this intuition, we need to extend the injection operator to an operator $\rhd$ that injects a configuration from $\Time_1$ to a result in $\Time_2$.
\begin{definition}[Injection of a configuration : $\rhd$]
  $\:$

  Given ${s}=({C_1},{\mem_1},{t_1})\in\State{\Time_1}$ and ${r}=({V_2},{\mem_2},t_2)\in\Result{\Time_2}$,
  define $s\rhd m_2$ and $s\rhd r$ as:
  \[
    s\rhd m_2\triangleq
    \lambda t.
    \begin{cases}
      m_1(t.1)               & t\in\underline{\Time_1} \\
      \inject{C_1}{m_2(t.2)} & t\in\underline{\Time_2}
    \end{cases}
    \qquad
    s\rhd r\triangleq
    (\inject{C_1}{V_2},s\rhd m_2,t_2)
  \]
  assuming that all timestamps $t\in\Time_1$ is lifted to $(t,0_2)$ and all timestamps $t\in\Time_2$ is lifted to $(t_1,t)$.

  Furthermore, when $\ell=(e,s')\in L_2$, and $A\subseteq (L_2\times R_2)\cup R_2$, we define:
  \[
    s\rhd\ell\triangleq(e,s\rhd s')\qquad
    {s}\rhd{A}\triangleq\{s\rhd\rho|\rho\in A\}\cup\{s\rhd\ell\rightsquigarrow s\rhd\rho|\ell\rightsquigarrow\rho\in A\}
  \]
\end{definition}

We shall omit $s_1$ and simply call the linked $\tick$ function as $\tick_+$ when the exported state $s_1$ is clear from the context.
More specifically, it is to be understood that $\tick_+(s_1)$ is used when computing $\sembracket{e}(s_1\rhd s_2)$.
Then we can prove that the $\tick_+$ function is indeed \emph{well-defined}.

\begin{lem}[Injection preserves timestamps under linked time]
  \[
    \forall s\in\State{\Time_1},s'\in\State{\Time_2}:{s}\rhd{\sembracket{e}}({s'})\subseteq{\sembracket{e}}({s}\rhd{s'})
  \]
\end{lem}

Now, as promised, we present how to link the semantics to obtain the semantics under linked time.
To streamline the presentation, we introduce more notation that captures what is needed when pasting together separate parts of a linked expression.
First, we write $\underline{e}(s)\triangleq\{r|(e,s)\rightsquigarrow r\}$ to denote the final value $(e,s)$ evalates to.
Note that if $e$ is a module, $\underline{e}(s)$ is the state that $e$ exports.
Second, we write $\sembracket{e}(S)\triangleq\bigcup_{s\in S}\sembracket{e}(s)$.
This is used when $e_2$ imports $S=\underline{e_1}(s)$ from $e_1$.
Third, we write $\ell\rightsquigarrow P\triangleq\{\ell,\ell\rightsquigarrow\rho|\rho\in P\}$.
This is used when pasting together the initial configuration $\ell=(\link{e_1}{e_2},s)$ with the separately computed configurations.
Finally, we write $(e,S)\triangleq\{(e,s)|s\in S\}$.

\begin{definition}[Concrete linking operator]
  Given $e_1$, $e_2$, $s$, let $\Exp=\{s_1\rhd 0_2|s_1\in\underline{e_1}(s)\}$. Then:
  \begin{align*}
    \Link\:e_1\:e_2\:s & \triangleq\sembracket{e_1}(s)\cup\sembracket{e_2}(\Exp)\cup(\link{e_1}{e_2},s)\rightsquigarrow(\{(e_1,s)\}\cup(e_2,\Exp)\cup\underline{e_2}(\Exp))
  \end{align*}
  when all timestamps $t\in\Time_1$ are lifted to $(t,0_2)$.
\end{definition}

Then the following result follows directly from the \emph{definition} of the collecting semantics.

\begin{thm}[Concrete linking] Given $s\in\State{\Time_1}$ and another time domain $\Time_2$,
  \[
    \sembracket{\link{e_1}{e_2}}(s)=\Link\:e_1\:e_2\:s
  \]
  under $\tick_+$.
\end{thm}

\section{Abstract Semantics}

The abstract semantics is almost exactly the same as the concrete semantics, except for the fact that the memory domain is now a finite map from the abstract time domain to a \emph{set} of values.
Note we do not need to define the $\A{C}$, $\A{v}$, $\A{V}$ components, as they are \emph{exactly} their concrete counterparts.
They are simply $C$, $v$, $V$, parametrized by a different $\Time$.

\begin{figure}[h!]
  \centering
  \footnotesize
  \begin{tabular}{rccll}
    Abstract Time                & $\A{t}$  & $\in$ & $\ATime$                                                                                   \\
    Environment/Context          & $\A{C}$  & $\in$ & $\Ctx\ATime$                                                                               \\
    Value of expressions         & $\A{v}$  & $\in$ & $\Value\ATime$                                                                             \\
    Value of expressions/modules & $\A{V}$  & $\in$ & $\Value{\ATime}+\Ctx{\ATime}$                                                              \\
    Abstract Memory              & $\A\mem$ & $\in$ & $\AMem{\ATime} \triangleq \fin{\ATime}{\wp(\Value{\ATime})}$                               \\
    Abstract State               & $\A{s}$  & $\in$ & $\AState{\ATime} \triangleq \Ctx{\ATime}\times\Mem{\ATime}\times\ATime$                    \\
    Abstract Result              & $\A{r}$  & $\in$ & $\AResult{\ATime} \triangleq (\Value{\ATime}+\Ctx{\ATime})\times\AMem{\ATime}\times\ATime$ \\
  \end{tabular}
  \caption{Definition of the semantic domains.}
\end{figure}

First the abstract evaluation relation $\A{\rightsquigarrow}$ is defined.
Note that the update for the memory is now a weak update. That is,
\begin{definition}[Weak update]
  Given $\A{\mem}\in\AMem{\ATime}$, $\A{t}\in\ATime$, $\A{v}\in\Value{\ATime}$, define $\A{\mem}[\A{t}\A{\mapsto}\A{v}]$ as:
  \[
    \A{\mem}[\A{t}\A{\mapsto}\A{v}](\A{t'})\triangleq
    \begin{cases}
      \A{\mem}(\A{t})\cup\{\A{v}\} & (\A{t'}=\A{t})     \\
      \A{\mem}(\A{t'})             & (\text{otherwise})
    \end{cases}
  \]
\end{definition}

Also, for the abstract time, we do not enforce the existence of an ordering on the timestamps, but we do need a policy for performing the tick operation.
The abstract $\A\tick$ must simulate the $\tick$ function, so it must have the same type as $\tick$.
\begin{definition}[Abstract time]
  $(\ATime,\A{\tick})$ is an \emph{abstract time} when $\A{\tick}:\Ctx{\ATime}\rightarrow\AMem{\ATime}\rightarrow\ATime\rightarrow\ExprVar\rightarrow\Value{\ATime}\rightarrow\ATime$ is the policy for advancing the timestamp.
\end{definition}

The abstract one-step reachability relation is defined in Fig. \ref{fig:absreach}.
From this relation, we can define the abstract semantics in the same way as the concrete version.

\begin{figure}[h!]
  \begin{flushright}
    \fbox{$(e,\A{C},\A\mem,\A{t})\A\rightsquigarrow(\A{V},\A{\mem'},\A{t'})/(e',\A{C'},\A{\mem'},\A{t'})$}
  \end{flushright}
  \vspace{0pt} % -0.75em}
  \footnotesize
  \[
    \begin{prooftree}
      \hypo{\A{t}_{x}=\addr(\A{C},x)}
      \hypo{\A{v}\in\A\mem(\A{t}_{x})}
      \infer[left label=ExprID]2{
      (x, \A{C}, \A\mem, \A{t})
      \A\rightsquigarrow
      (\A{v}, \A\mem, \A{t})
      }
    \end{prooftree}\qquad
    \begin{prooftree}
      \infer[left label=Fn]0{
      (\lambda x.e, \A{C}, \A\mem, \A{t})
      \A\rightsquigarrow
      (\langle\lambda x.e, \A{C}\rangle, \A\mem, \A{t})
      }
    \end{prooftree}
  \]

  \[
    \begin{prooftree}
      \infer[left label={AppL}]0{
      (e_{1}\:e_{2}, \A{C}, \A\mem, \A{t})
      \A\rightsquigarrow
      (e_{1},\A{C}, \A\mem,\A{t})
      }
    \end{prooftree}\qquad
    \begin{prooftree}
      \hypo{
        \begin{matrix}
          (e_{1}, \A{C}, \A\mem, \A{t})
          \A\rightsquigarrow
          (\langle\lambda x.e_{\lambda}, \A{C}_{\lambda}\rangle, \A\mem_{\lambda}, \A{t}_{\lambda})
        \end{matrix}
      }
      \infer[left label={AppR}]1{
      (e_{1}\:e_{2}, \A{C}, \A\mem, \A{t})
      \A\rightsquigarrow
      (e_{2}, \A{C}, \A\mem_{\lambda}, \A{t}_{\lambda})
      }
    \end{prooftree}
  \]

  \[
    \begin{prooftree}
      \hypo{
        \begin{matrix}
          (e_{1}, \A{C}, \A\mem, \A{t})
          \A\rightsquigarrow
          (\langle\lambda x.e_{\lambda}, \A{C}_{\lambda}\rangle, \A\mem_{\lambda}, \A{t}_{\lambda}) \\
          (e_{2}, \A{C}, \A\mem_{\lambda}, \A{t}_{\lambda})
          \A\rightsquigarrow
          (v, \A\mem_{a}, \A{t}_{a})
        \end{matrix}
      }
      \infer[left label={AppBody}]1{
      (e_{1}\:e_{2}, \A{C,} \A\mem, \A{t})
      \A\rightsquigarrow
      (e_{\lambda}, (x, \A{t}_{a})\cons \A{C}_{\lambda}, \A\mem_{a}[\A{t}_{a}\A\mapsto \A{v}], \A\tick\:\A{C}\:\A\mem_{a}\:\A{t}_{a}\:x\:\A{v})
      }
    \end{prooftree}
  \]

  \[
    \begin{prooftree}
      \hypo{
        \begin{matrix}
          (e_{1}, \A{C}, \A\mem, \A{t})
          \A\rightsquigarrow
          (\langle\lambda x.e_{\lambda}, \A{C}_{\lambda}\rangle, \A\mem_{\lambda}, \A{t}_{\lambda}) \\
          (e_{2}, \A{C}, \A\mem_{\lambda}, \A{t}_{\lambda})
          \A\rightsquigarrow
          (\A{v}, \A\mem_{a}, \A{t}_{a})                                                            \\
          (e_{\lambda}, (x, \A{t}_{a})\cons \A{C}_{\lambda}, \A\mem_{a}[\A{t}_{a}\A\mapsto \A{v}], \A\tick\:\A{C}\:\A\mem_{a}\:\A{t}_{a}\:x\:\A{v})
          \A\rightsquigarrow
          (\A{v'}, \A{\mem'},\A{t'})
        \end{matrix}
      }
      \infer[left label={App}]1{
      (e_{1}\:e_{2}, \A{C}, \A\mem, \A{t})
      \A\rightsquigarrow
      (\A{v'}, \A{\mem'},\A{t'})
      }
    \end{prooftree}
  \]

  \[
    \begin{prooftree}
      \infer[left label=LinkL]0{
      (\link{e_{1}}{e_{2}}, \A{C}, \A\mem, \A{t})
      \A\rightsquigarrow
      (e_{1}, \A{C}, \A\mem, \A{t})
      }
    \end{prooftree}\qquad
    \begin{prooftree}
      \hypo{
        \begin{matrix}
          (e_{1}, \A{C}, \A\mem, \A{t})
          \A\rightsquigarrow
          (\A{C'}, \A{\mem'}, \A{t'})
        \end{matrix}
      }
      \infer[left label=LinkR]1{
      (\link{e_{1}}{e_{2}}, \A{C}, \A\mem, \A{t})
      \A\rightsquigarrow
      (e_{2}, \A{C'}, \A{\mem'}, \A{t'})
      }
    \end{prooftree}
  \]

  \[
    \begin{prooftree}
      \hypo{
        \begin{matrix}
          (e_{1}, \A{C}, \A\mem, \A{t})
          \A\rightsquigarrow
          (\A{C'}, \A{\mem'}, \A{t'}) \\
          (e_{2}, \A{C'}, \A{\mem'}, \A{t'})
          \A\rightsquigarrow
          (\A{V}, \A{\mem''}, \A{t''})
        \end{matrix}
      }
      \infer[left label=Link]1{
      (\link{e_{1}}{e_{2}}, \A{C}, \A\mem, \A{t})
      \A\rightsquigarrow
      (\A{V}, \A{\mem''}, \A{t''})
      }
    \end{prooftree}\qquad
    \begin{prooftree}
      \infer[left label=Empty]0{
      (\varepsilon, \A{C}, \A\mem, \A{t})
      \A\rightsquigarrow
      (\A{C}, \A\mem, \A{t})
      }
    \end{prooftree}
  \]

  \[
    \begin{prooftree}
      \hypo{\A{C'}=\modctx(\A{C},M)}
      \infer[left label=ModID]1{
      (M, \A{C}, \A\mem, \A{t})
      \A\rightsquigarrow
      (\A{C'}, \A\mem, \A{t})
      }
    \end{prooftree}\qquad
    \begin{prooftree}
      \infer[left label=LetEL]0{
      (\mathtt{let}\:x\:e_1\:e_2, \A{C}, \A\mem, \A{t})
      \A\rightsquigarrow
      (e_{1}, \A{C}, \A\mem, \A{t})
      }
    \end{prooftree}
  \]

  \[
    \begin{prooftree}
      \hypo{
        \begin{matrix}
          (e_{1}, \A{C}, \A\mem, \A{t})
          \A\rightsquigarrow
          (\A{v}, \A{\mem'}, \A{t'})
        \end{matrix}
      }
      \infer[left label=LetER]1{
      (\mathtt{let}\:x\:e_1\:e_2, \A{C}, \A\mem, \A{t})
      \A\rightsquigarrow
      (e_{2}, (x, \A{t'})\cons \A{C}, \A{\mem'}[\A{t'}\A\mapsto \A{v}], \A\tick\:\A{C}\:\A{\mem'}\:\A{t'}\:x\:\A{v})
      }
    \end{prooftree}
  \]

  \[
    \begin{prooftree}
      \infer[left label=LetML]0{
      (\mathtt{let}\:M\:e_{1}\:e_{2}, \A{C}, \A\mem, \A{t})
      \A\rightsquigarrow
      (e_{1}, \A{C}, \A\mem, \A{t})
      }
    \end{prooftree}\quad
    \begin{prooftree}
      \hypo{
        \begin{matrix}
          (e_{1}, \A{C}, \A\mem, \A{t})
          \A\rightsquigarrow
          (\A{C'}, \A{\mem'}, \A{t'})
        \end{matrix}
      }
      \infer[left label=LetMR]1{
      (\mathtt{let}\:M\:e_{1}\:e_{2}, \A{C}, \A\mem, \A{t})
      \A\rightsquigarrow
      (e_{2}, (M, \A{C'})\cons \A{C}, \A{\mem'}, \A{t'})
      }
    \end{prooftree}
  \]

  \[
    \begin{prooftree}
      \hypo{
        \begin{matrix}
          (e_{1}, \A{C}, \A\mem, \A{t})
          \A\rightsquigarrow
          (\A{v}, \A{\mem'}, \A{t'}) \\
          (e_{2}, (x, \A{t'})\cons \A{C}, \A{\mem'}[\A{t'}\A\mapsto \A{v}], \A\tick\:\A{C}\:\A{\mem'}\:\A{t'}\:x\:\A{v})
          \A\rightsquigarrow
          (\A{C'}, \A{\mem''}, \A{t''})
        \end{matrix}
      }
      \infer[left label=LetE]1{
      (\mathtt{let}\:x\:e_1\:e_2, \A{C}, \A\mem, \A{t})
      \A\rightsquigarrow
      (\A{C'}, \A{\mem''}, \A{t''})
      }
    \end{prooftree}
  \]

  \[
    \begin{prooftree}
      \hypo{
        \begin{matrix}
          (e_{1}, \A{C}, \A\mem, \A{t})
          \A\rightsquigarrow
          (\A{C'}, \A{\mem'}, \A{t'}) \\
          (e_{2}, (M, \A{C'})\cons \A{C}, \A{\mem'}, \A{t'})
          \A\rightsquigarrow
          (\A{C''}, \A{\mem''}, \A{t''})
        \end{matrix}
      }
      \infer[left label=LetM]1{
      (\mathtt{let}\:M\:e_{1}\:e_{2}, \A{C}, \A\mem, \A{t})
      \A\rightsquigarrow
      (\A{C''}, \A{\mem''}, \A{t''})
      }
    \end{prooftree}
  \]
  \caption{The abstract one-step reachability relation.}
  \label{fig:absreach}
\end{figure}

\begin{definition}[Transfer function]
  Given $\A{A}\subseteq (\A{L}\times \A{R})\cup\A{R}$, define
  \[
    \A{\mathsf{Step}}(\A{A})\triangleq
    \left\{\A\ell\A\rightsquigarrow\A\rho,\A\rho|
    \A{A'}\subseteq \A{A}\wedge\A{\ell}\in \A{A}\wedge
    \begin{prooftree}[center=true]
      \hypo{\A{A'}}\infer1{\A\ell\A\rightsquigarrow\A\rho}
    \end{prooftree}\right\}
  \]
\end{definition}
\begin{definition}[Abstract semantics]
  \[
    \A{\sembracket{e}}(\A{s})\triangleq\mathsf{lfp}(\lambda \A{X}.\A{\mathsf{Step}}(\A{X})\cup\{(e,\A{s})\})
  \]
\end{definition}

\section{Whole-program Analysis}
This section clarifies what we mean by that the abstract semantics is a \emph{sound approximation} of the concrete semantics.
Since the only values in our language are closures that pair code with a context, we can make a Galois connection between $\wp((L\times R)\cup R)$ and $\wp((\A{L}\times\A{R})\cup\A{R})$ given a function $\alpha:\Time\rightarrow\ATime$.

\begin{definition}[Extensions of abstraction]
  Given a function $\alpha:\Time\rightarrow\ATime$,
  \begin{itemize}
    \item Extend $\alpha$ to a function on $\Ctx{\Time}\rightarrow\Ctx{\ATime}$ by mapping $\alpha$ over all timestamps.
    \item Extend $\alpha$ to a function on $\Value{\Time}\rightarrow\Value{\ATime}$ by mapping $\alpha$ over all timestamps.
    \item Extend $\alpha$ to a function on $\Mem{\Time}\rightarrow\AMem{\ATime}$ by defining
          \[\alpha(\mem)\triangleq\bigcup_{t\in\mathsf{dom}(\mem)}[\alpha(t)\mapsto\{\alpha(\mem(t))\}]\]
    \item Extend $\alpha$ to a function on $\Result{\Time}\rightarrow\AResult{\ATime}$ by $\alpha(V,\mem,t)\triangleq(\alpha(V),\alpha(\mem),\alpha(t))$
    \item Extend $\alpha$ to a function on $L\rightarrow\A{L}$ by $\alpha(e,s)\triangleq(e,\alpha(s))$.
  \end{itemize}
\end{definition}

Then it is obvious that:
\begin{lem}[Galois connection]
  Given a function $\alpha:\Time\rightarrow\ATime$,
  \begin{itemize}
    \item Extend $\alpha$ by ${\alpha}(A)\triangleq\{\alpha(\rho)|\rho\in A\}\cup\{\alpha(\ell)\A\rightsquigarrow\alpha(\rho)|\ell\rightsquigarrow\rho\in A\}$.
    \item Define ${\gamma}$ by ${\gamma}(\A{A})\triangleq\{\rho|\alpha(\rho)\in\A{A}\}\cup\{\ell\rightsquigarrow\rho|\alpha(\ell)\A\rightsquigarrow\alpha(\rho)\in\A{A}\}$.
  \end{itemize}
  Then $\forall A\subseteq(L\times R)\cup R,\A{A}\subseteq(\A{L}\times\A{R})\cup\A{R}:{\alpha}(A)\subseteq\A{A}\Leftrightarrow A\subseteq{\gamma}(\A{A})$.
\end{lem}

The ordering between elements of $\wp((L\times R)\cup R)$ and $\wp((\A{L}\times\A{R})\cup\A{R})$ is the subset order, because currently the only thing we are abstracting is the \emph{time} component, which describes the control flow of the program.
That is, the abstract semantics can be viewed as a control flow graph of the program, with the notion of ``program points'' described by $\A\rho\in \A{R}$ and the edges described by $\A\rightsquigarrow$.
Then all we need to show is that the abstract semantics overapproximates the concrete semantics, i.e, that $\sembracket{e}(s)\subseteq\gamma(\A{\sembracket{e}}(\alpha(s)))$.
However, it is not the case that this holds for arbitrary $\alpha$.
It must be that, as emphasized constantly in the previous sections, that $\A\tick$ is a sound approximation of $\tick$ with respect to $\alpha$.

\begin{definition}[Tick-approximating abstraction]
  Given a concrete time $(\Time,\le,\tick)$ and an abstract time $(\ATime, \A\tick)$, a function $\alpha:\Time\rightarrow\ATime$ is said to be \emph{tick-approximating} if:
  \[
    \forall C,\mem,x,t,v:\alpha(\tick\:C\:\mem\:x\:t\:v)=\A\tick\:\alpha(C)\:\alpha(\mem)\:x\:\alpha(t)\:\alpha(v)
  \]
\end{definition}

Now we can prove that:
\begin{thm}[Soundness]
  Given a tick-approximating $\alpha:\Time\rightarrow\ATime$,
  \[
    \forall s\in\State{\Time}:\sembracket{e}(s)\subseteq\gamma(\A{\sembracket{e}}(\alpha(s)))
  \]
\end{thm}

What's not obvious is that if the abstract time domain is finite, the analysis is guaranteed to terminate.
Since bindings for modules also exist in the stack $C$, showing that the state space given a finite $\ATime$ is finite is nontrivial.
However, since the \emph{syntax} of the program constrains how $C$ looks like, we can prove that:

\begin{thm}[Finiteness of time implies finiteness of abstraction]
  If $\ATime$ is finite,
  \[
    \forall e,\A{s}: |\A{\sembracket{e}}(\A{s})|<\infty
  \]
\end{thm}

\section{Separate Analysis}

\subsection{Addition of time domains}
For separate analysis, we need to define the linking operators in a way that soundly approximates the concrete version of linking.
Note that in concrete linking, the time domains were linked based on the fact that the timestamps are ordered by a total order.
Remember that the filtering operation determined whether the timestamp came \emph{before} or \emph{after} linking by comparing the first time component with the \emph{final} time before linking.
In the abstract semantics, such an approach is impossible, since the abstract timestamps do not preserve the order of the concrete timestamps.
Thus, in the abstract semantics, the linked timestamp must live in $\ATime_1+\ATime_2$.
The intuition is that the timestamps before linking and after linking is determined by their membership in each time domain.

Then the filtering operation for the context can naturally be defined as in Fig. \ref{fig:absfilter}, and the definition for the added time domain can be given.
\begin{figure}[h!]
  \footnotesize
  \[
    \A\filter_i(\A{C})\triangleq
    \begin{cases}
      []                                               & \A{C}=[]                                                \\
      (x,\A{t})\cons\A\filter_i(\A{C'})                & \A{C}=(x,\A{t})\cons \A{C'}\wedge \A{t}\in\A\Time_i     \\
      \A\filter_i(\A{C'})                              & \A{C}=(x,\A{t})\cons \A{C'}\wedge \A{t}\not\in\A\Time_i \\
      (M,\A\filter_i(\A{C'}))\cons\A\filter_i(\A{C''}) & \A{C}=(M, \A{C'})\cons \A{C''}
    \end{cases}
  \]
  \caption{Definition of the abstract filter operation ($i=1,2$).}
  \label{fig:absfilter}
\end{figure}

\begin{definition}[Addition of time domains]
  Let $(\ATime_1,\A\tick_1)$ and $(\ATime_2,\A\tick_2)$ be two abstract time domains.
  Given $\A{s}_1=(\A{C}_1,\A\mem_1,\A{t}_1)\in\AState{\ATime_1}$, define the $\A{\tick}_+(\A{s}_1)$ function as:
  \[
    \A\tick_{+}(\A{s}_1)(\A{C},\A\mem,\A{t},x,\A{v})\triangleq
    \begin{cases}
      \A{\tick}_1\:\A\filter_1(\A{C},\A\mem,\A{t},x,\A{v})                   & \A{t}\in\ATime_1 \\
      \A{\tick}_2\:\A\filter_2(\delete{\A{C}_1}{\A{C},\A\mem,\A{t},x,\A{v}}) & \A{t}\in\ATime_2
    \end{cases}
  \]

  Then we call the abstract time $(\ATime_1+\ATime_2,\A\tick_{+}(\A{s}_1))$ the linked time when $\A{s}_1$ is exported.
\end{definition}

Now the rest flows analogously to concrete linking.
First the injection operator that injects the exported state to the next time must be defined.

\begin{definition}[Injection of a configuration : $\A\rhd$]
  $\:$

  Given $\A{s}=(\A{C}_1,\A{\mem}_1,\A{t}_1)\in\AState{\ATime_1}$ and $\A{r}=(\A{V}_2,\A{\mem}_2,\A{t}_2)\in\AResult{\ATime_2}$,
  let $\A{s}\A\rhd \A{\mem}_2$ and $\A{s}\A\rhd \A{r}$:
  \[
    \A{s}\A\rhd\A{\mem}_2\triangleq
    \lambda \A{t}.
    \begin{cases}
      \A{\mem}_1(\A{t})                   & \A{t}\in\ATime_1 \\
      \inject{\A{C}_1}{\A{\mem}_2(\A{t})} & \A{t}\in\ATime_2
    \end{cases}
    \qquad
    \A{s}\A\rhd \A{r}\triangleq
    (\inject{\A{C}_1}{\A{V}_2},\A{s}\A\rhd \A{\mem}_2,\A{t}_2)
  \]

  Furthermore, when $\A\ell=(e,\A{s'})\in \A{L}_2$, and $\A{A}\subseteq (\A{L}_2\times \A{R}_2)\cup \A{R}_2$, we define:
  \[
    \A{s}\A\rhd\A\ell\triangleq(e,\A{s}\rhd \A{s'})\qquad
    \A{s}\A\rhd\A{A}\triangleq\{\A{s}\A\rhd\A\rho|\A\rho\in \A{A}\}\cup\{\A{s}\A\rhd\A\ell\A\rightsquigarrow \A{s}\A\rhd\A\rho|\A\ell\A\rightsquigarrow\A\rho\in \A{A}\}
  \]
\end{definition}

Then in the same manner as concrete linking, we have that:

\begin{lem}[Injection preserves timestamps under added time]
  \[
    \forall \A{s}\in\AState{\ATime_1},\A{s'}\in\AState{\ATime_2}:\A{s}\A\rhd{\A{\sembracket{e}}}(\A{s'})\subseteq\A{\sembracket{e}}(\A{s}\A\rhd\A{s'})
  \]
\end{lem}

We must also define the addition operator that recovers the semantics of the linked expression $e_2$ from the exported state $\A{s_1}$ and the \emph{separately} analyzed semantics of $e_2$.

\begin{definition}[Addition between exported configurations and separately analyzed results]
  $\:$

  Let $\A{s}_1$ be a configuration in $\ATime_1$, and let $\A{A}_2=\A{\sembracket{e}}(\A{s'})$ be the semantics of $e$ under $(\ATime_2,\A\tick_2)$.
  Define the ``addition'' between $\A{s}_1$ and $\A{A}_2$ as:
  \[
    \A{s}_1\oplus\A{A}_2\triangleq\mathsf{lfp}(\lambda\A{X}.\A{\mathsf{Step}}(\A{X})\cup(\A{s}_1\A\rhd\A{A}_2))
  \]
\end{definition}

Then because of the previous lemma, it is obvious that:
\begin{lem}[Addition of semantics equals semantics under added time]
  \[
    \A{s}\oplus\A{\sembracket{e}}(\A{s'}) = \A{\sembracket{e}}(\A{s}\A\rhd\A{s'})
  \]
\end{lem}

\subsection{Separating soundness}
The only thing that remains is the formulation of soundness between $\sembracket{\link{e_1}{e_2}}(s)$ under the linked time $(\underline{\Time_1}\uplus\underline{\Time_2},\le_+,\tick_{+}(s_1))$, when $s_1$ is the exported context, and the abstract semantics.

The tricky part is in the time $(t_1,0_2)$.
It is represented by \emph{both} $\alpha_1(t_1)\in\ATime_1$ and $\alpha_2(0_2)\in\ATime_2$, when $\alpha_1:\Time_1\rightarrow\ATime_1$ and $\alpha_2:\Time_2\rightarrow\ATime_2$ are tick-approximating.
Therefore, we cannot make a tick-approximating function between $\underline{\Time_1}\uplus\underline{\Time_2}$ and $\ATime_1+\ATime_2$.
Instead, we define a function $\alpha_+:\underline{\Time_1}\uplus\underline{\Time_2}\rightarrow\ATime_1+\ATime_2$ by using $\alpha_1$ and $\alpha_2$ which is not tick-approximating on the whole domain but is sound for all timestamps $t=(t_1,\_)$.
That is, we will define $\alpha_+$ so that the following holds:
\[
  \forall t\in\Time_2,C,\mem,x,v:\alpha_+(\tick_+\:C\:\mem\:(t_1,t)\:x\:v)=\A\tick_+\:\alpha_+(C)\:\alpha_+(\mem)\:\alpha_+(t_1,t)\:x\:\alpha_+(v)
\]

Fortunately, such an $\alpha_+$ is easy to find.
\begin{lem}[Linked abstraction]
  Let $s_1=(C_1,\mem_1,t_1)\in\State{\Time_1}$, and let $\alpha_1:\Time_1\rightarrow\ATime_1$.
  Also, let $\alpha_2:\Time_2\rightarrow\ATime_2$ be a tick-approximating abstraction.
  Now define $\alpha_+:\underline{\Time_1}\uplus\underline{\Time_2}\rightarrow\ATime_1+\ATime_2$ as:
  \[
    \alpha_+(t)\triangleq
    \begin{cases}
      \alpha_1(t.1) & t\in\underline{\Time_1} \\
      \alpha_2(t.2) & t\in\underline{\Time_2}
    \end{cases}
  \]
  Then $\alpha_+$ is tick-approximating on $\underline{\Time_2}$ between $(\underline{\Time_1}\uplus\underline{\Time_2},\le_+,\tick_+(s_1))$ and $(\ATime_1+\ATime_2,\A\tick_+(\alpha_1(s_1)))$.
\end{lem}

Since we gave up tick-approximation for the times before linking, we need to \emph{separate} the problem of finding a sound approximation of $\sembracket{e_1}(s)$ and finding a sound approximation of $\sembracket{e_2}(\Exp)$.

Finding a sound approximation of $\sembracket{e_1}(s)$ is easy.
From the results of the previous section, if we have a tick-approximating $\alpha_1$ between $\Time_1$ and $\ATime_1$, $\A{\sembracket{e_1}}(\alpha_1(s))$ is automatically a sound approximation.
The problem of finding a sound approximation for $\sembracket{e_2}(\Exp)$ is also easy if we have a sound approximation $\A\Exp$ of $\Exp$ that satisfies $\alpha_1(\Exp)\subseteq\A\Exp$.
Since $\alpha_1(s)\in\A\Exp$ for all $s\in\Exp$, if we merge $\A{s}\oplus\A{\sembracket{e_2}}(\A{0}_2)$ for all $\A{s}\in\A\Exp$, $\alpha_+(\sembracket{e_2}(\Exp))$ will be contained in the merged cache.
That is, if we write $\A{\Exp}\oplus\A{A}\triangleq\bigcup_{\A{s}\in\A\Exp}\A{s}\oplus\A{A}$, we have:
\begin{lem}[Separation of soundness]
  Given $s\in\State{\Time_1}$ and $\A\Exp\subseteq\AState{\ATime_1}$, assume:
  \begin{itemize}
    \item There exists an $\alpha_1:\Time_1\rightarrow\ATime_1$ satisfying $\alpha_1(s)\in\A{\Exp}$.
    \item There exists a time-approximating $\alpha_2:\Time_2\rightarrow\ATime_2$.
  \end{itemize}

  Then $\alpha_+(\sembracket{e_2}(s\rhd0_2))\subseteq\A\Exp\oplus\A{\sembracket{e_2}}(\A{0}_2)$.
\end{lem}

\subsection{Soundness of separate analysis}
Now, we may define the abstract linking operator that soundly approximates the concrete linking operator, using the same notation as in concrete linking.
\begin{definition}[Abstract linking operator]
  Given $e_1$, $e_2$, $\A{s}$, let $\A\Exp=\{\A{s}_1\A\rhd\A{0}_2|\A{s}_1\in\A{\underline{e_1}}(\A{s})\}$. Then:
  \[\A\Link\:e_1\:e_2\:\A{s}\triangleq\A{\sembracket{e_1}}(\A{s})\cup\A{\sembracket{e_2}}(\A\Exp)\cup(\link{e_1}{e_2},\A{s})\A\rightsquigarrow(\{(e_1,\A{s})\}\cup(e_2,\A\Exp)\cup\A{\underline{e_2}}(\A\Exp))\]
\end{definition}
Note that $\A{\sembracket{e_2}}(\A\Exp)$ can be computed by $\A{\underline{e_1}}(\A{s})\oplus\A{\sembracket{e_2}}(\A{0}_2)$, hence the analysis is separate.
Now we want to show that the abstract linking operation is a sound approximation of concrete linking.
However, as emphasized in the previous subsection, the statement of soundness cannot be achieved through just a single concretization function.
Since abstract linking approximates its concrete counterpart \emph{separately}, we need to concretize the part \emph{before} linking and \emph{after} linking separately.

\begin{thm}[Abstract linking]
  Let $\Time_i(i=1,2)$ be two concrete times, and let $\ATime_i(i=1,2)$ be two abstract times.
  Let $\alpha_i:\Time_i\rightarrow\ATime_i(i=1,2)$ be tick-approximating, and let $\A{s}=\alpha_1(s)$ approximate the initial state.
  Then, $\A\Link\:e_1\:e_2\:\A{s}$ is a sound approximation of $\Link\:e_1\:e_2\:s$.
  That is:
  \[\Link\:e_1\:e_2\:s\subseteq\gamma_1(\A{\sembracket{e_1}}(\A{s}))\cup\gamma_+(\A{\sembracket{e_2}}(\A\Exp)\cup(\link{e_1}{e_2},\A{s})\A\rightsquigarrow(\{(e_1,\A{s})\}\cup(e_2,\A\Exp)\cup\A{\underline{e_2}}(\A\Exp)))\]
  when the Galois pairs of $\alpha_1$ and $\alpha_+$, $\gamma_1$ and $\gamma_+$, are defined as in section 5.
\end{thm}

All is fine for linking two expressions.
The approximation for the exporting expression comes directly from the abstract semantics, and the approximation for the importing expression comes from linking the exporting set with the separately analyzed results.
However, the above theorem is not strong enough for linking more than two expressions.
This is because $\A\Link\:e_1\:e_2\:\A{s}$ does \emph{not} equal $\A{\sembracket{\link{e_1}{e_2}}}(\A{s})$, as $\A\tick_+$ cannot leap between $\ATime_1$ and $\ATime_2$.
Thus, $\A\Link\:\link{e_1}{e_2}\:e_3\:\A{s}$ does not mean that the semantics for $\link{e_1}{e_2}$ is computed separately.
Also, $\A\Link\:e_1\:\link{e_2}{e_3}\:\A{s}$ does not help much, since computing $\A{\sembracket{\link{e_2}{e_3}}}(\A{0})$ will be stuck before even reaching $e_3$.
To clarify on how to link an \emph{arbitrary} number of modules, we state the following theorem:
\begin{thm}[Compositionality]
  Given a sequence $\{e_n\}_{n\ge 0}$ and initial condition $s\in\State{\Time_0}$,

  \begin{itemize}
    \item Let $\ATime_n$ be abstract times connected with the concrete times by tick-approximating $\alpha_n$.
    \item Let the linked expressions $l_n$ be $l_0\triangleq e_0$, $l_{n+1}\triangleq\link{l_n}{e_{n+1}}$, and let $t_n$ be the final time of $\sembracket{l_n}(s)$.
    \item Define the linked abstraction functions $\alpha^{n}_+$ as:
          \[
            \alpha^0_+\triangleq\alpha_0
            \qquad
            \alpha^{n+1}_+(t)\triangleq
            \begin{cases}
              \alpha^n_+(t.1)   & t.1\neq t_n \\
              \alpha_{n+1}(t.2) & t.1=t_n
            \end{cases}
          \]
    \item Let $\A{s}=\alpha_0(s)$, and define $\A\Exp_n$ and $\A\Imp_n$ as:
          \[
            \A\Imp_0\triangleq\A{\sembracket{e_0}}(\A{s})\qquad
            \A\Exp_0\triangleq\{\A{s}_0\A\rhd\A{0}_1|\A{s}_0\in\A{\underline{e_0}}(\A{s})\}\qquad
            \A\Exp_{n}\triangleq\{\A{s}_n\A\rhd\A{0}_{n+1}|\A{s}_{n}\in\A{\underline{e_{n}}}(\A\Exp_{n-1})\}
          \]
          \[
            \A\Imp_{n+1}\triangleq\A{\sembracket{e_{n+1}}}(\A\Exp_n)\cup(l_{n+1},\A{s})\A\rightsquigarrow(\{(l_n,\A{s})\}\cup(e_{n+1},\A\Exp_n)\cup\A{\underline{e_{n+1}}}(\A\Exp_{n}))
          \]
  \end{itemize}

  Then:
  \[
    \sembracket{l_n}(s)\subseteq\bigcup_{i=0}^{n}{\gamma^i_+(\A\Imp_i)}
  \]
\end{thm}

What the above theorem means is that there exists a concrete $\tick$ function that can be covered separately by analyzing each component based only on the approximation of the exported context.
The fact that the analysis $\A\Imp_n$ can be computed without actually computing the final times $t_n$ is why this analysis can be called separate.
\bibliographystyle{ACM-Reference-Format}
\bibliography{citations}
\end{document}
%%% Local Variables: 
%%% coding: utf-8
%%% mode: latex
%%% TeX-engine: xetex
%%% End:
