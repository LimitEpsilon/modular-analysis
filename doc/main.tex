%! TEX program = xelatex
\documentclass[acmsmall,review]{acmart}\settopmatter{printfolios=true,printccs=false,printacmref=false}

%%% Typesetting for listings
\usepackage{listings}

\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{ltblue}{rgb}{0,0.4,0.4}
\definecolor{dkviolet}{rgb}{0.3,0,0.5}

%%% lstlisting coq style (inspired from a file of Assia Mahboubi)
\lstdefinelanguage{Coq}{
    % To insert blank lines, write %
    escapechar=\%,
    % Anything betweeen $ becomes LaTeX math mode
    mathescape=true,
    % Comments may or not include Latex commands
    texcl=false, 
    % Vernacular commands
    morekeywords=[1]{Section, Module, End, Require, Import, Export, Include,
        Variable, Variables, Parameter, Parameters, Axiom, Hypothesis,
        Hypotheses, Notation, Local, Tactic, Reserved, Scope, Open, Close,
        Bind, Delimit, Definition, Let, Ltac, Fixpoint, CoFixpoint, Add,
        Morphism, Relation, Implicit, Arguments, Unset, Contextual,
        Strict, Prenex, Implicits, Inductive, CoInductive, Record,
        Structure, Canonical, Coercion, Context, Class, Global, Instance,
        Program, Infix, Theorem, Lemma, Corollary, Proposition, Fact,
        Remark, Example, Proof, Goal, Save, Qed, Defined, Hint, Resolve,
        Rewrite, View, Search, Show, Print, Printing, All, Eval, Check,
        Projections, inside, outside, Def},
    % Gallina
    morekeywords=[2]{forall, exists, exists2, fun, fix, cofix, struct,
        match, with, end, as, in, return, let, if, is, then, else, for, of,
        nosimpl, when},
    % Sorts
    morekeywords=[3]{Type, Prop, Set, true, false, option},
    % Various tactics, some are std Coq subsumed by ssr, for the manual purpose
    morekeywords=[4]{pose, set, move, case, elim, apply, clear, hnf,
        intro, intros, generalize, rename, pattern, after, destruct,
        induction, using, refine, inversion, injection, rewrite, congr,
        unlock, compute, ring, field, fourier, replace, fold, unfold,
        change, cutrewrite, simpl, have, suff, wlog, suffices, without,
        loss, nat_norm, assert, cut, trivial, revert, bool_congr, nat_congr,
        symmetry, transitivity, auto, split, left, right, autorewrite},
    % Terminators
    morekeywords=[5]{by, done, exact, reflexivity, tauto, romega, omega,
        assumption, solve, contradiction, discriminate},
    % Control
    morekeywords=[6]{do, last, first, try, idtac, repeat},
    % Comments delimiters, we do turn this off for the manual
    morecomment=[s]{(*}{*)},
    % Spaces are not displayed as a special character
    showstringspaces=false,
    % String delimiters
    morestring=[b]",
    morestring=[d],
    % Size of tabulations
    tabsize=3,
    % Enables ASCII chars 128 to 255
    extendedchars=false,
    % Case sensitivity
    sensitive=true,
    % Automatic breaking of long lines
    breaklines=false,
    % Default style fors listings
    basicstyle=\small,
    % Position of captions is bottom
    captionpos=b,
    % flexible columns
    columns=[l]flexible,
    % Style for (listings') identifiers
    identifierstyle={\ttfamily\color{black}},
    % Style for declaration keywords
    keywordstyle=[1]{\ttfamily\color{dkviolet}},
    % Style for gallina keywords
    keywordstyle=[2]{\ttfamily\color{dkgreen}},
    % Style for sorts keywords
    keywordstyle=[3]{\ttfamily\color{ltblue}},
    % Style for tactics keywords
    keywordstyle=[4]{\ttfamily\color{dkblue}},
    % Style for terminators keywords
    keywordstyle=[5]{\ttfamily\color{dkred}},
    %Style for iterators
    %keywordstyle=[6]{\ttfamily\color{dkpink}},
    % Style for strings
    stringstyle=\ttfamily,
    % Style for comments
    commentstyle={\ttfamily\color{dkgreen}},
    %moredelim=**[is][\ttfamily\color{red}]{/&}{&/},
    literate=
    {\\forall}{{\color{dkgreen}{$\forall\;$}}}1
    {\\exists}{{$\exists\;$}}1
    {<-}{{$\leftarrow\;$}}1
    {=>}{{$\Rightarrow\;$}}1
    {==}{{\code{==}\;}}1
    {==>}{{\code{==>}\;}}1
    %    {:>}{{\code{:>}\;}}1
    {->}{{$\rightarrow\;$}}1
    {<->}{{$\leftrightarrow\;$}}1
    {<==}{{$\leq\;$}}1
    {\#}{{$^\star$}}1 
    {\\o}{{$\circ\;$}}1 
    {\@}{{$\cdot$}}1 
    {\/\\}{{$\wedge\;$}}1
    {\\\/}{{$\vee\;$}}1
    {++}{{\code{++}}}1
    {~}{{\ }}1
    {\@\@}{{$@$}}1
    {\\mapsto}{{$\mapsto\;$}}1
    {\\hline}{{\rule{\linewidth}{0.5pt}}}1
    %
}[keywords,comments,strings]

%%% Citation style
\citestyle{acmauthoryear}

%%% Math settings
\usepackage{amsthm,mathtools}
\theoremstyle{definition}
\newtheorem{defn}{Definition}[section]
\newtheorem{example}{Example}[section]
\theoremstyle{plain}
\newtheorem{lem}{Lemma}[section]
\newtheorem{thm}{Theorem}[section]
\newtheorem{cor}{Corollary}[section]

%%% PL constructs
\usepackage{galois}
\usepackage{ebproof}
\ebproofset{left label template=\textsc{[\inserttext]}}
\ebproofset{center=false}

%%% Custom commands
\newcommand*{\vbar}{|}
\newcommand*{\finto}{\xrightarrow{\text{\textrm{fin}}}}
\newcommand*{\istype}{\mathrel{â©´}}
\newcommand*{\ortype}{\mathrel{|}}
\newcommand*{\cons}{::}
\newcommand*{\pset}{\mathcal{P}}
\newcommand*{\preall}[2][black]{\prescript{\textcolor{#1}{\forall}}{}{#2}}
\newcommand*{\prexists}[2][black]{\prescript{\textcolor{#1}{\exists}}{}{#2}}

\def\ovbarw{1.2mu}
\def\ovbarh{1}
\def\equivadjust{-1em}
\newcommand*{\ovbar}[1]{\mkern \ovbarw\overline{\mkern-\ovbarw{\smash{#1}\scalebox{1}[\ovbarh]{\vphantom{i}}}\mkern-\ovbarw}\mkern \ovbarw}
\newcommand*{\A}[1]{\prescript{\circ}{}{#1}}
\newcommand*{\Abs}[1]{{#1}^{\#}}
\newcommand*{\Expr}{\mathsf{Expr}}
\newcommand*{\ExprVar}{\mathsf{Var}}
\newcommand*{\Module}{\mathsf{Module}}
\newcommand*{\ModVar}{\mathsf{ModVar}}
\newcommand*{\Time}{\mathbb{T}}
\newcommand*{\ATime}{\A{\Time}}
\newcommand*{\Ctx}{\mathsf{Ctx}}
\newcommand*{\Value}{\mathsf{Val}}
\newcommand*{\Mem}{\mathsf{Mem}}
\newcommand*{\Left}{\mathsf{Left}}
\newcommand*{\Right}{\mathsf{Right}}
\newcommand*{\Sig}{\mathsf{Sig}}
\newcommand*{\mem}{m}
\newcommand*{\AMem}{\A{\mathsf{Mem}}}
\newcommand*{\State}{\mathsf{State}}
\newcommand*{\AState}{\A{\mathsf{State}}}
\newcommand*{\Result}{\mathsf{Result}}
\newcommand*{\AResult}{\A{\mathsf{Result}}}
\newcommand*{\Tick}{\mathsf{Tick}}
\newcommand*{\lfp}{\mathsf{lfp}}
\newcommand*{\Step}{\mathsf{Step}}
\newcommand*{\semarrow}{\rightsquigarrow}
\newcommand*{\asemarrow}{\A{\rightsquigarrow}}
\newcommand*{\synlink}{\rtimes}
\newcommand*{\semlink}{\mathbin{\rotatebox[origin=c]{180}{$\propto$}}}
\newcommand*{\link}[2]{{#1}\rtimes{#2}}
\newcommand*{\mt}{\mathsf{empty}}
\newcommand*{\valid}{\mathsf{valid}}
\newcommand*{\Path}{\mathsf{Path}}
\newcommand*{\equivalent}[1][black]{\textcolor{#1}{\sim}}

\newcommand*{\doubleplus}{\ensuremath{\mathbin{+\mkern-3mu+}}}
\newcommand*{\project}{\text{\texttt{:>} }}
\newcommand*{\sembracket}[1]{\lBrack{#1}\rBrack}
\newcommand*{\fin}[2]{{#1}\xrightarrow{\text{fin}}{#2}}
\newcommand*{\addr}{\mathsf{addr}}
\newcommand*{\tick}{\mathsf{tick}}
\newcommand*{\modctx}{\mathsf{ctx}}
\newcommand*{\inject}[2]{{#2}\langle{#1}\rangle}
\newcommand*{\delete}[2]{{#2}{\langle{#1}\rangle}^{-1}}
\newcommand*{\filter}{\mathsf{filter}}
\newcommand*{\Let}{\mathtt{let}}

\title{A Syntax-Guided Framework for Modular Analysis}
\author{Joonhyup Lee}
\begin{document}
\maketitle
\section{Introduction}
We make the following observations:
\begin{itemize}
  \item Most code that static analyzers deal with is \emph{open code} that uses external values.
  \item Those external values are defined in a different \emph{scope} from the code of interest.
  \item The different scopes are organized in term of \emph{modules}.
  \item The modules are interfaced through \emph{module names}.
\end{itemize}
Therefore, experts who write realistic analyzers are immediately faced with the problem of \emph{closing} open code.
Especially, in the case when external values are not defined in the same language, the semantics of such values must be \emph{modelled}, either by the analysis expert or by the user of the analyzer.
Since we cannot possibly model all such cases in one try, attempts to close open code must be a never-ending race of fractional advances.

If we force the analyzers to output results only in the fortunate case that all external values has already been modelled, we end up unnecessarily recomputing each time we fail to close completely.
We claim that this is undesirable.
The analyzer, upon meeting an open term, may just ``cache'' what has been computed already and ``pick up'' from there when that open term is resolved.
The problem is: can we model such a computation {mathematically}?
Therefore, we aim to define semantics for terms that have been fractionally closed, and prove that \emph{closing} the \emph{fractionally closed semantics} is equal to the \emph{closed semantics}.

\subsection{Separate Static Analyis}
To illustrate what we mean by the ``fractionally closed semantics'', we first give a concrete example.
\begin{center}
  \begin{tabular}{ccc}
    \begin{minipage}{0.3\linewidth}
      \begin{lstlisting}[language=Coq]
(* Module M *)
let x = 1
%
%
%
    \end{lstlisting}
    \end{minipage} &
    \begin{minipage}{0.3\linewidth}
      \begin{lstlisting}[language=Coq]
(* Module F *)
let fix fact n =
  if n <= 0 then 1
  else n * fact (n - 1)
    \end{lstlisting}
    \end{minipage}      &
    \begin{minipage}{0.3\linewidth}
      \begin{lstlisting}[language=Coq]
(* Client code *)
Include M
Include F
(F.fact 100) + M.x
    \end{lstlisting}
    \end{minipage}
  \end{tabular}
\end{center}

Above, we have a piece of code that adds an integer \texttt{x} exported by the module \texttt{M} to the result of $100!$.
Given this program, a compiler that supports separate compilation produces object files that can be linked with different implementations of the module \texttt{M}.
What we desire is some sort of semantic object for static analyzers that corresponds to such object files.
Since object files represent programs with unresolved variable references, we say that they are fractionally closed.

Defining separate analysis results and linking allows discussion for a wide variety of cases.
Say that the client code is analyzed with \emph{only} assuming the implementation for \texttt{F.fact}.
Thus, the analysis result, if well defined, will contain the information that the unresolved variable \texttt{M.x} must be added to $100!$.
Later, when the full implementation of the modules are known, we simply link what was missing with the separate analysis results.

Such an approach is useful in two ways:

\noindent\textbf{Rely-guarantee}

When the client code is linked with another implementation of \texttt{F}, check whether \texttt{fact} is changed, and if it is not changed, simply inject the rest into the analysis results.

\noindent\textbf{Incrementality}

If the implementation of \texttt{x} is changed, it will not trigger re-analysis of the whole program.

\section{Uncovering Modularity in Operational Semantics}
First we introduce our model language.
The language is basically an extension of untyped lambda calculus with modules and the linking construct.

\begin{figure}[htb]
  \centering
  \begin{tabular}{rrcll}
    Identifiers & $x,M$ & $\in$         & $\ExprVar$                                                             \\
    Expression  & $e$   & $\rightarrow$ & $x$ $\vbar$ $\lambda x.e$ $\vbar$ $e$ $e$ & untyped $\lambda$-calculus \\
                &       & $\vbar$       & $\link{e}{e}$                             & linked expression          \\
                &       & $\vbar$       & $\varepsilon$                             & empty module               \\
                &       & $\vbar$       & $M$                                       & module identifier          \\
                &       & $\vbar$       & $\Let$ $x$ $e$ $e$                        & expression binding         \\
                &       & $\vbar$       & $\Let$ $M$ $e$ $e$                        & module binding             \\
  \end{tabular}
  \caption{Abstract syntax of the simple module language.}
  \label{fig:syntax}
\end{figure}
\subsection{Expressivity of the simple language}
\begin{align*}
  m_1 & \triangleq\text{\texttt{let x = 1 in }}\varepsilon                                                                                                                                                                                     \\
  m_2 & \triangleq\text{\texttt{let fact = fix }}\lambda\text{\texttt{fact.}}\lambda\text{\texttt{n.if0 n 1 (* n (fact (- n 1))) in }}\varepsilon                                                                                              \\
  e   & \triangleq(\text{\texttt{let M = }}m_1\text{\texttt{ in }}\varepsilon)\synlink(\text{\texttt{let F = }}m_2\text{\texttt{ in }}\varepsilon)\synlink(\text{\texttt{+ (F}}\synlink\text{\texttt{fact 100) (M}}\synlink\text{\texttt{x)}})
\end{align*}
Above is how the example in the introduction is translated into the simple module language in Figure \ref{fig:syntax}, assuming that the definitions for arithmetic and the fixpoint combinator \texttt{fix} are given.
The language is expressive enough to encode simple imports and exports that use module names as interfaces.

\subsection{Operational Semantics}
\begin{figure}[h!]
  \centering
  \begin{tabular}{rrcll}
    Environment/Context          & $C$ & $\in$         & $\Ctx$                                                      \\
    Value of expressions         & $v$ & $\in$         & $\Value \subseteq \Expr\times\Ctx$                          \\
    Value of expressions/modules & $V$ & $\in$         & $\Value\Ctx\triangleq\Value\uplus\Ctx$                      \\
    Context                      & $C$ & $\rightarrow$ & []                                     & empty stack        \\
                                 &     & $\vbar$       & $(x,v)\cons C$                         & expression binding \\
                                 &     & $\vbar$       & $(M,C)\cons C$                         & module binding     \\
    Value of expressions         & $v$ & $\rightarrow$ & $\langle \lambda x.e, C \rangle$       & closure
  \end{tabular}
  \caption{Definition of the semantic domains.}
  \label{fig:simpdom}
\end{figure}

\begin{figure}[h!]
  \scriptsize
  \begin{flushright}
    \fbox{$(e,C)\semarrow V\text{ or }(e',C')$}
  \end{flushright}
  \centering
  \vspace{0pt} % -0.75em}
  \[
    \begin{prooftree}
      \hypo{v=C(x)}
      \infer[left label=ExprID]1{
      (x, C)
      \semarrow
      v
      }
    \end{prooftree}\qquad
    \begin{prooftree}
      \infer[left label=Fn]0{
      (\lambda x.e, C)
      \semarrow
      \langle\lambda x.e, C\rangle
      }
    \end{prooftree}\qquad
    \begin{prooftree}
      \infer[left label={AppL}]0{
      (e_{1}\:e_{2}, C)
      \semarrow
      (e_{1},C)
      }
    \end{prooftree}
  \]

  \[
    \begin{prooftree}
      \hypo{
        \begin{matrix}
          (e_{1}, C)
          \semarrow
          \langle\lambda x.e_{\lambda}, C_{\lambda}\rangle
        \end{matrix}
      }
      \infer[left label={AppR}]1{
      (e_{1}\:e_{2}, C)
      \semarrow
      (e_{2}, C)
      }
    \end{prooftree}\qquad
    \begin{prooftree}
      \hypo{
        \begin{matrix}
          (e_{1}, C)
          \semarrow
          \langle\lambda x.e_{\lambda}, C_{\lambda}\rangle \\
          (e_{2}, C)
          \semarrow
          v
        \end{matrix}
      }
      \infer[left label={AppBody}]1{
      (e_{1}\:e_{2}, C)
      \semarrow
      (e_{\lambda}, (x, v)\cons C_{\lambda})
      }
    \end{prooftree}\qquad
    \begin{prooftree}
      \hypo{
        \begin{matrix}
          (e_{1}, C)
          \semarrow
          \langle\lambda x.e_{\lambda}, C_{\lambda}\rangle \\
          (e_{2}, C)
          \semarrow
          v                                                \\
          (e_{\lambda}, (x, v)\cons C_{\lambda})
          \semarrow
          v'
        \end{matrix}
      }
      \infer[left label={App}]1{
      (e_{1}\:e_{2}, C)
      \semarrow
      v'
      }
    \end{prooftree}
  \]

  \[
    \begin{prooftree}
      \infer[left label=LinkL]0{
      (\link{e_{1}}{e_{2}}, C)
      \semarrow
      (e_{1}, C)
      }
    \end{prooftree}\qquad
    \begin{prooftree}
      \hypo{
        \begin{matrix}
          (e_{1}, C)
          \semarrow
          C'
        \end{matrix}
      }
      \infer[left label=LinkR]1{
      (\link{e_{1}}{e_{2}}, C)
      \semarrow
      (e_{2}, C')
      }
    \end{prooftree}\qquad
    \begin{prooftree}
      \hypo{
        \begin{matrix}
          (e_{1}, C)
          \semarrow
          C' \\
          (e_{2}, C')
          \semarrow
          V
        \end{matrix}
      }
      \infer[left label=Link]1{
      (\link{e_{1}}{e_{2}}, C)
      \semarrow
      V
      }
    \end{prooftree}
  \]

  \[
    \begin{prooftree}
      \infer[left label=Empty]0{
      (\varepsilon, C)
      \semarrow
      C
      }
    \end{prooftree}\qquad
    \begin{prooftree}
      \hypo{C'=C(M)}
      \infer[left label=ModID]1{
      (M, C)
      \semarrow
      C'
      }
    \end{prooftree}
  \]

  \[
    \begin{prooftree}
      \infer[left label=LetEL]0{
      (\mathtt{let}\:x\:e_1\:e_2, C)
      \semarrow
      (e_{1}, C)
      }
    \end{prooftree}\quad
    \begin{prooftree}
      \hypo{
        \begin{matrix}
          (e_{1}, C)
          \semarrow
          v
        \end{matrix}
      }
      \infer[left label=LetER]1{
      (\mathtt{let}\:x\:e_1\:e_2, C)
      \semarrow
      (e_{2}, (x, v)\cons C)
      }
    \end{prooftree}\quad
    \begin{prooftree}
      \hypo{
        \begin{matrix}
          (e_{1}, C)
          \semarrow
          v \\
          (e_{2}, (x, v)\cons C)
          \semarrow
          C'
        \end{matrix}
      }
      \infer[left label=LetE]1{
      (\mathtt{let}\:x\:e_1\:e_2, C)
      \semarrow
      C'
      }
    \end{prooftree}
  \]

  \[
    \begin{prooftree}
      \infer[left label=LetML]0{
      (\mathtt{let}\:M\:e_{1}\:e_{2}, C)
      \semarrow
      (e_{1}, C)
      }
    \end{prooftree}\quad
    \begin{prooftree}
      \hypo{
        \begin{matrix}
          (e_{1}, C)
          \semarrow
          C'
        \end{matrix}
      }
      \infer[left label=LetMR]1{
      (\mathtt{let}\:M\:e_{1}\:e_{2}, C)
      \semarrow
      (e_{2}, (M, C')\cons C)
      }
    \end{prooftree}\quad
    \begin{prooftree}
      \hypo{
        \begin{matrix}
          (e_{1}, C)
          \semarrow
          C' \\
          (e_{2}, (M, C')\cons C)
          \semarrow
          C''
        \end{matrix}
      }
      \infer[left label=LetM]1{
      (\mathtt{let}\:M\:e_{1}\:e_{2}, C)
      \semarrow
      C''
      }
    \end{prooftree}
  \]
  \caption{The concrete one-step transition relation.}
  \label{fig:simpreach}
\end{figure}
We present the operational semantics $\semarrow$ for our language.
The semantic domains are given in Figure \ref{fig:simpdom} and the operational semantics is defined in Figure \ref{fig:simpreach}.

Our semantics relate an element $\ell$ of $\Left\triangleq\Expr\times\Ctx$ with an element $\rho$ of $\Right\triangleq\Left\uplus\Value\Ctx$.
Note that $C(x)$ pops the highest value that is associated with $x$ from the stack $C$ and $C(M)$ pops the highest context associated with $M$ from $C$.
The relation $\semarrow$ is unorthodox in that unlike normal big-step operaional semantics, it relates a configuration not only to its final result but also to intermediate configurations of which its values are required to compute the final result.
Why it is defined as such is because defining a \emph{collecting semantics} becomes much simpler.

\subsection{Collecting Semantics}
To define a semantics that is computable, we must formulate the collecting semantics as a least fixed point of a monotonic function that maps an element of some CPO $D$ to $D$.
In our case, $D\triangleq\pset(\Sigma)$ when $\Sigma\triangleq\semarrow\uplus\Right$ and $\pset(S)$ is the powerset of $S$.
The semantics of an expression $e$ starting from initial states in $S\subseteq\Ctx$ is the collection of $\ell\semarrow\rho$ and $\rho$ derivable from initial configurations $(e,C)$ with $C\in S$.
Defining the transfer function is straightforward from the definition of the transition relation.

\begin{defn}[Transfer function]
  Given $A\in D$, define
  \[
    \mathsf{Step}(A)\triangleq
    \left\{\ell\semarrow\rho, \rho\middle|
    \begin{prooftree}[center=true]
      \hypo{A'}\infer1{\ell\semarrow\rho}
    \end{prooftree}\text{ and }
    A'\subseteq A\text{ and }\ell\in A
    \right\}
  \]
\end{defn}

The $\mathsf{Step}$ function is naturally monotonic, as a ``cache'' $A$ that remembers more about the intermediate proof tree will derive more results than a cache that remembers less.
In fact, we can prove that it is continuous, as it preserves the least upper bound of chains.
Now, because of Tarski's fixpoint theorem, we can formulate the collecting semantics in fixpoint form.
\begin{defn}[Collecting semantics]
  Given $e\in\Expr$ and $S\subseteq\Ctx$, define:
  \[
    \sembracket{e}S\triangleq\lfp(\lambda X.\mathsf{Step}(X)\cup\{(e,C)|C\in S\})
  \]
\end{defn}
Note that the above definition can be defined without qualms for situations when the $C$ in $(e,C)$ does not close $e$.
Then the collecting semantics will store the proof tree only up to the point the first free variable is evaluated.

\subsection{Semantic Linking}
Now we present a natural notion of \emph{semantic linking} that, given a (1) (possibly incomplete) proof tree of an expression $e$ under some initial context $C_1$ and (2) some external context $C_2$, gives the meaning of $e$ under the \emph{linked} context of $C_1$ and $C_2$.
Thus, it will be clear how analysis results obtained locally can be reused to obtain the meaning of the whole program, all at the level of the operational semantics.

We first define what it means to \emph{fill in the blanks} of an individual $V_2\in\Value\Ctx$ with a $C_1\in\Ctx$:
\[
  \inject{C_{1}}{V_{2}}\triangleq
  \begin{cases}
    C_1                                           & V_{2}=[]                        \\
    (x, \inject{C_1}{v})\cons\inject{C_{1}}{C}    & V_{2}=(x,v)\cons C              \\
    (M, \inject{C_{1}}{C})\cons\inject{C_{1}}{C'} & V_{2}=(M,C)\cons C'             \\
    \langle\lambda x.e,\inject{C_1}{C}\rangle     & V_2=\langle\lambda x.e,C\rangle
  \end{cases}
\]
This does indeed ``fill in the blanks'', since:
\begin{lem}[Fill in the Blanks]
  For all $C_1,C_2\in\Ctx$, for each expression variable $x$,
  \[
    C_2(x)=v\Rightarrow\inject{C_1}{C_2}(x)=\inject{C_1}{v}\text{ and }C_2(x)=\bot\Rightarrow\inject{C_1}{C_2}(x)=C_1(x)
  \]
  and for each module variable $M$,
  \[
    C_2(M)=C\Rightarrow\inject{C_1}{C_2}(x)=\inject{C_1}{C}\text{ and }C_2(M)=\bot\Rightarrow\inject{C_1}{C_2}(M)=C_1(M)
  \]
\end{lem}
\begin{proof}[Sketch]
  Induction on $C_2$.
\end{proof}

Moreover, filling in the blanks preserves the evaluation relation $\semarrow$.
When we define $\inject{C_1}{\ell}$ for $C_1\in\Ctx,\ell=(e,C_2)\in\Left$ as $(e,\inject{C_1}{C_2})$, we have:
\begin{lem}[Injection Preserves Evaluation]
  For all $\ell\in\Left$, $\rho\in\Right$, $\ell\semarrow\rho\Rightarrow\inject{C}{\ell}\semarrow\inject{C}{\rho}$.
\end{lem}
\begin{proof}[Sketch]
  Induction on $\semarrow$.
\end{proof}

Thus, we can define $\rhd$ that injects a \emph{set} of contexts $S$ into an element $A$ of $D$ and a semantic linking operation $\semlink$ that does the rest of the computation:
\begin{defn}[Injection]
  For $S\subseteq\Ctx$ and $A\in D$, define:
  \[S\rhd A\triangleq\{\inject{C}{\rho}|C\in S,\rho\in A\}\cup\{\inject{C}{\ell}\semarrow\inject{C}{\rho}|C\in S,\ell\semarrow\rho\in A\}\]
\end{defn}
\begin{defn}[Semantic Linking]
  For $S\subseteq\Ctx$ and $A\in D$, define:
  \[S\semlink A\triangleq\lfp(\lambda X.\Step(X)\cup(S\rhd A))\]
\end{defn}

Thus we reach the main theorem that allows ``fractional closures'' to be soundly defined:
\begin{thm}[Advance]
  For all $e\in\Expr$ and $S_1,S_2\subseteq\Ctx$,
  \[\sembracket{e}(S_1\rhd S_2)=S_1\semlink\sembracket{e}S_2\]
\end{thm}
\begin{proof}
  Let $A$ be $\{(e,C)|C\in S_1\rhd S_2\}$, and let $B$ be $S_1\rhd\sembracket{e}S_2$.
  Note that $A\subseteq B$ by the definition of $\sembracket{e}S_2$.
  Also, let $X_A$ be $\lfp(\lambda X.\Step(X)\cup A)=\sembracket{e}(S_1\rhd S_2)$ and let $X_B$ be $\lfp(\lambda X.\Step(X)\cup B)=S_1\semlink\sembracket{e}S_2$.
  Since injection preserves evaluation, we have that $B\subseteq X_A$.

  Then first, $X_A$ is a fixed point of $\lambda X.\Step(X)\cup B$, since:
  \[X_A=X_A\cup B=(\Step(X_A)\cup A)\cup B=\Step(X_A)\cup(A\cup B)=\Step(X_A)\cup B\]
  Then since $X_B$ is the least fixed point, $X_B\subseteq X_A$.

  Also, note that $X_B$ is a pre-fixed point of $\lambda X.\Step(X)\cup A$, since:
  \[\Step(X_B)\cup A\subseteq\Step(X_B)\cup B=X_B\]
  $D$ is a complete lattice, so by Tarski's fixpoint theorem, $X_A$ is the least of all pre-fixed points of $\lambda X.\Step(X)\cup A$.
  Since $X_B$ is a pre-fixed point, $X_A\subseteq X_B$.

  Since $X_B\subseteq X_A$ and $X_A\subseteq X_B$, we have that $X_A=X_B$.
\end{proof}

\subsection{Skeleton of a Static Analysis}
Since we have defined a semantics that fully embrace \emph{incomplete computations}, we only have to abstract our semantic operators to obtain a sound static analysis.

We require a CPO $\Abs{D}$ that is Galois connected with $D$ by abstraction $\alpha$ and concretization $\gamma$:
\[\pset(\Sigma)=D\galois{\alpha}{\gamma}\Abs{D}\]
and semantic operators $\Abs\Step$ and $\Abs\rhd$ that satisfies:
\[\Step\circ\gamma\subseteq\gamma\circ\Abs\Step\qquad\rhd\circ(\gamma,\gamma)\subseteq\gamma\circ\Abs\rhd\]
Then we define $\Abs{\sembracket{e}}$ and $\Abs\semlink$ as:
\[
  \Abs{\sembracket{e}}\Abs{S}\triangleq\lfp(\lambda\Abs{X}.\Abs\Step(\Abs{X})\Abs\cup\alpha\{(e,C)|C\in\gamma\Abs{S}\})\qquad
  \Abs{S}\Abs\semlink\Abs{A}\triangleq\lfp(\lambda\Abs{X}.\Abs\Step(\Abs{X})\Abs\cup(\Abs{S}\Abs\rhd\Abs{A}))
\]
which, by definition and Tarski's fixpoint theorem satisfies:
\[\sembracket{e}\circ\gamma\subseteq\gamma\circ\Abs{\sembracket{e}}\qquad\semlink\circ(\gamma,\gamma)\subseteq\gamma\circ\Abs\semlink\]
Then we can soundly approximate fractional specifications by:
\begin{align*}
  S_1\semlink\sembracket{e}S_2 & \subseteq S_1\semlink\gamma(\Abs{\sembracket{e}}\alpha(S_2))                 & (\because\sembracket{e}\subseteq\gamma\circ\Abs{\sembracket{e}}\circ\alpha\text{ and monotonicity of }\semlink) \\
                               & \subseteq \gamma(\alpha(S_1))\semlink\gamma(\Abs{\sembracket{e}}\alpha(S_2)) & (\because\text{id}\subseteq\gamma\circ\alpha\text{ and monotonicity of }\semlink)                               \\
                               & \subseteq\gamma(\alpha(S_1)\Abs\semlink\Abs{\sembracket{e}}\alpha(S_2))      & (\because\semlink\circ(\gamma,\gamma)\subseteq\gamma\circ\Abs\semlink)
\end{align*}
\section{Instrumented Semantics}
All that is left is to present an abstraction for the semantics in the previous section.
Since the depth of the context $C$ is unbound due to entries $(x,v)$ also containing $C$ in the environment part of $v$, we need to abstract $S\subseteq\Ctx$ to finitely compute an overapproximation.
However, devising such an abstraction is not immediately obvious.

Consider an abstract context $\Abs{C}$ that overapproximates $\gamma(\Abs{C})\subseteq\Ctx$.
For a variable $x$, we expect that $\gamma(\Abs{C}(x))\supseteq\{C(x)|C\in\gamma(\Abs{C})\}$, when the operation $\Abs{C}(x)$ reads the abstract closure bound to $x$ from $\Abs{C}$.
Thus, there is a recursive structure, where reading from an abstract context must return an abstract closure again containing an abstract context.

To break this recursive structure, we employ the common technique of introducing addresses and a memory.
Thus, we extend the operational semantics of the previous section to a sematics that involve choosing a \emph{time} domain $\Time$ to use as addresses.

\subsection{Semantic Domains}
\begin{figure}[h!]
  \centering
  \begin{tabular}{rrcll}
    Time                         & $t$    & $\in$         & $\Time$                                                                  \\
    Environment/Context          & $C$    & $\in$         & $\Ctx$                                                                   \\
    Value of expressions         & $v$    & $\in$         & $\Value \subseteq \Expr\times\Ctx$                                       \\
    Value of expressions/modules & $V$    & $\in$         & $\Value\Ctx\triangleq\Value\uplus\Ctx$                                   \\
    Memory                       & $\mem$ & $\in$         & $\Mem \triangleq \fin{\Time}{\Value}$                                    \\
    State                        & $s$    & $\in$         & $\State \subseteq \Ctx\times\Mem\times\Time$                             \\
    Result                       & $r$    & $\in$         & $\Result \subseteq \Value\Ctx\times\Mem\times\Time$                      \\
    Context                      & $C$    & $\rightarrow$ & []                                                  & empty stack        \\
                                 &        & $\vbar$       & $(x,t)\cons C$                                      & expression binding \\
                                 &        & $\vbar$       & $(M,C)\cons C$                                      & module binding     \\
    Value of expressions         & $v$    & $\rightarrow$ & $\langle \lambda x.e, C \rangle$                    & closure
  \end{tabular}
  \caption{Definition of the instrumented semantic domains.}
  \label{fig:concdom}
\end{figure}

The domains for defining the operational semantics is extended to include the \emph{time} and \emph{memory}.
Compared with Figure \ref{fig:simpdom}, Figure \ref{fig:concdom} defines four more sets, $\Time$, $\Mem$, $\State$, and $\Result$.
A $s=(C,\mem,t)\in\State$ corresponds to a $C$ in Figure \ref{fig:simpdom}, as the pair $(C,\mem)$ cooperates to represent the recursively defined $C$ in the original representation.
Similarly, a $r=(V,\mem,t)\in\Result$ corresponds to a $V$ in Figure \ref{fig:simpdom}, as the pair $(V,\mem)$ cooperates to represent the recursively defined $V$.

Note that a heavy burden has been cast upon the \emph{time} component.
The time component is responsible for providing \emph{fresh} addresses to write to in the memory, and it is also an indicator of the execution \emph{history} up to that point.
Hence, the policy for incrementing the timestamps of states decides what events are recorded in the timestamps, and the abstraction of this policy must select what events are preserved in the abstract semantics.
We name this policy $\tick$ in our framework.
The \emph{type} of $\tick$ can be freely chosen, since it may choose to record any event that occurs during execution, but in this section we choose the type $\Time\rightarrow\Time$, the simplest possible option.

\subsection{Operational Semantics}
\begin{figure}[h!]
  \scriptsize
  \begin{flushright}
    \fbox{$(e,C,\mem,t)\semarrow(V,\mem',t')\text{ or }(e',C',\mem',t')$}
  \end{flushright}
  \centering
  \vspace{0pt} % -0.75em}
  \[
    \begin{prooftree}
      \hypo{t_{x}={C}(x)}
      \hypo{v=\mem(t_{x})}
      \infer[left label=ExprID]2{
      (x, C, \mem, t)
      \semarrow
      (v, \mem, t)
      }
    \end{prooftree}\qquad
    \begin{prooftree}
      \infer[left label=Fn]0{
      (\lambda x.e, C, \mem, t)
      \semarrow
      (\langle\lambda x.e, C\rangle, \mem, t)
      }
    \end{prooftree}
  \]

  \[
    \begin{prooftree}
      \hypo{
        \begin{matrix}
          (e_{1}, C, \mem, t)
          \semarrow
          (\langle\lambda x.e_{\lambda}, C_{\lambda}\rangle, \mem_{\lambda}, t_{\lambda}) \\
          (e_{2}, C, \mem_{\lambda}, t_{\lambda})
          \semarrow
          (v, \mem_{a}, t_{a})                                                            \\
          (e_{\lambda}, (x, \tick(t_{a}))\cons C_{\lambda}, \mem_{a}[\tick(t_{a})\mapsto v], \tick(t_a))
          \semarrow
          (v', \mem',t')
        \end{matrix}
      }
      \infer[left label={App}]1{
      (e_{1}\:e_{2}, C, \mem, t)
      \semarrow
      (v', \mem',t')
      }
    \end{prooftree}
  \]

  \[
    \begin{prooftree}
      \hypo{
        \begin{matrix}
          (e_{1}, C, \mem, t)
          \semarrow
          (C', \mem', t') \\
          (e_{2}, C', \mem', t')
          \semarrow
          (V, \mem'', t'')
        \end{matrix}
      }
      \infer[left label=Link]1{
      (\link{e_{1}}{e_{2}}, C, \mem, t)
      \semarrow
      (V, \mem'', t'')
      }
    \end{prooftree}\qquad
    \begin{prooftree}
      \infer[left label=Empty]0{
      (\varepsilon, C, \mem, t)
      \semarrow
      (C, \mem, t)
      }
    \end{prooftree}\qquad
    \begin{prooftree}
      \hypo{C'={C}(M)}
      \infer[left label=ModID]1{
      (M, C, \mem, t)
      \semarrow
      (C', \mem, t)
      }
    \end{prooftree}
  \]

  \[
    \begin{prooftree}
      \hypo{
        \begin{matrix}
          (e_{1}, C, \mem, t)
          \semarrow
          (v, \mem', t') \\
          (e_{2}, (x, \tick(t'))\cons C, \mem'[\tick(t')\mapsto v], \tick(t'))
          \semarrow
          (C', \mem'', t'')
        \end{matrix}
      }
      \infer[left label=LetE]1{
      (\mathtt{let}\:x\:e_1\:e_2, C, \mem, t)
      \semarrow
      (C', \mem'', t'')
      }
    \end{prooftree}
  \]

  \[
    \begin{prooftree}
      \hypo{
        \begin{matrix}
          (e_{1}, C, \mem, t)
          \semarrow
          (C', \mem', t') \\
          (e_{2}, (M, C')\cons C, \mem', t')
          \semarrow
          (C'', \mem'', t'')
        \end{matrix}
      }
      \infer[left label=LetM]1{
      (\mathtt{let}\:M\:e_{1}\:e_{2}, C, \mem, t)
      \semarrow
      (C'', \mem'', t'')
      }
    \end{prooftree}
  \]
  \caption{Excerpt of the concrete instrumented semantics, corresponding to the big-step evaluation rules.}
  \label{fig:concreach}
\end{figure}

An excerpt of the instrumented operational semantics is given in Figure \ref{fig:concreach}.
One must first note that there is a problem with the definition of $\semarrow$ as it is.
There are no restrictions on $\tick$ and the states $(C,\mem,t)$, thus a write to the address $t$ may overwrite an existing value that may be used for future computations.
That is, $\tick(t)\not\in\mathsf{supp}(C,\mem)$ must be guaranteed, when $\mathsf{supp}(C,\mem)$ is the set of timestamps reachable from $(C,\mem)$.
To enforce this invariant upon all \emph{valid} concrete executions defined by the relation $\semarrow$, we enforce that there be a \emph{total order} on $\Time$.
Then our criteria can be guaranteed by first enforcing that $C\le t$ and $\mem\le t$, when $C\le t$ means that all timestamps in $C$ are bound by $t$, and $\mem\le t$ means that all timestamps allocated in the memory are bound by $t$.

Then the criteria that $\tick(t)$ must be fresh is formalized by demanding that:
\[t < \tick(t)\]
for all $t$.
This condition is not as restrictive as it seems, as we can conversely think of a $\tick$ generating fresh timestamps as \emph{inducing} a total order on $\Time$.
Now, to allow only such valid transitions, we define:
\[
  \State\triangleq\{(C,\mem,t)|C\le t\text{ and }\mem\le t\}\qquad
  \Result\triangleq\{(V,\mem,t)|V\le t\text{ and }\mem\le t\}
\]
as the set of valid states that enable $\tick$ to generate fresh timestamps.
It is almost trivial that the set $\Left\times\Right$, when $\Left\triangleq\Expr\times\State$ and $\Right\triangleq\Left\uplus\Result$, is closed under the inductive definition of $\semarrow$.
That is,
\begin{lem}[Valid States Transition to Valid States]
  For all $\ell\in\Left$ and $\rho$, if $\ell\semarrow\rho$ according to the inductive rules, $\rho\in\Right$.
\end{lem}
\begin{proof}[Sketch]
  Induction on $\semarrow$.
\end{proof}

\subsection{Collecting Semantics}
The definition for the collecting semantics of the language is identical to the collecting semantics in the previous section.
That is, when we let $D\triangleq\pset(\Sigma)$ where $\Sigma\triangleq\Right\uplus\semarrow$,
\begin{defn}[Transfer function]
  Given $A\in D$, define
  \[
    \mathsf{Step}(A)\triangleq
    \left\{\ell\semarrow\rho, \rho\middle|
    \begin{prooftree}[center=true]
      \hypo{A'}\infer1{\ell\semarrow\rho}
    \end{prooftree}\text{ and }
    A'\subseteq A\text{ and }\ell\in A
    \right\}
  \]
\end{defn}
and
\begin{defn}[Collecting semantics]
  Given $e\in\Expr$ and $S\subseteq\State$, define:
  \[
    \sembracket{e}S\triangleq\lfp(\lambda X.\mathsf{Step}(X)\cup\{(e,s)|s\in S\})
  \]
\end{defn}
\section{Abstract Semantics}
\begin{figure}[h!]
  \centering
  \begin{tabular}{rrcll}
    Abstract Time                & $\A{t}$    & $\in$         & $\A{\Time}$                                                                               \\
    Environment/Context          & $\A{C}$    & $\in$         & $\A{\Ctx}$                                                                                \\
    Value of expressions         & $\A{v}$    & $\in$         & $\A{\Value} \subseteq \Expr\times\A{\Ctx}$                                                \\
    Value of expressions/modules & $\A{V}$    & $\in$         & $\A{\Value\Ctx}\triangleq\A{\Value}\uplus\A{\Ctx}$                                        \\
    Abstract Memory              & $\A{\mem}$ & $\in$         & $\A{\Mem} \triangleq \fin{\A{\Time}}{\pset(\A{\Value})}$                                  \\
    Abstract State               & $\A{s}$    & $\in$         & $\A{\State} \triangleq \A{\Ctx}\times\A{\Mem}\times\A{\Time}$                             \\
    Abstract Result              & $\A{r}$    & $\in$         & $\A{\Result} \triangleq \A{\Value\Ctx}\times\A{\Mem}\times\A{\Time}$                      \\
    Context                      & $\A{C}$    & $\rightarrow$ & []                                                                   & empty stack        \\
                                 &            & $\vbar$       & $(x,\A{t})\cons \A{C}$                                               & expression binding \\
                                 &            & $\vbar$       & $(M,\A{C})\cons \A{C}$                                               & module binding     \\
    Value of expressions         & $\A{v}$    & $\rightarrow$ & $\langle \lambda x.e, \A{C} \rangle$                                 & closure
  \end{tabular}
  \caption{Definition of the semantic domains in the abstract case.}
  \label{fig:absdom}
\end{figure}
Now we present a way to simply abstract the concrete semantics via a finite abstraction of the time component.
For this purpose, we choose a finite \emph{abstract time} domain $\A\Time$ that is connected to the concrete time domain via an auxiliary function $\A\alpha:\Time\rightarrow\A\Time$.
Since the policy to update the timestamp must also be compatible with respect to $\A\alpha$, we require the $\A\tick:\A\Time\rightarrow\A\Time$ function to satisfy $\A\alpha\circ\tick=\A\tick\circ\A\alpha$.

Then the operational semantics can be abstracted directly, with modifications only in the \emph{update} of the memory and \emph{reads} from the memory.
The memory update operation is defined as a weak update, that is:
\[
  \A{\mem}[\A{t}\A{\mapsto}\A{v}](\A{t'})\triangleq
  \begin{cases}
    \A{\mem}(\A{t})\cup\{\A{v}\} & (\A{t'}=\A{t})     \\
    \A{\mem}(\A{t'})             & (\text{otherwise})
  \end{cases}
\]
and the read from the memory returns a set of closures with abstract addresses, allowing transitions to any value within that set.
An excerpt for the abstract version of the operational semantics $\A\semarrow$ is in Figure \ref{fig:absreach}.
$\A\semarrow\subseteq\A\Left\times\A\Right$, when $\A\Left\triangleq\Expr\times\A\State$ and $\A\Right\triangleq\A\Left\uplus\A\Result$.

\begin{figure}[h!]
  \scriptsize
  \begin{flushright}
    \fbox{$(e,\A{C},\A\mem,\A{t})\A\semarrow(\A{V},\A{\mem'},\A{t'})\text{ or }(e',\A{C'},\A{\mem'},\A{t'})$}
  \end{flushright}
  \vspace{0pt} % -0.75em}
  \[
    \begin{prooftree}
      \hypo{\A{t_x}=\A{C}(x)}
      \hypo{\A{v}\in\A\mem(\A{t_x})}
      \infer[left label=ExprID]2{
      (x, \A{C}, \A\mem, \A{t})
      \A\semarrow
      (\A{v}, \A\mem, \A{t})
      }
    \end{prooftree}\qquad
    \begin{prooftree}
      \infer[left label=Fn]0{
      (\lambda x.e, \A{C}, \A\mem, \A{t})
      \A\semarrow
      (\langle\lambda x.e, \A{C}\rangle, \A\mem, \A{t})
      }
    \end{prooftree}
  \]

  \[
    \begin{prooftree}
      \hypo{
        \begin{matrix}
          (e_{1}, \A{C}, \A\mem, \A{t})
          \A\semarrow
          (\langle\lambda x.e_{\lambda}, \A{C}_{\lambda}\rangle, \A\mem_{\lambda}, \A{t_\lambda}) \\
          (e_{2}, \A{C}, \A\mem_{\lambda}, \A{t_\lambda})
          \A\semarrow
          (\A{v}, \A\mem_{a}, \A{t_a})                                                            \\
          (e_{\lambda}, (x, \A\tick(\A{t_a}))\cons \A{C}_{\lambda}, \A\mem_{a}[\A\tick(\A{t_a})\A\mapsto \A{v}], \A\tick(\A{t_a}))
          \A\semarrow
          (\A{v'}, \A{\mem'},\A{t'})
        \end{matrix}
      }
      \infer[left label={App}]1{
      (e_{1}\:e_{2}, \A{C}, \A\mem, \A{t})
      \A\semarrow
      (\A{v'}, \A{\mem'},\A{t'})
      }
    \end{prooftree}
  \]

  \[
    \begin{prooftree}
      \hypo{
        \begin{matrix}
          (e_{1}, \A{C}, \A\mem, \A{t})
          \A\semarrow
          (\A{C'}, \A{\mem'}, \A{t'}) \\
          (e_{2}, \A{C'}, \A{\mem'}, \A{t'})
          \A\semarrow
          (\A{V}, \A{\mem''}, \A{t''})
        \end{matrix}
      }
      \infer[left label=Link]1{
      (\link{e_{1}}{e_{2}}, \A{C}, \A\mem, \A{t})
      \A\semarrow
      (\A{V}, \A{\mem''}, \A{t''})
      }
    \end{prooftree}\:
    \begin{prooftree}
      \infer[left label=Empty]0{
      (\varepsilon, \A{C}, \A\mem, \A{t})
      \A\semarrow
      (\A{C}, \A\mem, \A{t})
      }
    \end{prooftree}\:
    \begin{prooftree}
      \hypo{\A{C'}=\A{C}(M)}
      \infer[left label=ModID]1{
      (M, \A{C}, \A\mem, \A{t})
      \A\semarrow
      (\A{C'}, \A\mem, \A{t})
      }
    \end{prooftree}
  \]

  \[
    \begin{prooftree}
      \hypo{
        \begin{matrix}
          (e_{1}, \A{C}, \A\mem, \A{t})
          \A\semarrow
          (\A{v}, \A{\mem'}, \A{t'}) \\
          (e_{2}, (x, \A\tick(\A{t'}))\cons \A{C}, \A{\mem'}[\A\tick(\A{t'})\A\mapsto \A{v}], \A\tick(\A{t'}))
          \A\semarrow
          (\A{C'}, \A{\mem''}, \A{t''})
        \end{matrix}
      }
      \infer[left label=LetE]1{
      (\mathtt{let}\:x\:e_1\:e_2, \A{C}, \A\mem, \A{t})
      \A\semarrow
      (\A{C'}, \A{\mem''}, \A{t''})
      }
    \end{prooftree}
  \]

  \[
    \begin{prooftree}
      \hypo{
        \begin{matrix}
          (e_{1}, \A{C}, \A\mem, \A{t})
          \A\semarrow
          (\A{C'}, \A{\mem'}, \A{t'}) \\
          (e_{2}, (M, \A{C'})\cons \A{C}, \A{\mem'}, \A{t'})
          \A\semarrow
          (\A{C''}, \A{\mem''}, \A{t''})
        \end{matrix}
      }
      \infer[left label=LetM]1{
      (\mathtt{let}\:M\:e_{1}\:e_{2}, \A{C}, \A\mem, \A{t})
      \A\semarrow
      (\A{C''}, \A{\mem''}, \A{t''})
      }
    \end{prooftree}
  \]
  \caption{Excerpt of the abstract operational semantics, corresponding to the big-step evaluation rules.}
  \label{fig:absreach}
\end{figure}
We note that the abstract operational semantics is a sound approximation of the concrete semantics in the operational sense, since if we extend $\A\alpha$ as:
\begin{align*}
  \A\alpha([])                          & \triangleq []                                                                                    \\
  \A\alpha((x,t_x)\cons C)              & \triangleq(x,\A\alpha(t_x))\cons\A\alpha(C)                                                      \\
  \A\alpha((M,C_M)\cons C)              & \triangleq(M,\A\alpha(C_M))\cons\A\alpha(C)                                                      \\
  \A\alpha(\langle\lambda x.e,C\rangle) & \triangleq\langle\lambda x.e,\A\alpha(C)\rangle                                                  \\
  \A\alpha(\mem)                        & \triangleq\lambda\A{t}.\{\A\alpha(\mem(t))|\A\alpha(t)=\A{t}\text{ and }t\in\mathsf{dom}(\mem)\} \\
  \A\alpha(e,C,\mem,t)                  & \triangleq(e,\A\alpha(C),\A\alpha(\mem),\A\alpha(t))                                             \\
  \A\alpha(V,\mem,t)                    & \triangleq(\A\alpha(V),\A\alpha(\mem),\A\alpha(t))
\end{align*}
We have:
\begin{lem}[Operational Soundness]
  For all $\ell\in\Left$ and $\rho\in\Right$, if $\ell\semarrow\rho$ then $\A\alpha(\ell)\A\semarrow\A\alpha(\rho)$.
\end{lem}
\begin{proof}[Sketch]
  Induction on $\semarrow$.
\end{proof}

Then if we define $\Abs{D}\triangleq\pset(\A\Sigma)$, when $\A\Sigma\triangleq\A\Right\uplus\A\semarrow$, we can establish a Galois connection between $D$ and $\Abs{D}$.
The abstraction and concretization functions are given by:
\begin{defn}[Abstraction and Concretization]
  Define $\alpha:D\rightarrow\Abs{D}$ and $\gamma:\Abs{D}\rightarrow D$ by:
  \[
    \alpha(A)\triangleq\{\A\alpha(\ell)\asemarrow\A\alpha(\rho)|\ell\semarrow\rho\in A\}\cup\{\A\alpha(\rho)|\rho\in A\}
  \]
  \[
    \gamma(\Abs{A})\triangleq\{\ell\semarrow\rho|\A\alpha(\ell)\asemarrow\A\alpha(\rho)\in\Abs{A}\}\cup\{\rho|\A\alpha(\rho)\in\Abs{A}\}
  \]
\end{defn}

Then it is straightforward to see that:
\begin{lem}[Galois Connection]
  $\pset(\Sigma)=D\galois{\alpha}{\gamma}\Abs{D}=\pset(\A\Sigma)$. That is:
  \[\forall A\in D,\Abs{A}\in\Abs{D}:\alpha(A)\subseteq\Abs{A}\Leftrightarrow A\subseteq\gamma(\Abs{A})\]
\end{lem}
\begin{proof}[Sketch]
  Straightforward from the definitions of $\alpha$ and $\gamma$.
\end{proof}

The definition for the abstract fixpoint semantics is naturally connected soundly with the collecting semantics.
\begin{defn}[Abstract transfer function]
  Given $\Abs{A}\in\Abs{D}$, define
  \[
    \Abs{\mathsf{Step}}(\Abs{A})\triangleq
    \left\{\A\ell\A\semarrow\A\rho, \A\rho\middle|
    \begin{prooftree}[center=true]
      \hypo{\Abs{A'}}\infer1{\A\ell\A\semarrow\A\rho}
    \end{prooftree}\text{ and }
    \Abs{A'}\subseteq \Abs{A}\text{ and }\A\ell\in\Abs{A}
    \right\}
  \]
\end{defn}
\begin{defn}[Abstract semantics]
  Given $e\in\Expr$ and $\Abs{S}\subseteq\A\State$, define:
  \[
    \Abs{\sembracket{e}}\Abs{S}\triangleq\lfp(\lambda \Abs{X}.\Abs{\mathsf{Step}}(\Abs{X})\cup\{(e,\A{s})|\A{s}\in \Abs{S}\})
  \]
\end{defn}
Then we can prove that:
\begin{thm}[Soundness]
  For all $e\in\Expr$, $\sembracket{e}\circ\gamma\subseteq\gamma\circ\Abs{\sembracket{e}}$.
\end{thm}
\begin{proof}
  From operational soundness, we have that $\alpha\circ\Step\subseteq\Abs\Step\circ\alpha$.
  Then by the fixpoint transfer theorem and Galois connection, we have our desired result.
\end{proof}

Now we can say that $\Abs{\sembracket{e}}\alpha(S)$ is a sound abstraction of $\sembracket{e}S$.
However, is it true that $\Abs{\sembracket{e}}\alpha(S)$ is finitely computable?
The answer to this question is ``yes''.

\begin{thm}[Finiteness]
  For all $e\in\Expr$ and $\Abs{S}\subseteq\A\Ctx$, if $\Abs{S}$ is finite, $\Abs{\sembracket{e}}\Abs{S}$ is finite.
\end{thm}
\begin{proof}[Sketch]
  Given $\A{s}\in\Abs{S}$, we want to prove that there is some finite set $X$ satisfying:
  \[\forall \A\rho\in\A\Right:(e,\A{s})\A\semarrow^*\A\rho\Rightarrow\A\rho\in X\]
  Note that $\A\rho$ is of the form $(\langle\lambda x.e',\A{C}\rangle,\A\mem,\A{t})$ or $(\A{C},\A\mem,\A{t})$ or $(e',\A{C},\A\mem,\A{t})$.
  Since there is a finite number of abstract timestamps, we only have to show that there is a finite number of \emph{shapes} of $\A\rho$ that is stripped of the timestamps.
  This is proven in Coq (\texttt{Abstract.v}).
\end{proof}

\section{Linking in the Instrumented Semantics}
Now we need to define an injection operation that fills in the blanks of a $r=(V,\mem,t)\in\Result$ with a $s=(C',\mem',t')\in\State$.
Recall the definition for injection in the semantics without memory.
$\inject{C}{V}$ enables access to values that were previously not available in $V$ by filling in the bottom of the stack with $C$.
Thus, we must mimic this by filling in all contexts in $r$ with the context part of $s$.
Also, to retain all information stored in the memory, the memory part of $r$ must be merged with the memory of $s$.

It is at this point that a problem occurs.
When merging the two memories $\mem$ and $\mem'$, we may encounter overlapping addresses.
Thus, we must require that all reachable addresses from $(C,\mem)$ does not overlap with reachable addresses in $(C',\mem')$.
Then again, this requirement may be lifted if we allow linking of semantics that use \emph{different} time domains as addresses.
After all, we can only \emph{read} values from $C$ in $\inject{C}{V}$; why not preserve addresses that were used in $s$ before injection and never allow writing to those addresses?
Thus, in this section we first define $\inject{s_1}{r_2}$, when $s_1$ uses $\Time_1$ as addresses and $r_2$ uses $\Time_2$ as addresses.
Then $\inject{s_1}{r_2}$ must live in a version of $\Result$ that uses $\Time_1+\Time_2$ as addresses.
From now on, variables with subscripts $1$ or $2$ are to be understood to be using $\Time_i(i=1,2)$ as addresses, and variables with the subscript $+$ are to be understood to be the linked version.

Defining linking between different time domains demand that $\tick$, $\A\Time$, $\A\alpha$, and $\A\tick$ also be linked.
Concretely, we demand that the linked $\tick_+$ preserves the condition that $\A\alpha_+\circ\tick_+=\A\tick_+\circ\A\alpha_+$.
Also, we need to link $\tick$ well so that for all valid transitions $\ell_2\semarrow\rho_2$ under $\tick_2$, $\inject{s_1}{\ell_2}\semarrow\inject{s_1}{\rho_2}$ is also a valid transition under $\tick_+$.
This is to ensure that injection into the collecting semantics is well-defined.
For the rest of this section, we define linking for all semantic domains and prove that the requirements laid out in the skeleton for static analysis hold.

\subsection{$\tick_+$, $\A\alpha_+$, $\A\tick$}
We must first define $\tick_+$, $\A\alpha_+$, and $\A\tick_+$ that satisfies the condition that $t_+<\tick_+(t_+)$ and $\A\alpha_+\circ\tick_+=\A\tick_+\circ\A\alpha_+$.
We define $\le_+$ to be the \emph{lexicographic} order on $\Time_1+\Time_2$, when an element $t_1$ of $\Time_1$ is lifted to $(0,t_1)$ and an element $t_2$ of $\Time_2$ is lifted to $(1,t_2)$.
Then if we define:
\[
  \tick_+(t)\triangleq
  \begin{cases}
    \tick_1(t) & t\in\Time_1 \\
    \tick_2(t) & t\in\Time_2
  \end{cases}\quad
  \A\alpha_+(t)\triangleq
  \begin{cases}
    \A\alpha_1(t) & t\in\Time_1 \\
    \A\alpha_2(t) & t\in\Time_2
  \end{cases}\quad
  \A\tick_+(\A{t})\triangleq
  \begin{cases}
    \A\tick_1(\A{t}) & \A{t}\in\A\Time_1 \\
    \A\tick_2(\A{t}) & \A{t}\in\A\Time_2
  \end{cases}
\]
it is easy to check that all requirements are satisfied.

\subsection{Concrete Linking}
Now we define injection between $s_1=(C_1,\mem_1,t_1)\in\State_1$ and $r_2=(V_2,\mem_2,t_2)\in\Result_2$:
\[
  \begin{array}{cc}
    \inject{C_{1}}{V_{2}}\triangleq
    \begin{cases}
      C_1                                           & V_{2}=[]                            \\
      (x, t)\cons\inject{C_{1}}{C}                  & V_{2}=(x,t)\cons C                  \\
      (M, \inject{C_{1}}{C})\cons\inject{C_{1}}{C'} & V_{2}=(M,C)\cons C'                 \\
      \langle\lambda x.e,\inject{C_1}{C_2}\rangle   & V_{2}=\langle\lambda x.e,C_2\rangle
    \end{cases} &
    \begin{array}{l}
      \inject{C_1}{\mem_2}\triangleq
      \displaystyle\bigcup_{t\in\mathsf{dom}(\mem_2)}[t\mapsto\inject{C_1}{\mem_2(t)}] \\ \\
      \inject{s_1}{r_2}\triangleq
      (\inject{C_1}{V_2},\mem_1\cup\inject{C_1}{\mem_2},t_2)
    \end{array}
  \end{array}
\]

As is expected, injecting $s_1$ into $r_2$ involves injecting $C_1$ in every context in $r_2$ and merging the memories.
This definition is exactly what we were searching for, since it respects all requirements laid out in the introduction to this section.
First, $\inject{s_1}{r_2}\in\Result_+$ with respect to the ordering $\le_+$.
Also, if we define $\inject{s_1}{\ell_2}$ when $\ell_2=(e,s_2)$ by $(e,\inject{s_1}{s_2})$, we can show that injection preserves valid transitions. That is,
\begin{lem}[Injection Preserves Evaluation]
  For all $s_1\in\State_1$, $\ell_2\in\Left_2$ and $\rho_2\in\Right_2$,
  if $\ell_2\semarrow\rho_2$ under $\tick_2$, then $\inject{s_1}{\ell_2}\semarrow\inject{s_1}{\rho_2}$ under $\tick_+$.
\end{lem}
\begin{proof}[Sketch]
  Induction on $\semarrow$ under $\tick_2$.
\end{proof}

Thus we can define $\rhd$ and $\semlink$ that satisfies the desired property.
\begin{defn}[Injection]
  For $S_1\subseteq\State_1$ and $A_2\in D_2$, define:
  \[
    S_1\rhd A_2\triangleq\{\inject{s_1}{\rho_2}|s_1\in S_1,\rho_2\in A_2\}\cup\{\inject{s_1}{\ell_2}\semarrow\inject{s_1}{\rho_2}|s_1\in S_1,\ell_2\semarrow\rho_2\in A_2\}
  \]
\end{defn}
\begin{defn}[Semantic Linking]
  For $S_1\subseteq\State_1$ and $A_2\in D_2$, define:
  \[
    S_1\semlink A_2\triangleq\lfp(\lambda X.\Step(X)\cup(S_1\rhd A_2))
  \]
\end{defn}
\begin{thm}[Advance]
  For all $e\in\Expr$ and $S_1\subseteq\State_1$, $S_2\subseteq\State_2$,
  \[
    \sembracket{e}(S_1\rhd S_2)=S_1\semlink\sembracket{e}S_2
  \]
\end{thm}
\subsection{Abstract Linking}
We can define injection and linking in the abstract semantics in the same way as the concrete semantics.
Only the definition of $\inject{\A{C}_1}{\A\mem_2}$ has to be adapted to account for the fact that $\A\mem_2(\A{t})$ is now a \emph{set} of closures.
This means that $\inject{\A{C}_1}{\A\mem_2}$ must be defined as:
\[\inject{\A{C}_1}{\A\mem_2}\triangleq\lambda\A{t}.\{\inject{\A{C}_1}{\A{v}_2}|\A{v}_2\in\A\mem_2(\A{t})\}\]
Then we can show that:
\begin{lem}[Injection Preserves Abstract Evaluation]
  For all $\A{s}_1\in\A\State_1$, $\A\ell_2\in\A\Left_2$ and $\A\rho_2\in\A\Right_2$, if $\A\ell_2\A\semarrow\A\rho_2$ under $\A\tick_2$,
  then $\inject{\A{s}_1}{\A\ell_2}\A\semarrow\inject{\A{s}_1}{\A\rho_2}$ under $\A\tick_+$.
\end{lem}
\begin{proof}[Sketch]
  Induction on $\A\semarrow$ under $\A\tick_2$.
\end{proof}
and thus we can define:
\begin{defn}[Abstract Injection]
  For $\Abs{S}_1\subseteq\A\State_1$ and $\Abs{A}_2\in\Abs{D}_2$, define:
  \[
    \Abs{S}_1\Abs\rhd\Abs{A}_2\triangleq\{\inject{\A{s}_1}{\A\rho_2}|\A{s}_1\in\Abs{S}_1,\A\rho_2\in\Abs{A}_2\}\cup\{\inject{\A{s}_1}{\A\ell_2}\A\semarrow\inject{\A{s}_1}{\A\rho_2}|\A{s}_1\in\Abs{S}_1,\A\ell_2\A\semarrow\A\rho_2\in\Abs{A}_2\}
  \]
\end{defn}
\begin{defn}[Abstract Linking]
  For $\Abs{S}_1\subseteq\A\State_1$ and $\Abs{A}_2\in\Abs{D}_2$, define:
  \[
    \Abs{S}_1\Abs\semlink\Abs{A}_2\triangleq\lfp(\lambda\Abs{X}.\Abs\Step(\Abs{X})\cup(\Abs{S}_1\Abs\rhd\Abs{A}_2))
  \]
\end{defn}
so that the \emph{best possible result} is achieved:
\begin{thm}[Abstract Advance]
  For all $e\in\Expr$ and $\Abs{S}_1\subseteq\A\State_1$, $\Abs{S}_2\subseteq\A\State_2$,
  \[
    \Abs{\sembracket{e}}(\Abs{S}_1\Abs\rhd\Abs{S}_2)=\Abs{S}_1\Abs\semlink\Abs{\sembracket{e}}\Abs{S}_2
  \]
\end{thm}
Since we have that
\[
  \alpha_+(S_1\rhd A_2)=\alpha_1(S_1)\Abs\rhd\alpha_2(A_2)
\]
due to $\alpha_+(\inject{s_1}{r_2})=\inject{\alpha_1(s_1)}{\alpha(r_2)}$, the above theorem directly leads to overapproximation by:
\begin{align*}
  S_1\semlink\sembracket{e}S_2 & =\sembracket{e}(S_1\rhd S_2)                                          & (\because\text{Advance})                                           \\
                               & \subseteq\gamma_+(\Abs{\sembracket{e}}\alpha_+(S_1\rhd S_2))          & (\because\text{Galois connection})                                 \\
                               & =\gamma_+(\Abs{\sembracket{e}}(\alpha_1(S_1)\Abs\rhd\alpha_2(S_2)))   & (\because\alpha_+(S_1\rhd A_2)=\alpha_1(S_1)\Abs\rhd\alpha_2(A_2)) \\
                               & =\gamma_+(\alpha_1(S_1)\Abs\semlink\Abs{\sembracket{e}}\alpha_2(S_2)) & (\because\text{Abstract advance})
\end{align*}
\section{Equivalence Between Initial States}
\subsection{Motivation}
Assume that we have a cached analysis result of a program fragment $e$ under an abstract state $\A{s}$ that uses timestamps in $\{0,1\}$.
We want to analyze $e$ under another initial state $\A{s'}$ that uses abstract timestamps in $\{a,b\}$.
The problem is: what is the criteria for reusing the cached analysis results?

Based on the previous section, we want to find a $s''$ that satisfies $\inject{\A{s''}}{\A{s}}=\A{s'}$, so that linking $\A{s''}$ into the cached results result in the semantics that started from $\A{s'}$.
However, equality is not possible because the timestamps that are used are different.
Thus, in this section, we define what it means for semantics that use different timestamps to be \emph{equivalent}.
The definition of equivalence need to satisfy two desired properties, namely:
\begin{enumerate}
  \item If $\A{s}$ and $\A{s'}$ are equivalent, all $s\in\gamma(\{\A{s}\})\Rightarrow$ must have an equivalent $s'\in\gamma'(\{\A{s'}\})$.
  \item If $s$ and $s'$ are equivalent, $(e,s)$ and $(e,s')$ must step to equivalent states.
\end{enumerate}
These two properties ensure that if we find a $\A{s''}$ such that $\inject{\A{s''}}{\A{s}}$ is \emph{equivalent} to $\A{s'}$, linking $\A{s''}$ with the cached results will result in an overapproximation of something \emph{equivalent} to the semantics that started from $\gamma'(\{\A{s'}\})$.

\subsection{Definitions}
In this section, we assume a pair of semantics using $(\Time,\le,\ATime,\A\alpha)$ and $(\Time',\le',\ATime',\A\alpha')$.

We first define what it means for two states $s\in\State$ and $s'\in\State'$ to be equivalent.
Recall that $s=(C,\mem,t)$ and $s'=(C',\mem',t')$ for some contexts $C,C'$, some memories $\mem,\mem'$, and some times $t,t'$.
The choice of $t$ and $t'$ is ``not special'' in the sense that as long as they are more recent than the contexts and memories, $\tick$ will continue producing fresh addresses.
Thus, the notion of equivalence is defined by how $C$ and $\mem$ components ``look the same''.

Note that information in $C$ and $\mem$ is only accessed through a sequence of names $x$ and $M$.
Thus, one may imagine access ``paths'' with names on the edges and reachable timestamps on the vertices as representing the way that $(C,\mem)$ is \emph{viewed}.
Also, given a $\varphi\in\Time\rightarrow\Time'$, we can define how access paths that use timestamps in $\Time$ are translated to access paths in $\Time'$.
%The definitions are given in Figure \ref{fig:accpath}.
\begin{center}
  %\centering
  \begin{tabular}{rclcrrcl}
    $p$ & $\rightarrow$ & $\epsilon$                   & empty path     & $\qquad$ & $\varphi(\epsilon)$                   & \hspace{-2em} & $\triangleq\epsilon$                              \\
        & $|$           & $\xrightarrow{x}t\:p$        & address access & $\qquad$ & $\varphi(\xrightarrow{x}t\:p)$        & \hspace{-2em} & $\triangleq\xrightarrow{x}\varphi(t)\:\varphi(p)$ \\
        & $|$           & $\xrightarrow{M}p$           & module access  & $\qquad$ & $\varphi(\xrightarrow{M}p)$           & \hspace{-2em} & $\triangleq\xrightarrow{M}\varphi(p)$             \\
        & $|$           & $\xrightarrow{\lambda x.e}p$ & value access   & $\qquad$ & $\varphi(\xrightarrow{\lambda x.e}p)$ & \hspace{-2em} & $\triangleq\xrightarrow{\lambda x.e}\varphi(p)$
  \end{tabular}
  %\caption{Definition for access paths and how translation of timestamps are mapped over access paths.}
  %\label{fig:accpath}
\end{center}

From now on, we shall write $\Path$ for the set of access paths that use timestamps in $\Time$, and $\Path'$ for the set of access paths that use timestamps in $\Time'$.
Then given an access path, we can define a predicate $\valid\in(\Ctx\uplus\Time)\times\Mem\times\Path\rightarrow\mathsf{Prop}$.
$\valid(r,\mem,p)$ is true iff starting from $r$, all accesses edges in $p$ are valid.
Likewise, we can define a predicate $\A\valid\in(\A\Ctx\uplus\A\Time)\times\A\Mem\times\A\Path\rightarrow\mathsf{Prop}$.
$\A\valid(\A{r},\A\mem,\A{p})$ is true iff starting from $\A{r}$, all access edges in $\A{p}$ are valid.
%\vspace{-1em}
\begin{figure}[h!]
  \centering
  \begin{minipage}{0.4\linewidth}
    \scriptsize
    \begin{align*}
      \valid(\_,\mem,\epsilon)                  & \triangleq\mathsf{True}                                                        \\
      \valid(C,\mem,\xrightarrow{x}t\:p)        & \triangleq t=C(x)\wedge\valid(t,\mem,p)                                        \\
      \valid(C,\mem,\xrightarrow{M}p)           & \triangleq\valid(C(M),\mem,p)                                                  \\
      \valid(t,\mem,\xrightarrow{\lambda x.e}p) & \triangleq\langle\lambda x.e,\prexists{C}\rangle=\mem(t)\wedge\valid(C,\mem,p) \\
      \valid(\text{otherwise})                  & \triangleq\mathsf{False}
    \end{align*}
  \end{minipage}
  \begin{minipage}{0.4\linewidth}
    \scriptsize
    \begin{align*}
      \A\valid(\_,\A\mem,\epsilon)                          & \triangleq\mathsf{True}                                                                                \\
      \A\valid(\A{C},\A\mem,\xrightarrow{x}\A{t}\:\A{p})    & \triangleq\A{t}=\A{C}(x)\wedge\A\valid(\A{t},\A\mem,\A{p})                                             \\
      \A\valid(\A{C},\A\mem,\xrightarrow{M}\A{p})           & \triangleq\A\valid(\A{C}(M),\A\mem,\A{p})                                                              \\
      \A\valid(\A{t},\A\mem,\xrightarrow{\lambda x.e}\A{p}) & \triangleq\langle\lambda x.e,\prexists{\A{C}}\rangle\in\A\mem(\A{t})\wedge\A\valid(\A{C},\A\mem,\A{p}) \\
      \A\valid(\text{otherwise})                            & \triangleq\mathsf{False}
    \end{align*}
  \end{minipage}
  \caption{Definitions for the $\valid$ and $\A\valid$ predicates.}
  \label{fig:valid}
  \vspace{-1em}
\end{figure}

Now we can give straightforward definitions of equivalence.
\begin{defn}[Equivalent Concrete States]
  Let $s=(C,\mem,\_)\in\State$ and $s'=(C',\mem',\_)\in\State'$.
  We say $s$ is \emph{equivalent} to $s'$ and write $s\equivalent s'$ when there exists a $\varphi:\Time\rightarrow\Time'$ and $\varphi':\Time'\rightarrow\Time$ such that:
  \begin{enumerate}
    \item $\forall p\in\Path:$ if $\valid(C,\mem,p)$ then $\valid(C',\mem',\varphi(p))$ and $p=\varphi'(\varphi(p))$.
    \item $\forall p'\in\Path':$ if $\valid(C',\mem',p')$ then $\valid(C,\mem,\varphi'(p'))$ and $p'=\varphi(\varphi'(p'))$.
  \end{enumerate}
\end{defn}
\begin{defn}[Weakly Equivalent Abstract States]\label{def:weakequiv}
  Let $\A{s}=(\A{C},\A\mem,\_)\in\AState$ and $\A{s}'=(\A{C}',\A\mem',\_)\in\AState'$.
  We say $\A{s}$ is \emph{weakly equivalent} to $\A{s}'$ when there exists a $\A\varphi:\ATime\rightarrow\ATime'$ and $\A\varphi':\ATime'\rightarrow\ATime$ such that:
  \begin{enumerate}
    \item $\forall\A{p}\in\A\Path:$ if $\A\valid(\A{C},\A\mem,\A{p})$ then $\A\valid(\A{C'},\A{\mem'},\A\varphi(\A{p}))$ and $\A{p}=\A\varphi'(\A\varphi(\A{p}))$.
    \item $\forall\A{p'}\in\A{\Path'}:$ if $\A\valid(\A{C'},\A{\mem'},\A{p'})$ then $\valid(\A{C},\A{\mem},\A\varphi'(\A{p'}))$ and $\A{p'}=\A\varphi(\A\varphi'(\A{p'}))$.
  \end{enumerate}
\end{defn}
The reason that the above definition is called ``weak equivalence'' is because it is not sufficient to guarantee equivalence after concretization.
Consider
\[
  [(x,0)],\{0\mapsto\{\langle\lambda z.z,[(x,1)]\rangle,\langle\lambda z.z,[(y,2)]\rangle\},1\mapsto\{\langle\lambda z.z,[]\rangle\}\}
\]
and
\[
  [(x,0)],\{0\mapsto\{\langle\lambda z.z,[(x,1);(y,2)]\rangle\},1\mapsto\{\langle\lambda z.z,[]\rangle\}\}
\]
They are weakly equivalent, yet their concretizations are not equivalent.
Thus, we need to strengthen the definition for abstract equivalence.

Before going into the definition, we introduce some terminology.
First, we say that two states are \emph{weakly equivalent by} $\A\varphi,\A\varphi'$ when $\A\varphi,\A\varphi'$ are the functions that translate between abstract timestamps in Definition \ref{def:weakequiv}.
Second, we say that $\A{t}$ is \emph{reachable from} $\A{s}$ when there is some valid access path $\A{p}$ from $\A{s}$ containing $\A{t}$.
Now we actually give the definition:
\begin{defn}[Equivalent Abstract States]
  Let $\A{s}=(\_,\A\mem,\_)\in\AState$ and $\A{s}'=(\_,\A\mem',\_)\in\AState'$.
  We say $\A{s}$ is \emph{equivalent} to $\A{s}'$ and write $\A{s}\A\equivalent\A{s'}$ when there exists a $\A\varphi:\ATime\rightarrow\ATime'$ and $\A\varphi':\ATime'\rightarrow\ATime$ such that:
  \begin{enumerate}
    \item $\A{s}$ and $\A{s'}$ are weakly equivalent by $\A\varphi,\A\varphi'$.
    \item For each $\A{t}$ reachable from $\A{s}$, if $\langle\lambda x.e,\A{C}\rangle\in\A\mem(\A{t})$, there exists a $\A{C'}$ such that $\langle\lambda x.e,\A{C'}\rangle\in\A\mem'(\A\varphi(\A{t}))$ and $\A{C}$, $\A{C'}$ are weakly equivalent by $\A\varphi,\A\varphi'$ under the empty memory.
    \item The same holds for each $\A{t'}$ reachable from $\A{s'}$.
  \end{enumerate}
\end{defn}

We extend the definition of equivalence between elements of $\Sigma$ and $\Sigma'$:
\begin{align*}
  (\langle\lambda x.e,C\rangle,\mem,t)\equivalent(\langle\lambda x.e,C'\rangle,\mem',t')                       & \triangleq(C,\mem,t)\equivalent(C',\mem',t')                       \\
  (e,s)\equivalent(e,s')                                                                                       & \triangleq s\equivalent s'                                         \\
  (\langle\lambda x.e,\A{C}\rangle,\A\mem,\A{t})\A\equivalent(\langle\lambda x.e,\A{C}'\rangle,\A\mem',\A{t}') & \triangleq(\A{C},\A\mem,\A{t})\A\equivalent(\A{C}',\A\mem',\A{t}') \\
  (e,\A{s})\A\equivalent(e,\A{s}')                                                                             & \triangleq\A{s}\A\equivalent\A{s}
\end{align*}
Then we can extend the definition of equivalence between the elements of $D$ and $D'$:
\begin{align*}
  A\equivalent A'\triangleq                 & (\forall\ell\semarrow\rho,\rho\in A:\exists\ell'\semarrow\rho',\rho'\in A':\ell\equivalent\ell'\land\rho\equivalent\rho')\land                                       \\
                                            & (\forall\ell'\semarrow\rho',\rho'\in A':\exists\ell\semarrow\rho,\rho\in A:\ell\equivalent\ell'\land\rho\equivalent\rho')                                            \\
  \Abs{A}\Abs\equivalent \Abs{A'}\triangleq & (\forall\A\ell\A\semarrow\A\rho,\A\rho\in\Abs{A}:\exists\A\ell'\A\semarrow\A\rho',\A\rho'\in\Abs{A'}:\A\ell\A\equivalent\A\ell'\land\A\rho\A\equivalent\A\rho')\land \\
                                            & (\forall\A\ell'\A\semarrow\A\rho',\A\rho'\in\Abs{A'}:\exists\A\ell\A\semarrow\A\rho,\A\rho\in\Abs{A}:\A\ell\A\equivalent\A\ell'\land\A\rho\A\equivalent\A\rho')
\end{align*}
\subsection{Propeties of Equivalence}
We first note that the relations $\equivalent$ and $\A\equivalent$ are actually equivalence relations.
That is, they are reflexive, transitive, and commutative.
We must also show that equivalence is well-behaved under the step relation and concretization.
That is, we must show that concretizing equivalent abstract states lead to equivalent states, and that equivalence preserves the step relation.
\begin{lem}[Concretization Preserves Equivalence]\label{lem:concreteqiuv}
  Assume that each $\A{t},\A{t'}$ in $\ATime,\ATime'$ corresponds to an infinite set of concrete timestamps.
  Then for all $\Abs{S}\subseteq\AState$ and $\Abs{S'}\subseteq\AState'$,
  \[\Abs{S}\Abs\equivalent\Abs{S'}\Rightarrow\gamma(\Abs{S})\equivalent\gamma'(\Abs{S'})\]
\end{lem}
\begin{proof}[Sketch]
  We want to prove:
  \[\forall s\in\State,\A{s}'\in\AState':\A\alpha(s)\A\equivalent\A{s}'\Rightarrow\exists s'\in\State':s\equivalent s'\land\A\alpha'(s')=\A{s}'\]
  If this is true, $\forall s\in\gamma(\Abs{S}):\exists s'\in\gamma(\Abs{S'}):s\equivalent s'$.
  Similarly, we have $\forall s'\in\gamma(\Abs{S'}):\exists s\in\gamma(\Abs{S}):s\equivalent s'$, so that $\gamma(\Abs{S})\equivalent\gamma'(\Abs{S'})$.

  This is proven in Coq (\texttt{ConcretEquivalence.v}).
\end{proof}
\begin{lem}[Evaluation Preserves Equivalence]
  For all $\ell\in\Left$, $\rho\in\Right$, $\ell'\in\Left'$,
  \[\ell\semarrow\rho\text{ and }\ell\equivalent\ell'\Rightarrow\exists\rho':\ell'\semarrow\rho'\text{ and }\rho\equivalent\rho'\]
  Thus, if $S\subseteq\State$ and $S'\subseteq\State'$ are equivalent, $\sembracket{e}S\equivalent\sembracket{e}S'$.
\end{lem}
\begin{proof}[Sketch]
  This is proven in Coq (\texttt{OperationalEquivalence.v}).
\end{proof}
Note that there is a caveat in Lemma \ref{lem:concreteqiuv}.
We have required that all partitions $\A\alpha^{-1}(\A{t})$ of $\Time$ to be infinite.
This is natural, since if an abstract address that concretizes to a finite set corresponds to an abstract address that concretizes to an infinite set, the concretization might no longer be equivalent.
This constraint is not as restrictive as it seems, as widely used abstractions such as \emph{k}-CFA already satisfy this criterion.

\subsection{How to Utilize Equivalence}
Here is a general outline that utilize abstract equivalence and abstract linking to overapproximate any initial state.
The goal is to overapproximate something equivalent to $\sembracket{e}\gamma(\Abs{S})$, when all abstract timestamps in $\Abs{S}$ correspond to infinitely many concrete timestamps.
\begin{description}
  \item[Step 1] Choose a finite set $\A\Time_2$ and a function $\A\tick_2\in\A\Time_2\rightarrow\A\Time_2$.
  \item[Step 2] Assume an initial condition $\Abs{S}_2$ and compute $\Abs{\sembracket{e}}\Abs{S}_2$.
  \item[Step 3] Choose a finite set $\A\Time_1$ and $\A\tick_1\in\A\Time_1\rightarrow\A\Time_1$.
  \item[Step 4] Find a $\Abs{S}_1$ such that $\Abs{S}_1\Abs\rhd\Abs{S}_2$ is equivalent to some \emph{superset} $\ovbar{\Abs{S}}$ of $\Abs{S}$.
  \item[Result] Then $\Abs{S}_1\Abs\semlink\Abs{\sembracket{e}}\Abs{S}_2$ overapproximates an equivalent superset of $\sembracket{e}\gamma(\Abs{S})$.
\end{description}
$\Abs{S}_1\Abs\semlink\Abs{\sembracket{e}}\Abs{S}_2$ overapproximates an equivalent superset of $\sembracket{e}\gamma(\Abs{S})$, since if we let:
\[\Time_+\triangleq(\ATime_1+\ATime_2)\times\mathbb{Z}\quad\tick_+(\A{t},n)\triangleq(\A\tick_+(\A{t}),n+1)\quad\A\alpha_+(\A{t},n)\triangleq\A{t}\]
we have a concrete time $\Time_+$ that is connected to $\ATime_1+\ATime_2$ by $\A\alpha_+$ such that all abstract timestamps correspond to infinitely many concrete timestamps.
Thus:
\begin{align*}
  \sembracket{e}\gamma(\Abs{S}) & \subseteq\sembracket{e}\gamma(\ovbar{\Abs{S}})                      & (\because\Abs{S}\subseteq\ovbar{\Abs{S}}\text{ and }\gamma\text{ monotonic}) \\
                                & \equivalent\sembracket{e}\gamma_+(\Abs{S}_1\Abs\rhd\Abs{S}_2)       & (\because\gamma,\semarrow\text{ preserves equivalence})                      \\
                                & \subseteq\gamma_+(\Abs{\sembracket{e}}(\Abs{S}_1\Abs\rhd\Abs{S}_2)) & (\because\text{Soundness})                                                   \\
                                & =\gamma_+(\Abs{S}_1\Abs\semlink\Abs{\sembracket{e}}\Abs{S}_2)       & (\because\text{Abstract advance})
\end{align*}
%\begin{center}
%  \begin{tabular}{ccc}
%    \begin{minipage}{0.3\linewidth}
%      \begin{lstlisting}[language=Coq]
%(* Module F, case 1 *)
%let f g n = 
%  if n <= 0 then 0 
%  else g n
%%
%    \end{lstlisting}
%    \end{minipage} &
%    \begin{minipage}{0.3\linewidth}
%      \begin{lstlisting}[language=Coq]
%(* Module F, case 2 *)
%let f g n = 
%  if n <= 0 then 0 
%  else g (n - 1)
%%
%    \end{lstlisting}
%    \end{minipage} &
%    \begin{minipage}{0.3\linewidth}
%      \begin{lstlisting}[language=Coq]
%(* Client code *)
%Include F
%let fix g n =
%  n + f g (n - 1)
%let ret = g 3
%    \end{lstlisting}
%    \end{minipage}
%  \end{tabular}
%\end{center}
%Above, we have a piece of code that uses higher-order functions to parametrize the behavior of \texttt{g} over the implementation of \texttt{f}.
%In the first case, \texttt{g n} computes the sum from $0$ to $n$.
%In the second case, \texttt{g n} computes the sum of numbers with parity equal to the parity of $n$ in the range $[0,n]$.

%\begin{figure}[h!]
%  \centering
%  \begin{tabular}{rrr}
%    \multicolumn{1}{l}{Given an initial $(C_i,\mem_i)$:}                                                                                                                                                                                                                                     \\
%    \hline
%    $(e_1,\prexists[blue]{s_1})\semarrow\preall[orange]{r_1}\in\sembracket{e_1}S_1$        & $(e_2,\prexists[blue]{s_2})\semarrow\preall[orange]{r_2}\in\sembracket{e_2}S_2$ & $(e_\lambda,\prexists[blue]{s_\lambda})\semarrow\preall[orange]{r_\lambda}\in\sembracket{e_\lambda}S_\lambda$ \\
%    $(C_1,\mem_1)=\inject{\prexists[blue]{o_1}}{s_1}$                                      & $(C_2,\mem_{\lambda,2})=\inject{\prexists[blue]{o_2}}{s_2}$                     & $(C_\lambda,\mem_{a,\lambda})=\inject{\prexists[blue]{o_\lambda}}{s_\lambda}$                                 \\
%    $(\langle\lambda x.e_\lambda,C_{\lambda,1}\rangle,\mem_{\lambda,1})=\inject{o_1}{r_1}$ & $(v_a,\mem_{a,2})=\inject{o_2}{r_2}$                                            & $(v,\mem)=\inject{o_\lambda}{r_\lambda}$                                                                      \\
%    \\
%    \multicolumn{1}{l}{Such that:}                                                                                                                                                                                                                                                           \\
%    \hline
%    $(C_i,\mem_i)\equivalent[red](C_1,\mem_1)$                                             & $(C_1,\mem_{\lambda,1})$                                                        & \multicolumn{1}{l}{\hspace{\equivadjust}$\equivalent[red](C_2,\mem_{\lambda,2})$}                             \\
%                                                                                           & $(C_{\lambda,1},\mem_{\lambda,1})$                                              & \multicolumn{1}{l}{\hspace{\equivadjust}$\equivalent[red](\prexists[blue]{C_{\lambda,2}},\mem_{\lambda,2})$}  \\
%                                                                                           & $((x,\prexists[blue]{t})::C_{\lambda,2},\mem_{a,2}[t\mapsto v_a])$              & \multicolumn{1}{l}{\hspace{\equivadjust}$\equivalent[red](C_\lambda,\mem_{a,\lambda})$}
%  \end{tabular}
%  \caption{How the application $e_1\:e_2$ can be analyzed by composing pre-analyzed results. The table should be read column by column. $((e,\prexists{s})\semarrow\preall{r}\in A)P(s,r)$ means $(\exists s)(\forall r)((e,s)\semarrow r\in A\Rightarrow P(s,r))$}
%\end{figure}
\bibliographystyle{ACM-Reference-Format}
\bibliography{citations}
\end{document}
%%% Local Variables: 
%%% coding: utf-8
%%% mode: latex
%%% TeX-engine: xetex
%%% End:
