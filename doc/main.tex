%! TEX program = xelatex
\documentclass[acmsmall,review]{acmart}\settopmatter{printfolios=true,printccs=false,printacmref=false}

%%% Typesetting for listings
\usepackage{listings}
\setmonofont{JuliaMono}[Scale=MatchLowercase]

\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{ltblue}{rgb}{0,0.4,0.4}
\definecolor{dkviolet}{rgb}{0.3,0,0.5}

%%% lstlisting coq style (inspired from a file of Assia Mahboubi)
\lstdefinelanguage{Coq}{ 
    % Anything betweeen $ becomes LaTeX math mode
    mathescape=true,
    % Comments may or not include Latex commands
    texcl=false, 
    % Vernacular commands
    morekeywords=[1]{Section, Module, End, Require, Import, Export,
        Variable, Variables, Parameter, Parameters, Axiom, Hypothesis,
        Hypotheses, Notation, Local, Tactic, Reserved, Scope, Open, Close,
        Bind, Delimit, Definition, Let, Ltac, Fixpoint, CoFixpoint, Add,
        Morphism, Relation, Implicit, Arguments, Unset, Contextual,
        Strict, Prenex, Implicits, Inductive, CoInductive, Record,
        Structure, Canonical, Coercion, Context, Class, Global, Instance,
        Program, Infix, Theorem, Lemma, Corollary, Proposition, Fact,
        Remark, Example, Proof, Goal, Save, Qed, Defined, Hint, Resolve,
        Rewrite, View, Search, Show, Print, Printing, All, Eval, Check,
        Projections, inside, outside, Def},
    % Gallina
    morekeywords=[2]{forall, exists, exists2, fun, fix, cofix, struct,
        match, with, end, as, in, return, let, if, is, then, else, for, of,
        nosimpl, when},
    % Sorts
    morekeywords=[3]{Type, Prop, Set, true, false, option},
    % Various tactics, some are std Coq subsumed by ssr, for the manual purpose
    morekeywords=[4]{pose, set, move, case, elim, apply, clear, hnf,
        intro, intros, generalize, rename, pattern, after, destruct,
        induction, using, refine, inversion, injection, rewrite, congr,
        unlock, compute, ring, field, fourier, replace, fold, unfold,
        change, cutrewrite, simpl, have, suff, wlog, suffices, without,
        loss, nat_norm, assert, cut, trivial, revert, bool_congr, nat_congr,
        symmetry, transitivity, auto, split, left, right, autorewrite},
    % Terminators
    morekeywords=[5]{by, done, exact, reflexivity, tauto, romega, omega,
        assumption, solve, contradiction, discriminate},
    % Control
    morekeywords=[6]{do, last, first, try, idtac, repeat},
    % Comments delimiters, we do turn this off for the manual
    morecomment=[s]{(*}{*)},
    % Spaces are not displayed as a special character
    showstringspaces=false,
    % String delimiters
    morestring=[b]",
    morestring=[d],
    % Size of tabulations
    tabsize=3,
    % Enables ASCII chars 128 to 255
    extendedchars=false,
    % Case sensitivity
    sensitive=true,
    % Automatic breaking of long lines
    breaklines=false,
    % Default style fors listings
    basicstyle=\small,
    % Position of captions is bottom
    captionpos=b,
    % flexible columns
    columns=[l]flexible,
    % Style for (listings') identifiers
    identifierstyle={\ttfamily\color{black}},
    % Style for declaration keywords
    keywordstyle=[1]{\ttfamily\color{dkviolet}},
    % Style for gallina keywords
    keywordstyle=[2]{\ttfamily\color{dkgreen}},
    % Style for sorts keywords
    keywordstyle=[3]{\ttfamily\color{ltblue}},
    % Style for tactics keywords
    keywordstyle=[4]{\ttfamily\color{dkblue}},
    % Style for terminators keywords
    keywordstyle=[5]{\ttfamily\color{dkred}},
    %Style for iterators
    %keywordstyle=[6]{\ttfamily\color{dkpink}},
    % Style for strings
    stringstyle=\ttfamily,
    % Style for comments
    commentstyle={\ttfamily\color{dkgreen}},
    %moredelim=**[is][\ttfamily\color{red}]{/&}{&/},
    literate=
    {\\forall}{{\color{dkgreen}{$\forall\;$}}}1
    {\\exists}{{$\exists\;$}}1
    {<-}{{$\leftarrow\;$}}1
    {=>}{{$\Rightarrow\;$}}1
    {==}{{\code{==}\;}}1
    {==>}{{\code{==>}\;}}1
    %    {:>}{{\code{:>}\;}}1
    {->}{{$\rightarrow\;$}}1
    {<->}{{$\leftrightarrow\;$}}1
    {<==}{{$\leq\;$}}1
    {\#}{{$^\star$}}1 
    {\\o}{{$\circ\;$}}1 
    {\@}{{$\cdot$}}1 
    {\/\\}{{$\wedge\;$}}1
    {\\\/}{{$\vee\;$}}1
    {++}{{\code{++}}}1
    {~}{{\ }}1
    {\@\@}{{$@$}}1
    {\\mapsto}{{$\mapsto\;$}}1
    {\\hline}{{\rule{\linewidth}{0.5pt}}}1
    %
}[keywords,comments,strings]

%%% Citation style
\citestyle{acmauthoryear}

%%% Math settings
\usepackage{amsthm,mathtools}
\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]
\newtheorem{example}{Example}[section]
\newtheorem{lem}{Lemma}[section]
\newtheorem{thm}{Theorem}[section]
\newtheorem{cor}{Corollary}[section]

%%% PL constructs
\usepackage{galois}
\usepackage{ebproof}
\ebproofset{left label template=\textsc{[\inserttext]}}
\ebproofset{center=false}

%%% Custom commands
\newcommand*{\vbar}{|}
\newcommand*{\finto}{\xrightarrow{\text{\textrm{fin}}}}
\newcommand*{\istype}{\mathrel{â©´}}
\newcommand*{\ortype}{\mathrel{|}}
\newcommand*{\cons}{::}

\def\ovbarw{1.2mu}
\def\ovbarh{1}
\newcommand*{\ovbar}[1]{\mkern \ovbarw\overline{\mkern-\ovbarw{\smash{#1}\scalebox{1}[\ovbarh]{\vphantom{i}}}\mkern-\ovbarw}\mkern \ovbarw}
\newcommand*{\A}[1]{{#1}^{\#}}
\newcommand*{\Expr}{\text{Expr}}
\newcommand*{\ExprVar}{\text{Var}}
\newcommand*{\Module}{\text{Module}}
\newcommand*{\ModVar}{\text{ModVar}}
\newcommand*{\Time}{\mathbb{T}}
\newcommand*{\ATime}{\A{\Time}}
\newcommand*{\Ctx}{\text{Ctx}}
\newcommand*{\Value}{\text{Val}}
\newcommand*{\Mem}{\text{Mem}}
\newcommand*{\Left}{\text{L}}
\newcommand*{\Right}{\text{R}}
\newcommand*{\mem}{m}
\newcommand*{\AMem}{\A{\text{Mem}}}
\newcommand*{\State}{\text{State}}
\newcommand*{\AState}{\A{\text{State}}}
\newcommand*{\Result}{\text{Result}}
\newcommand*{\AResult}{\A{\text{Result}}}
\newcommand*{\Tick}{\text{Tick}}
\newcommand*{\semarrow}{\rightsquigarrow}
\newcommand*{\semlink}{\mathbin{\rotatebox[origin=c]{180}{$\propto$}}}
\newcommand*{\link}[2]{{#1}\semlink{#2}}
\newcommand*{\mt}{\mathsf{empty}}

\newcommand*{\doubleplus}{\ensuremath{\mathbin{+\mkern-3mu+}}}
\newcommand*{\project}{\text{\texttt{:>} }}
\newcommand*{\Exp}{\mathsf{Exp}}
\newcommand*{\Imp}{\mathsf{Imp}}
\newcommand*{\Fin}{\mathsf{Fin}}
\newcommand*{\Link}{\mathsf{Link}}
\newcommand*{\sembracket}[1]{\lBrack{#1}\rBrack}
\newcommand*{\fin}[2]{{#1}\xrightarrow{\text{fin}}{#2}}
\newcommand*{\addr}{\mathsf{addr}}
\newcommand*{\tick}{\mathsf{tick}}
\newcommand*{\modctx}{\mathsf{ctx}}
\newcommand*{\mapinject}[2]{{#2}[{#1}]}
\newcommand*{\inject}[2]{{#2}\langle{#1}\rangle}
\newcommand*{\deletepre}[2]{{#2}\overline{\doubleplus}{#1}}
\newcommand*{\deletemap}[2]{{#1}\overline{[{#2}]}}
\newcommand*{\delete}[2]{{#2}{\langle{#1}\rangle}^{-1}}
\newcommand*{\filter}{\mathsf{filter}}
\newcommand*{\Let}{\mathtt{let}}

\title{A Syntax-Guided Framework for Modular Analysis}
\author{Joonhyup Lee}
\begin{document}
\maketitle

\section{Abstract Syntax}

In this section we define the abstract syntax for a simple language that captures the essence of modules and linking.
The language is basically an extension of untyped lambda calculus with modules and the linking construct.

\begin{figure}[htb]
  \centering
  \footnotesize
  \begin{tabular}{rrcll}
    Identifiers & $x,M$ & $\in$         & $\ExprVar$                              \\
    Expression  & $e$   & $\rightarrow$ & $x$                & value identifier   \\
                &       & $\vbar$       & $\lambda x.e$      & function           \\
                &       & $\vbar$       & $e$ $e$            & application        \\
                &       & $\vbar$       & $\link{e}{e}$      & linked expression  \\
                &       & $\vbar$       & $\varepsilon$      & empty module       \\
                &       & $\vbar$       & $M$                & module identifier  \\
                &       & $\vbar$       & $\Let$ $x$ $e$ $e$ & binding expression \\
                &       & $\vbar$       & $\Let$ $M$ $e$ $e$ & binding module     \\
  \end{tabular}
  \caption{Abstract syntax of the simple module language.}
\end{figure}
\subsection{Rationale for the design of the simple language}

There are no recursive modules, first-class modules, or functors in the simple language that is defined.
Also, note that the nonterminals for the modules and expressions are not separated. Why is this so?

The rationale for the exclusion of recursive modules/first-class modules/functors is because we want to enforce static scoping.
That is, we need to be able to statically determine where variables were bound when using them.
To enforce static scoping when function applications might return modules, we need to employ signatures to project the dynamically computed modules onto a statically known context.
Concretely, we need to define signatures $S$ where $\lambda M\project S.e$ statically resolves the context when $M$ is used in the body $e$, and $(e_1\:e_2)\project S$ enforces that a dynamic computation is resolved into one static form.
To simplify the presentation, we first consider the case that does not require signatures.

The rationale for not separating modules and expressions in the syntax is because we want to utilize the linking construct to link both modules to expressions and modules to modules.
That is, we want expressions to be parsed as $\link{(\link{m_1}{m_2})}{e}$.
$\link{m_1}{m_2}$ links a module with a module, and $\link{(\link{m_1}{m_2})}{e}$ links a module with an expression.
Why this is convenient will be clear when we explain separate analysis; we want to link modules with modules as well as expressions.

\section{Concrete Semantics}

In this section, we present the dynamics of the simple language presented in the previous section.

\subsection{Structural Operational Semantics}

First, we give the operational semantics for the dynamic execution of the module language.
The one-step transition relation $\semarrow$ will relate a configuration(expression and state) either to (1) another configuration of which its results are used for the evaluation of the first configuration, or to (2) the final result.

Prior to defining this relation, the semantic domains must be set up.
As is common in defining dynamics for call-by-value lambda calculus, one must define \emph{environments} to record what values were bound to variables.
For the ease of program analysis, this environment is divided again into (1) a context $C$ that binds variables in scope to the \emph{time} those variables were bound, and (2) a memory $\mem$ which records which values were bound at what time.

The representation of the context $C$ is a stack that records variables \emph{in the order} they were bound.
In the spirit of de Bruijn, to access the value of a variable $x$, one has to read off the closest binding time from $C$ and consult the memory to determine what value was bound at that time.
In contrast, to access the exported context from a variable $M$, one has to look up the exported context from $C$, not from the memory.

This separation between where we store modules and where we store closures emphasizes the fact that \emph{where} the variables are bound is guided by syntax.
The only thing that is dynamic is \emph{when} the variables are bound, which is represented by the time component.

Now, we start by defining what we mean by \emph{time} and \emph{context}, which is the essence of our model.

\subsubsection{Time and Context}

We first define sets that are parametrized by our choice of the time domain, namely the \emph{value}, \emph{memory}, and \emph{context} domains.
Also, we present the notational conventions used in this paper to represent members of each domain.

\begin{figure}[htb]
  \centering
  \footnotesize
  \begin{tabular}{rrcll}
    Time                         & $t$     & $\in$         & $\Time$                                                                                                       \\
    Environment/Context          & $C$     & $\in$         & $\Ctx(\Time)$                                                                                                 \\
    Value of expressions         & $v$     & $\in$         & $\Value(\Time) \triangleq \Expr\times\Ctx(\Time)$                                                             \\
    Value of expressions/modules & $V$     & $\in$         & $\Value(\Time)\uplus\Ctx(\Time)$                                                                              \\
    Memory                       & $\mem$  & $\in$         & $\Mem(\Time) \triangleq \fin{\Time}{\Value(\Time)}$                                                           \\
    State                        & $s$     & $\in$         & $\State(\Time) \triangleq \Ctx(\Time)\times\Mem(\Time)\times\Time$                                            \\
    Result                       & $r$     & $\in$         & $\Result(\Time) \triangleq (\Value(\Time)\uplus\Ctx(\Time))\times\Mem(\Time)\times\Time$                      \\
    Tick                         & $\tick$ & $\in$         & $\Tick(\Time)\triangleq(\State(\Time)\times\ExprVar\times\Value(\Time))\rightarrow\Time$                      \\
    Context                      & $C$     & $\rightarrow$ & []                                                                                       & empty stack        \\
                                 &         & $\vbar$       & $(x,t)\cons C$                                                                           & expression binding \\
                                 &         & $\vbar$       & $(M,C)\cons C$                                                                           & module binding     \\
    Value of expressions         & $v$     & $\rightarrow$ & $\langle \lambda x.e, C \rangle$                                                         & closure
  \end{tabular}
  \caption{Definition of the semantic domains.}
\end{figure}

Note that $\State(\Time)\subseteq\Result(\Time)$.
This is because the results from modules are the states that they export.
Later on, when we define predicates on results, it is to be understood that their definition applies to states as well.

Also, note that we have defined a domain $\Tick(\Time)$ which is comprised of functions that receive a state, a variable, and a value and returns a timestamp.
As can be inferred from the name of the domain, a $\tick\in\Tick(\Time)$ is the policy that the designer of the analysis chooses to represent the concrete flow of the program.
The time $\tick(s,x,v)$ is the time that is incremented when the value $v$ is bound to a variable $x$ under state $s$.
Naturally, our definition of the one-step transition relation is parametrized by the choice of $\tick$.

Why does the $\tick$ function for the concrete time take in $s, x, v$?
This is a suggestion to the analysis designer.
For program analysis, the designer must think of an \emph{abstract} tick operator that \emph{simulates} its concrete counterpart.
If the concrete tick function is not able to take into account the environment that the time is incremented, the abstraction of the tick function will not be able to hold much information about the execution of the program.

Now for the auxiliary operators that is used when defining the evaluation relation.
We define the function that extracts the address for an value id $x$,
and the function that looks up the dynamic context bound to a module id $M$.
\begin{figure}[h!]
  \centering
  \footnotesize
  \[
    \addr(C,x)\triangleq
    \begin{cases}
      \bot         & C=[]                              \\
      t            & C=(x, t)\cons C'                  \\
      \addr(C',x)  & C=(x', t)\cons C' \wedge x'\neq x \\
      \addr(C'',x) & C=(M, C')\cons C''
    \end{cases}
    \quad
    \modctx(C,M)\triangleq
    \begin{cases}
      \bot           & C=[]                               \\
      C'             & C=(M, C')\cons C''                 \\
      \modctx(C'',M) & C=(M', C')\cons C''\wedge M'\neq M \\
      \modctx(C',M)  & C=(x, t)\cons C'
    \end{cases}
  \]
  \caption{Definitions for the $\addr$ and $\modctx$ operators.}
\end{figure}

\subsubsection{The Relation}
Now we define the one-step transition relation.
The relation $\semarrow_\tick$ relates $(e,C,\mem,t)\in\Expr\times\State(\Time)$ with either
$(V,\mem,t)\in\Result(\Time)$ or the next expression and state, when $\tick$ is used to increment the time.
Note that we constrain whether an expression returns $v$ or $C$ by the definition of $\semarrow_\tick$.
The complete definition for the relation is given in Fig. \ref{fig:concreach}.
Also, the equivalence of the relation with a reference interpreter is formalized in Coq.

\begin{figure}[h!]
  \begin{flushright}
    \fbox{$(e,C,\mem,t)\semarrow_\tick(V,\mem',t')\text{ or }(e',C',\mem',t')$}
  \end{flushright}
  \vspace{0pt} % -0.75em}
  \footnotesize
  \[
    \begin{prooftree}
      \hypo{t_{x}=\addr(C,x)}
      \hypo{v=\mem(t_{x})}
      \infer[left label=ExprID]2{
      (x, C, \mem, t)
      \semarrow
      (v, \mem, t)
      }
    \end{prooftree}\qquad
    \begin{prooftree}
      \infer[left label=Fn]0{
      (\lambda x.e, C, \mem, t)
      \semarrow
      (\langle\lambda x.e, C\rangle, \mem, t)
      }
    \end{prooftree}
  \]

  \[
    \begin{prooftree}
      \infer[left label={AppL}]0{
      (e_{1}\:e_{2}, C, \mem, t)
      \semarrow
      (e_{1},C, \mem,t)
      }
    \end{prooftree}\qquad
    \begin{prooftree}
      \hypo{
        \begin{matrix}
          (e_{1}, C, \mem, t)
          \semarrow
          (\langle\lambda x.e_{\lambda}, C_{\lambda}\rangle, \mem_{\lambda}, t_{\lambda})
        \end{matrix}
      }
      \infer[left label={AppR}]1{
      (e_{1}\:e_{2}, C, \mem, t)
      \semarrow
      (e_{2}, C, \mem_{\lambda}, t_{\lambda})
      }
    \end{prooftree}
  \]

  \[
    \begin{prooftree}
      \hypo{
        \begin{matrix}
          (e_{1}, C, \mem, t)
          \semarrow
          (\langle\lambda x.e_{\lambda}, C_{\lambda}\rangle, \mem_{\lambda}, t_{\lambda}) \\
          (e_{2}, C, \mem_{\lambda}, t_{\lambda})
          \semarrow
          (v, \mem_{a}, t_{a})
        \end{matrix}
      }
      \infer[left label={AppBody}]1{
      (e_{1}\:e_{2}, C, \mem, t)
      \semarrow
      (e_{\lambda}, (x, t_{a})\cons C_{\lambda}, \mem_{a}[t_{a}\mapsto v], \tick((C,\mem_{a},t_{a}),x,v))
      }
    \end{prooftree}
  \]

  \[
    \begin{prooftree}
      \hypo{
        \begin{matrix}
          (e_{1}, C, \mem, t)
          \semarrow
          (\langle\lambda x.e_{\lambda}, C_{\lambda}\rangle, \mem_{\lambda}, t_{\lambda}) \\
          (e_{2}, C, \mem_{\lambda}, t_{\lambda})
          \semarrow
          (v, \mem_{a}, t_{a})                                                            \\
          (e_{\lambda}, (x, t_{a})\cons C_{\lambda}, \mem_{a}[t_{a}\mapsto v], \tick((C,\mem_{a},t_{a}),x,v))
          \semarrow
          (v', \mem',t')
        \end{matrix}
      }
      \infer[left label={App}]1{
      (e_{1}\:e_{2}, C, \mem, t)
      \semarrow
      (v', \mem',t')
      }
    \end{prooftree}
  \]

  \[
    \begin{prooftree}
      \infer[left label=LinkL]0{
      (\link{e_{1}}{e_{2}}, C, \mem, t)
      \semarrow
      (e_{1}, C, \mem, t)
      }
    \end{prooftree}\qquad
    \begin{prooftree}
      \hypo{
        \begin{matrix}
          (e_{1}, C, \mem, t)
          \semarrow
          (C', \mem', t')
        \end{matrix}
      }
      \infer[left label=LinkR]1{
      (\link{e_{1}}{e_{2}}, C, \mem, t)
      \semarrow
      (e_{2}, C', \mem', t')
      }
    \end{prooftree}
  \]

  \[
    \begin{prooftree}
      \hypo{
        \begin{matrix}
          (e_{1}, C, \mem, t)
          \semarrow
          (C', \mem', t') \\
          (e_{2}, C', \mem', t')
          \semarrow
          (V, \mem'', t'')
        \end{matrix}
      }
      \infer[left label=Link]1{
      (\link{e_{1}}{e_{2}}, C, \mem, t)
      \semarrow
      (V, \mem'', t'')
      }
    \end{prooftree}\qquad
    \begin{prooftree}
      \infer[left label=Empty]0{
      (\varepsilon, C, \mem, t)
      \semarrow
      (C, \mem, t)
      }
    \end{prooftree}\qquad
    \begin{prooftree}
      \hypo{C'=\modctx(C,M)}
      \infer[left label=ModID]1{
      (M, C, \mem, t)
      \semarrow
      (C', \mem, t)
      }
    \end{prooftree}
  \]

  \[
    \begin{prooftree}
      \infer[left label=LetEL]0{
      (\mathtt{let}\:x\:e_1\:e_2, C, \mem, t)
      \semarrow
      (e_{1}, C, \mem, t)
      }
    \end{prooftree}
  \]

  \[
    \begin{prooftree}
      \hypo{
        \begin{matrix}
          (e_{1}, C, \mem, t)
          \semarrow
          (v, \mem', t')
        \end{matrix}
      }
      \infer[left label=LetER]1{
      (\mathtt{let}\:x\:e_1\:e_2, C, \mem, t)
      \semarrow
      (e_{2}, (x, t')\cons C, \mem'[t'\mapsto v], \tick((C,\mem',t'),x,v))
      }
    \end{prooftree}
  \]

  \[
    \begin{prooftree}
      \infer[left label=LetML]0{
      (\mathtt{let}\:M\:e_{1}\:e_{2}, C, \mem, t)
      \semarrow
      (e_{1}, C, \mem, t)
      }
    \end{prooftree}\qquad
    \begin{prooftree}
      \hypo{
        \begin{matrix}
          (e_{1}, C, \mem, t)
          \semarrow
          (C', \mem', t')
        \end{matrix}
      }
      \infer[left label=LetMR]1{
      (\mathtt{let}\:M\:e_{1}\:e_{2}, C, \mem, t)
      \semarrow
      (e_{2}, (M, C')\cons C, \mem', t')
      }
    \end{prooftree}
  \]

  \[
    \begin{prooftree}
      \hypo{
        \begin{matrix}
          (e_{1}, C, \mem, t)
          \semarrow
          (v, \mem', t') \\
          (e_{2}, (x, t')\cons C, \mem'[t'\mapsto v], \tick((C,\mem',t'),x,v))
          \semarrow
          (C', \mem'', t'')
        \end{matrix}
      }
      \infer[left label=LetE]1{
      (\mathtt{let}\:x\:e_1\:e_2, C, \mem, t)
      \semarrow
      (C', \mem'', t'')
      }
    \end{prooftree}\quad
    \begin{prooftree}
      \hypo{
        \begin{matrix}
          (e_{1}, C, \mem, t)
          \semarrow
          (C', \mem', t') \\
          (e_{2}, (M, C')\cons C, \mem', t')
          \semarrow
          (C'', \mem'', t'')
        \end{matrix}
      }
      \infer[left label=LetM]1{
      (\mathtt{let}\:M\:e_{1}\:e_{2}, C, \mem, t)
      \semarrow
      (C'', \mem'', t'')
      }
    \end{prooftree}
  \]
  \caption{The concrete one-step transition relation. The subscript $\tick$ is omitted for brevity.}
  \label{fig:concreach}
\end{figure}

Our definition of $\semarrow_\tick$ is parametrized by the choice of $\Time$, and the choice of $\tick$.
Note that without putting some constraints on the behavior of $\tick$, the semantics might not agree with what is conventionally accepted as an operational semantics for the lambda calculus, such as the CESK machine.
That is, the $\tick$ function must produce \emph{fresh} timestamps.
To ensure that $\tick$ is well-behaved, we always assume that: (1) $\tick$ produces a strictly larger timestamp, and (2) all reachable addresses are bound by the current time.
The first guarantee is formalized by:
\begin{definition}[Concrete time]
  $(\Time, \le, \tick)$ is a \emph{concrete time} when
  \begin{enumerate}
    \item $(\Time, \le)$ is a total order.
    \item $\tick\in\Tick(\Time)$ satisfies: $\forall t\in\Time:t <\tick((\_,\_,t),\_,\_)$
  \end{enumerate}
\end{definition}
and the second guarantee is formalized by:
\begin{definition}[Time-boundedness]
  All $(V,\mem,t)\in\Result(\Time)$ satisfies $V < t$ and $\mem < t$, when:
  \[
    \begin{array}{cc}
      C < t\triangleq
      \begin{cases}
        \mathsf{True}        & C=[]              \\
        t' < t\wedge C' < t  & C=(x,t')\cons C'  \\
        C' < t\wedge C'' < t & C=(M,C')\cons C''
      \end{cases}
       &
      \begin{array}{l}
        V < t\triangleq
        \begin{cases}
          C < t & V=\langle\_,C\rangle \\
          C < t & V=C
        \end{cases} \\
        \mem < t\triangleq\forall t'\in\mathsf{dom}(\mem):t'<t\wedge\mem(t') < t
      \end{array}
    \end{array}
  \]
\end{definition}

The above two definitions ensure that $\tick$ allocates fresh timestamps.
That is, it does not matter what $\tick$ you choose to instantiate $\semarrow$ as long as it satisfies our simple requirement.
Still, how do we formalize this notion, that the choice of $\tick$ is ``irrelevent'' in formulating the semantics?
We first define what it means for two results(and states) to be isomorphic, and prove that for isomorphic initial states, all reachable configurations are isomorphic, \emph{no matter what} $\tick$ is used.

\begin{definition}[Isomorphic results]
  Let $r=(V,\mem,t)\in\Result(\Time)$ and $r'=(V',\mem',t')\in\Result(\Time')$.
  We say $r$ is \emph{isomorphic} to $r'$ and write $r\cong r'$ when there exists $f:\Time\rightarrow\Time'$ and $g:\Time'\rightarrow\Time$ such that
  $f(V)=V'\wedge f\circ\mem=\mem'\circ f\wedge f(t)=t'$ and $g(V')=V\wedge g\circ\mem'=\mem\circ g\wedge g(t')=t$.
  $f(V)$ is defined by mapping $f$ over all timestamps in the context part of $V$.
\end{definition}

$f$ and $g$ in the above definition serves to translate timestamps from one time domain to another, and since the results have the same structure, the translations must be the same.
Naturally, this definition can be extended between $\ell\in\Left\triangleq\Expr\times\State(\Time)$, which is the \textbf{l}eft-hand-side of $\semarrow$, and $\rho\in\Right\triangleq\Left\cup\Result(\Time)$, which is the \textbf{r}ight-hand-side.
That is, we say that $\ell\cong\ell'$ when the expression parts are equal and the state parts are isomorphic, and
$\rho\cong\rho'$ follows directly, since $\rho\in\Left$ or $\rho\in\Result(\Time)$.
Now we state what it means for the $\tick$ function to be irrelevent.

\begin{thm}[Irrelevence of $\tick$]
  Let $s\in\State(\Time)$ and $s'\in\State(\Time')$.
  If $s\cong s'$, then:
  \[\forall\tick,\tick',e,\rho:(e,s)\semarrow_\tick\rho\Rightarrow\exists\rho':(e,s')\semarrow_{\tick'}\rho'\wedge\rho\cong\rho'\]
\end{thm}

The above theorem suggests (1) $\semarrow_\tick$ is well-defined, and (2) no matter what $\Time$ and $\tick$ we approximate in our analysis, the results will be valid in the sense that it models all concrete executions starting from an isomorphic initial state.
For example, in the common case when one would like to analyze an expression evaluated starting from $([],\varnothing,0)$, any instantiation of $\Time$ or $\tick$ will be meaningful.
Moreover, later on, when we describe concrete linking, we link two states to obtain a state \emph{isomorphic} to what is exported from an external module.
Theorem 2.1 provides the reason why such a process is acceptable in describing the semantics of a linked expression.

\subsection{Collecting Semantics}

For program analysis, we need to define a collecting semantics that captures the strongest property we want to model.
In the case of modular analysis, we need to collect \emph{all} intermediate nodes in the proof tree when trying to prove what the initial configuration evaluates to.
Consider the case when $\link{e_1}{e_2}$ is evaluated from state $s$.
Since $e_2$ has free variables that are exported by $e_1$, separately analyzing $e_2$ will result in an incomplete proof tree.
What it means to separately analyze, then link two expressions $e_1$ and $e_2$ is to (1) compute what $e_1$ will export to $e_2$, (2) partially compute the proof tree for $e_2$, and (3) inject the exported context into the partial proof to complete the execution.

What should be the \emph{type} of the collecting semantics?
The analysis must keep track of all configurations that were reached along with the results computed from the intermediate configurations, thus it must be a set that collects all those elements.
Concretely, the collecting semantics $\sembracket{e}S$ of an expression $e$ evaluated under initial conditions in $S\subseteq\State(\Time)\times\Tick(\Time)$ must be a subset of $(\Left\times\Tick(\Time)\times\Right )\cup(\Right\times\Tick(\Time))$, when $\Left$ and $\Right$ are the left and right sides of $\semarrow_\tick$ as defined in the previous subsection, and $\Tick(\Time)$ specifies what $\tick$ is used.

To define a semantics that is computable, we must formulate the collecting semantics as a least fixed point of a monotonic function that maps an element of some CPO $D$ to $D$.
In our case, $D=\wp((\Left\times\Tick(\Time)\times\Right )\cup(\Right\times\Tick(\Time)))$ as defined previously.
Defining the transfer function is straightforward from the definition of the transition relation.

\begin{definition}[Transfer function]
  Given $A\subseteq(\Left\times\Tick(\Time)\times\Right )\cup(\Right\times\Tick(\Time))$, define
  \[
    \mathsf{Step}(A)\triangleq
    \left\{\ell\semarrow_\tick\rho, (\rho,\tick)|
    \begin{prooftree}[center=true]
      \hypo{A'}\infer1{\ell\semarrow_\tick\rho}
    \end{prooftree}\wedge
    A'\subseteq A\wedge(\ell,\tick)\in A
    \right\}
  \]
\end{definition}

The $\mathsf{Step}$ function is naturally monotonic, as a ``cache'' $A$ that remembers more about the intermediate proof tree will derive more results than a cache that remembers less.
Now, because of Tarski's fixpoint theorem, we can formulate the collecting semantics in fixpoint form.
\begin{definition}[Concrete semantics]
  \[
    \sembracket{e}S\triangleq\mathsf{lfp}(\lambda X.\mathsf{Step}(X)\cup\{((e,s),\tick)|(s,\tick)\in S\})
  \]
\end{definition}
We extend $\cong$ to a relation between two caches $A\subseteq(\Left\times\Tick(\Time)\times\Right )\cup(\Right\times\Tick(\Time))$ and $A'\subseteq(\Left\times\Tick(\Time')\times\Right )\cup(\Right\times\Tick(\Time'))$ to mean that: (1) $\forall(\rho,\_)\in A:\exists(\rho',\_)\in A':\rho\cong\rho'$ and vice versa, and (2) $\forall\ell\semarrow\rho\in A:\exists\ell'\semarrow\rho'\in A':\ell\cong\ell'\wedge\rho\cong\rho'$ and vice versa.
It is clear from Theorem 2.1 that if $S\cong S'$, then $\sembracket{e}S\cong\sembracket{e}S'$.

\section{Concrete Linking}

Before we go into definitions, we would like to make our objectives clear.
Assume we want to analyze $\link{e_1}{e_2}$ under initial condition $S$.
Normally, the final results of $\link{e_1}{e_2}$ are calculated by first calculating the results for $e_1$ under $S$, which is exported to $e_2$, then calculating the results for $e_2$ under the exported states.
That is, if we write $|\sembracket{e}S|$ for the final results of $e$ under $S$, $|\sembracket{\link{e_1}{e_2}}S|=|\sembracket{e_2}|\sembracket{e_1}S||$.

Instead, what we want to do is to calculate a part of $\sembracket{e_2}|\sembracket{e_1}S|$ \emph{in advance}, then fill in the blanks later to obtain $|\sembracket{\link{e_1}{e_2}}S|$.
Since we do not know what $|\sembracket{e_1}S|$ will be, we must \emph{assume} an initial state $S_2$ for $e_2$, which must be isomorphic to a \emph{fragment} of what $e_1$ will export to $e_2$.
For example, if we assume that when $e_1$ returns, the identifier \texttt{id} is bound to $\langle\lambda x.x,[]\rangle$, $S_2$ will be something like $\{((\mathtt{id},0)\cons[],\{0\mapsto\langle\lambda x.x,[]\rangle\},1)\}$.

So we first analyze $\sembracket{e_2}S_2$.
Later on, after we have calculated $|\sembracket{e_1}S|$, we check if our assumption is \emph{guaranteed}.
That is, we check if $|\sembracket{e_1}S|\cong S_1\rhd S_2$, when $S_1\rhd S_2$ means that $|\sembracket{e_1}S|$ can be {separated} as the {injection}($\rhd$) of some $S_1$ into our assumed $S_2$.
Then, we {link}($\semlink$) the missing part $S_1$ with the separately analyzed $\sembracket{e_2}S_2$ to obtain the final result for $\link{e_1}{e_2}$.
Thus our main theorem will be:
\begin{thm}[Concrete Linking] For $S\subseteq\State(\Time)\times\Tick(\Time)$ and $S_i\subseteq\State(\Time_i)\times\Tick(\Time_i)$,
  \[
    |\sembracket{\link{e_1}{e_2}}S|\cong|S_1\semlink\sembracket{e_2}S_2|
  \]
  where $|\sembracket{e_1}S|\cong S_1\rhd S_2$.
\end{thm}

Now, to formalize the above theorem, we need to define (1) what $|\sembracket{e}S|$ is, (2) what $S_1\rhd S_2$ is, and (3) what $S_1\semlink A_2$ is.
The first definition is straightforward: $|\sembracket{e}S|\triangleq\{r|(e,\_)\semarrow r\in\sembracket{e}S\}$, and we understand $|S_1\semlink\sembracket{e}S_2|$ to be $\{r|(e,\_)\semarrow r\in S_1\semlink\sembracket{e}S_2\}$.
The definitions for the injection and (semantic) linking operators need more consideration.

\subsection{Injection and Deletion}
We want to define what it means to \emph{inject} an external $S_1\subseteq\State(\Time_1)\times\Tick(\Time_1)$ into an assumed $S_2\subseteq\State(\Time_2)\times\Tick(\Time_2)$.
Naturally, we must first define elementwise injection $\rhd$ between $(s_1,\tick_1)\in S_1$ and $(s_2,\tick_2)\in S_2$ and map this over all pairs in $S_1\times S_2$.
What properties must $(s_+,\tick_+)=(s_1,\tick_1)\rhd(s_2,\tick_2)$ satisfy?

Consider the case when we did not assume anything, that is, when $s_2=([],\varnothing,0)$.
Then first, we expect that $s_+\cong s_1$.
Second, the $\tick_+$ function under $s_+$ must preserve the transitions made by $\tick_2$ under $s_2$.
That is, if $(e,s_2)\semarrow_{\tick_2}^*(e',s_2')$, then $(s_+',\tick_+')=(s_1,\tick_1)\rhd(s_2',\tick_2)$ must satisfy
$\tick_+=\tick_+'$ and $(e,s_+)\semarrow_{\tick_+}^*(e',s_+')$, when $R^*$ means the reflexive and transitive closure of a relation $R$.
This is because we want all transitions after injecting the exported states into the semantics calculated in advance to be valid transitions.

As the first step in defining $\rhd$, we first define the injection operator for contexts, when $\inject{C_1}{C_2}$ ``fills in the blank'' in $C_2$ with $C_1$.
The deletion operator $\delete{C_1}{C_2}$, which ``digs out'' $C_1$ from $C_2$, is also defined.
Why it is defined might not so be obvious here, but it is necessary to guarantee the second property we expect of $\rhd$.
\begin{figure}[h!]
  \footnotesize
  \[
    \inject{C_{1}}{C_{2}}\triangleq
    \begin{cases}
      C_1                                             & C_{2}=[]              \\
      (x, t)\cons\inject{C_{1}}{C'}                   & C_{2}=(x,t)\cons C'   \\
      (M, \inject{C_{1}}{C'})\cons\inject{C_{1}}{C''} & C_{2}=(M,C')\cons C''
    \end{cases}
    \delete{C_{1}}{C_{2}}\triangleq
    \begin{cases}
      []                                              & C_{2}=C_{1}\lor C_{2}=[] \\
      (x,t)\cons\delete{C_{1}}{C'}                    & C_{2}=(x,t)\cons C'      \\
      (M, \delete{C_{1}}{C'})\cons\delete{C_{1}}{C''} & C_{2}=(M, C')\cons C''
    \end{cases}
  \]
  \caption{Definition of the injection operator $\inject{C_1}{C_2}$ and the deletion operator $\delete{C_1}{C_2}$.}
  \label{fig:concinject}
\end{figure}

Note that if we inject $C_1\in\Ctx(\Time_1)$ into $C_2\in\Ctx(\Time_2)$, we obtain $\inject{C_1}{C_2}\in\Ctx(\Time_1+\Time_2)$.
Why the linked time is the separate sum of the two time domains is because we want to separate what came from outside and what was assumed.
Then naturally, we expect $\tick_+$ to increment timestamps in $\Time_1+\Time_2$ by using $\tick_1$ for timestamps in $\Time_1$, and by using $\tick_2$ for timestamps in $\Time_2$.
However, the context and memory will contain timestamps both in $\Time_1$ and $\Time_2$.
Therefore, we need to define the filter operations $C.1$ and $C.2$ which selects only timestamps from the time domain of interest.

\begin{figure}[h!]
  \footnotesize
  \[
    \begin{array}{cc}
      C.i\triangleq
      \begin{cases}
        []                  & C=[]                                    \\
        (x,t)\cons C'.i     & C=(x,t)\cons C'\wedge t\in{\Time_i}     \\
        C'.i                & C=(x,t)\cons C'\wedge t\not\in{\Time_i} \\
        (M,C'.i)\cons C''.i & C=(M, C')\cons C''
      \end{cases} &
      \begin{array}{l}
        V.i\triangleq
        \begin{cases}
          C.i                           & V=C                           \\
          \langle\lambda x.e,C.i\rangle & V=\langle\lambda x.e,C\rangle
        \end{cases} \\ \\
        \mem.i\triangleq
        \displaystyle\bigcup_{t\in\mathsf{dom}(\mem)\cap\Time_i}\{t\mapsto \mem(t).i\}
      \end{array}
    \end{array}
  \]
  \caption{Definition for the filter operations ($i=1,2$).}
  \label{fig:concfilter}
\end{figure}

Now we give the definition for $\rhd$.
\begin{definition}[Filling in the Blanks]
  Let $s_1=(C_1,\mem_1,t_1)\in\State(\Time_1)$ and $r_2=(V_2,\mem_2,t_2)\in\Result(\Time_2)$. Then we define:
  \[
    \begin{array}{cc}
      \inject{C_1}{V_2}\triangleq
      \begin{cases}
        \inject{C_1}{C_2}                           & V_2=C_2                            \\
        \langle\lambda x.e,\inject{C_1}{C_2}\rangle & V_2=\langle\lambda x.e, C_2\rangle
      \end{cases} &
      \begin{array}{l}
        \inject{C_1}{\mem_2}\triangleq
        \displaystyle\bigcup_{t\in\mathsf{dom}(\mem_2)}\{t\mapsto\inject{C_1}{\mem_2(t)}\} \\
        \inject{s_1}{r_2}\triangleq
        (\inject{C_1}{V_2},\mem_1\cup\inject{C_1}{\mem_2},t_2)
      \end{array}
    \end{array}
  \]
\end{definition}

Note that $\inject{s_1}{r_2}\in\Result(\Time_1+\Time_2)$ is time-bounded if we define the order relation on $\Time_1+\Time_2$ as $t_1<t_2$ for all $t_1\in\Time_1$ and $t_2\in\Time_2$.
Also, we define $\delete{C_1}{V_2}$ and $\delete{C_1}{\mem_2}$ analogously to injection.
Now we only have to define $\tick_+$ which preserves the separate transitions even after injection.

\begin{definition}[Injection]
  Let $(s_1,\tick_1)\in\State(\Time_1)\times\Tick(\Time_1)$ and $(r_2,\tick_2)\in\Result(\Time_2)\times\Tick(\Time_2)$.
  We define $(s_1,\tick_1)\rhd(r_2,\tick_2)\triangleq(\inject{s_1}{r_2},\tick_+)\in\Result(\Time_1+\Time_2)\times\Tick(\Time_1+\Time_2)$, when $\tick_+$ is given by:
  \[
    \tick_+((C,\mem,t),x,v)\triangleq
    \begin{cases}
      \tick_1((C.1,\mem.1,t),x,v.1)                                           & t\in\Time_1 \\
      \tick_2((\delete{C_1}{C}.2,\delete{C_1}{\mem}.2,t),x,\delete{C_1}{v}.2) & t\in\Time_2
    \end{cases}
  \]
\end{definition}

Since $\tick_+$ digs out $C_1$ from the memory and context, timestamps produced by $\tick_+$ after injection will look at only the parts before injection.
Thus, it will produce the same timestamps that were produced by $\tick_2$ under $S_2$.
This is why transitions after injection are valid as transitions under injected time.

\subsection{Semantic Linking}
\begin{figure}[h!]
  \footnotesize
  \begin{align*}
    (s_1,\tick_1)\rhd(\rho_2,\tick_2)                         & \triangleq
    \begin{cases}
      (r_+,\tick_+)     & \rho_2=r_2\wedge(r_+,\tick_+)=(s_1,\tick_1)\rhd(r_2,\tick_2)            \\
      ((e,s_+),\tick_+) & \rho_2=\ell_2=(e,s_2)\wedge(s_+,\tick_+)=(s_1,\tick_1)\rhd(s_2,\tick_2)
    \end{cases} \\
    (s_1,\tick_1)\rhd(\ell_2\semarrow_{\tick_2}\rho_2) & \triangleq
    \ell_+\semarrow_{\tick_+}\rho_+                                                      \\
                                                              & \text{ where }
    (\ell_+,\tick_+)=(s_1,\tick_1)\rhd(\ell_2,\tick_2)\wedge
    (\rho_+,\tick_+)=(s_1,\tick_1)\rhd(\rho_2,\tick_2)
  \end{align*}
  \caption{Extension of $\rhd$ to define injection into a cache.}
  \label{fig:extinject}
\end{figure}
Now we need to define the semantic linking operator $\semlink$.
More specifically, we must define $S_1\semlink A_2$, when $S_1\subseteq\State(\Time_1)\times\Tick(\Time_1)$ and $A_2\subseteq(\Left_2\times\Tick(\Time_2)\times\Right_2)\cup(\Right_2\times\Tick(\Time_2))$.
Remember that $A_2$ is the separately computed semantics, and $S_1$ is what was missing.
Thus, we must first inject all $(s_1,\tick_1)\in S_1$ into $(\rho_2,\tick_2),\ell_2\semarrow_{\tick_2}\rho_2\in A_2$.
The definition for elementwise injection into a cache is given in Fig. \ref{fig:extinject}.
Next, since we have gained new information about the external environment, we must collect more that can be gleaned from $S_1$.
Thus, the definition of semantic linking is as follows:
\begin{definition}[Semantic Linking]
  Let $S_1\subseteq\State(\Time_1)\times\Tick(\Time_1)$ and $A_2\subseteq(\Left_2\times\Tick(\Time_2)\times\Right_2)\cup(\Right_2\times\Tick(\Time_2))$.
  Then:
  \[
    S_1\semlink A_2\triangleq
    \mathsf{lfp}(\lambda X.\mathsf{Step}(X)\cup(S_1\rhd A_2))
  \]
\end{definition}

Since we defined $\rhd$ and thus $\semlink$ well, we have the following property:
\begin{lem}[Advance]
  Let $S_1\subseteq\State(\Time_1)\times\Tick(\Time_1)$ and $S_2\subseteq\State(\Time_2)\times\Tick(\Time_2)$. Then:
  \[
    \sembracket{e}(S_1\rhd S_2)=S_1\semlink\sembracket{e}S_2
  \]
\end{lem}
This means that we can compute part of $\sembracket{e}S$ in \emph{advance}, when $S$ is {separable} into $S_1\rhd S_2$, by $\sembracket{e}S_2$, then link $S_1$ later to obtain the full semantics.
Thus our main theorem follows directly: since $|\sembracket{e_1}S|\cong S_1\rhd S_2$(separability), 
\[
|\sembracket{\link{e_1}{e_2}}S|=|\sembracket{e_2}|\sembracket{e_1}S||\cong|\sembracket{e_2}(S_1\rhd S_2)|=|S_1\semlink\sembracket{e_2}S_2|
\]
when the first equality is from the definition of $|\sembracket{e}S|$, $\cong$ is due to the separability assumption and irrelevence of $\tick$, and the final equality is due to the advance lemma.

\subsection{A Simple Case}

The most obvious case in separability is when $e_2$ does not depend on what $e_1$ exports.
In this case, $S_2=\mt\triangleq\{([],\varnothing,0)\}$.
Since any $S$ is trivially separable as $S\cong S\rhd\mt\cong$, we have that $|\sembracket{e_1}S|\cong|\sembracket{e_1}S|\rhd\mt$.
Thus, we have:
\begin{cor}[A Simple Case]
  \[
    |\sembracket{\link{e_1}{e_2}}S|\cong||\sembracket{e_1}S|\semlink\sembracket{e_2}\mt|
  \]
\end{cor}

\newpage
\section{Abstract Semantics}

The abstract semantics is almost exactly the same as the concrete semantics, except for the fact that the memory domain is now a finite map from the abstract time domain to a \emph{set} of values.
Note we do not need to define the $\A{C}$, $\A{v}$, $\A{V}$ components, as they are \emph{exactly} their concrete counterparts.
They are simply $C$, $v$, $V$, parametrized by a different $\Time$.

\begin{figure}[h!]
  \centering
  \footnotesize
  \begin{tabular}{rccll}
    Abstract Time                & $\A{t}$  & $\in$ & $\ATime$                                                                                   \\
    Environment/Context          & $\A{C}$  & $\in$ & $\Ctx(\ATime)$                                                                             \\
    Value of expressions         & $\A{v}$  & $\in$ & $\Value(\ATime)$                                                                           \\
    Value of expressions/modules & $\A{V}$  & $\in$ & $\Value(\ATime)+\Ctx(\ATime)$                                                              \\
    Abstract Memory              & $\A\mem$ & $\in$ & $\AMem(\ATime) \triangleq \fin{\ATime}{\wp(\Value(\ATime))}$                               \\
    Abstract State               & $\A{s}$  & $\in$ & $\AState(\ATime) \triangleq \Ctx(\ATime)\times\Mem{\ATime}\times\ATime$                    \\
    Abstract Result              & $\A{r}$  & $\in$ & $\AResult(\ATime) \triangleq (\Value(\ATime)+\Ctx(\ATime))\times\AMem(\ATime)\times\ATime$ \\
  \end{tabular}
  \caption{Definition of the semantic domains.}
\end{figure}

First the abstract evaluation relation $\A{\semarrow}$ is defined.
Note that the update for the memory is now a weak update. That is,
\begin{definition}[Weak update]
  Given $\A{\mem}\in\AMem(\ATime)$, $\A{t}\in\ATime$, $\A{v}\in\Value(\ATime)$, define $\A{\mem}[\A{t}\A{\mapsto}\A{v}]$ as:
  \[
    \A{\mem}[\A{t}\A{\mapsto}\A{v}](\A{t'})\triangleq
    \begin{cases}
      \A{\mem}(\A{t})\cup\{\A{v}\} & (\A{t'}=\A{t})     \\
      \A{\mem}(\A{t'})             & (\text{otherwise})
    \end{cases}
  \]
\end{definition}

Also, for the abstract time, we do not enforce the existence of an ordering on the timestamps, but we do need a policy for performing the tick operation.
The abstract $\A\tick$ must simulate the $\tick$ function, so it must have the same type as $\tick$.
\begin{definition}[Abstract time]
  $(\ATime,\A{\tick})$ is an \emph{abstract time} when $\A{\tick}:\Ctx(\ATime)\rightarrow\AMem(\ATime)\rightarrow\ATime\rightarrow\ExprVar\rightarrow\Value(\ATime)\rightarrow\ATime$ is the policy for advancing the timestamp.
\end{definition}

The abstract one-step reachability relation is defined in Fig. \ref{fig:absreach}.
From this relation, we can define the abstract semantics in the same way as the concrete version.

\begin{figure}[h!]
  \begin{flushright}
    \fbox{$(e,\A{C},\A\mem,\A{t})\A\semarrow(\A{V},\A{\mem'},\A{t'})/(e',\A{C'},\A{\mem'},\A{t'})$}
  \end{flushright}
  \vspace{0pt} % -0.75em}
  \footnotesize
  \[
    \begin{prooftree}
      \hypo{\A{t}_{x}=\addr(\A{C},x)}
      \hypo{\A{v}\in\A\mem(\A{t}_{x})}
      \infer[left label=ExprID]2{
      (x, \A{C}, \A\mem, \A{t})
      \A\semarrow
      (\A{v}, \A\mem, \A{t})
      }
    \end{prooftree}\qquad
    \begin{prooftree}
      \infer[left label=Fn]0{
      (\lambda x.e, \A{C}, \A\mem, \A{t})
      \A\semarrow
      (\langle\lambda x.e, \A{C}\rangle, \A\mem, \A{t})
      }
    \end{prooftree}
  \]

  \[
    \begin{prooftree}
      \infer[left label={AppL}]0{
      (e_{1}\:e_{2}, \A{C}, \A\mem, \A{t})
      \A\semarrow
      (e_{1},\A{C}, \A\mem,\A{t})
      }
    \end{prooftree}\qquad
    \begin{prooftree}
      \hypo{
        \begin{matrix}
          (e_{1}, \A{C}, \A\mem, \A{t})
          \A\semarrow
          (\langle\lambda x.e_{\lambda}, \A{C}_{\lambda}\rangle, \A\mem_{\lambda}, \A{t}_{\lambda})
        \end{matrix}
      }
      \infer[left label={AppR}]1{
      (e_{1}\:e_{2}, \A{C}, \A\mem, \A{t})
      \A\semarrow
      (e_{2}, \A{C}, \A\mem_{\lambda}, \A{t}_{\lambda})
      }
    \end{prooftree}
  \]

  \[
    \begin{prooftree}
      \hypo{
        \begin{matrix}
          (e_{1}, \A{C}, \A\mem, \A{t})
          \A\semarrow
          (\langle\lambda x.e_{\lambda}, \A{C}_{\lambda}\rangle, \A\mem_{\lambda}, \A{t}_{\lambda}) \\
          (e_{2}, \A{C}, \A\mem_{\lambda}, \A{t}_{\lambda})
          \A\semarrow
          (v, \A\mem_{a}, \A{t}_{a})
        \end{matrix}
      }
      \infer[left label={AppBody}]1{
      (e_{1}\:e_{2}, \A{C,} \A\mem, \A{t})
      \A\semarrow
      (e_{\lambda}, (x, \A{t}_{a})\cons \A{C}_{\lambda}, \A\mem_{a}[\A{t}_{a}\A\mapsto \A{v}], \A\tick\:\A{C}\:\A\mem_{a}\:\A{t}_{a}\:x\:\A{v})
      }
    \end{prooftree}
  \]

  \[
    \begin{prooftree}
      \hypo{
        \begin{matrix}
          (e_{1}, \A{C}, \A\mem, \A{t})
          \A\semarrow
          (\langle\lambda x.e_{\lambda}, \A{C}_{\lambda}\rangle, \A\mem_{\lambda}, \A{t}_{\lambda}) \\
          (e_{2}, \A{C}, \A\mem_{\lambda}, \A{t}_{\lambda})
          \A\semarrow
          (\A{v}, \A\mem_{a}, \A{t}_{a})                                                            \\
          (e_{\lambda}, (x, \A{t}_{a})\cons \A{C}_{\lambda}, \A\mem_{a}[\A{t}_{a}\A\mapsto \A{v}], \A\tick\:\A{C}\:\A\mem_{a}\:\A{t}_{a}\:x\:\A{v})
          \A\semarrow
          (\A{v'}, \A{\mem'},\A{t'})
        \end{matrix}
      }
      \infer[left label={App}]1{
      (e_{1}\:e_{2}, \A{C}, \A\mem, \A{t})
      \A\semarrow
      (\A{v'}, \A{\mem'},\A{t'})
      }
    \end{prooftree}
  \]

  \[
    \begin{prooftree}
      \infer[left label=LinkL]0{
      (\link{e_{1}}{e_{2}}, \A{C}, \A\mem, \A{t})
      \A\semarrow
      (e_{1}, \A{C}, \A\mem, \A{t})
      }
    \end{prooftree}\qquad
    \begin{prooftree}
      \hypo{
        \begin{matrix}
          (e_{1}, \A{C}, \A\mem, \A{t})
          \A\semarrow
          (\A{C'}, \A{\mem'}, \A{t'})
        \end{matrix}
      }
      \infer[left label=LinkR]1{
      (\link{e_{1}}{e_{2}}, \A{C}, \A\mem, \A{t})
      \A\semarrow
      (e_{2}, \A{C'}, \A{\mem'}, \A{t'})
      }
    \end{prooftree}
  \]

  \[
    \begin{prooftree}
      \hypo{
        \begin{matrix}
          (e_{1}, \A{C}, \A\mem, \A{t})
          \A\semarrow
          (\A{C'}, \A{\mem'}, \A{t'}) \\
          (e_{2}, \A{C'}, \A{\mem'}, \A{t'})
          \A\semarrow
          (\A{V}, \A{\mem''}, \A{t''})
        \end{matrix}
      }
      \infer[left label=Link]1{
      (\link{e_{1}}{e_{2}}, \A{C}, \A\mem, \A{t})
      \A\semarrow
      (\A{V}, \A{\mem''}, \A{t''})
      }
    \end{prooftree}\qquad
    \begin{prooftree}
      \infer[left label=Empty]0{
      (\varepsilon, \A{C}, \A\mem, \A{t})
      \A\semarrow
      (\A{C}, \A\mem, \A{t})
      }
    \end{prooftree}
  \]

  \[
    \begin{prooftree}
      \hypo{\A{C'}=\modctx(\A{C},M)}
      \infer[left label=ModID]1{
      (M, \A{C}, \A\mem, \A{t})
      \A\semarrow
      (\A{C'}, \A\mem, \A{t})
      }
    \end{prooftree}\qquad
    \begin{prooftree}
      \infer[left label=LetEL]0{
      (\mathtt{let}\:x\:e_1\:e_2, \A{C}, \A\mem, \A{t})
      \A\semarrow
      (e_{1}, \A{C}, \A\mem, \A{t})
      }
    \end{prooftree}
  \]

  \[
    \begin{prooftree}
      \hypo{
        \begin{matrix}
          (e_{1}, \A{C}, \A\mem, \A{t})
          \A\semarrow
          (\A{v}, \A{\mem'}, \A{t'})
        \end{matrix}
      }
      \infer[left label=LetER]1{
      (\mathtt{let}\:x\:e_1\:e_2, \A{C}, \A\mem, \A{t})
      \A\semarrow
      (e_{2}, (x, \A{t'})\cons \A{C}, \A{\mem'}[\A{t'}\A\mapsto \A{v}], \A\tick\:\A{C}\:\A{\mem'}\:\A{t'}\:x\:\A{v})
      }
    \end{prooftree}
  \]

  \[
    \begin{prooftree}
      \infer[left label=LetML]0{
      (\mathtt{let}\:M\:e_{1}\:e_{2}, \A{C}, \A\mem, \A{t})
      \A\semarrow
      (e_{1}, \A{C}, \A\mem, \A{t})
      }
    \end{prooftree}\quad
    \begin{prooftree}
      \hypo{
        \begin{matrix}
          (e_{1}, \A{C}, \A\mem, \A{t})
          \A\semarrow
          (\A{C'}, \A{\mem'}, \A{t'})
        \end{matrix}
      }
      \infer[left label=LetMR]1{
      (\mathtt{let}\:M\:e_{1}\:e_{2}, \A{C}, \A\mem, \A{t})
      \A\semarrow
      (e_{2}, (M, \A{C'})\cons \A{C}, \A{\mem'}, \A{t'})
      }
    \end{prooftree}
  \]

  \[
    \begin{prooftree}
      \hypo{
        \begin{matrix}
          (e_{1}, \A{C}, \A\mem, \A{t})
          \A\semarrow
          (\A{v}, \A{\mem'}, \A{t'}) \\
          (e_{2}, (x, \A{t'})\cons \A{C}, \A{\mem'}[\A{t'}\A\mapsto \A{v}], \A\tick\:\A{C}\:\A{\mem'}\:\A{t'}\:x\:\A{v})
          \A\semarrow
          (\A{C'}, \A{\mem''}, \A{t''})
        \end{matrix}
      }
      \infer[left label=LetE]1{
      (\mathtt{let}\:x\:e_1\:e_2, \A{C}, \A\mem, \A{t})
      \A\semarrow
      (\A{C'}, \A{\mem''}, \A{t''})
      }
    \end{prooftree}
  \]

  \[
    \begin{prooftree}
      \hypo{
        \begin{matrix}
          (e_{1}, \A{C}, \A\mem, \A{t})
          \A\semarrow
          (\A{C'}, \A{\mem'}, \A{t'}) \\
          (e_{2}, (M, \A{C'})\cons \A{C}, \A{\mem'}, \A{t'})
          \A\semarrow
          (\A{C''}, \A{\mem''}, \A{t''})
        \end{matrix}
      }
      \infer[left label=LetM]1{
      (\mathtt{let}\:M\:e_{1}\:e_{2}, \A{C}, \A\mem, \A{t})
      \A\semarrow
      (\A{C''}, \A{\mem''}, \A{t''})
      }
    \end{prooftree}
  \]
  \caption{The abstract one-step reachability relation.}
  \label{fig:absreach}
\end{figure}

\begin{definition}[Transfer function]
  Given $\A{A}\subseteq (\A{L}\times \A{R})\cup\A{R}$, define
  \[
    \A{\mathsf{Step}}(\A{A})\triangleq
    \left\{\A\ell\A\semarrow\A\rho,\A\rho|
    \A{A'}\subseteq \A{A}\wedge\A{\ell}\in \A{A}\wedge
    \begin{prooftree}[center=true]
      \hypo{\A{A'}}\infer1{\A\ell\A\semarrow\A\rho}
    \end{prooftree}\right\}
  \]
\end{definition}
\begin{definition}[Abstract semantics]
  \[
    \A{\sembracket{e}}(\A{s})\triangleq\mathsf{lfp}(\lambda \A{X}.\A{\mathsf{Step}}(\A{X})\cup\{(e,\A{s})\})
  \]
\end{definition}

\section{Whole-program Analysis}
This section clarifies what we mean by that the abstract semantics is a \emph{sound approximation} of the concrete semantics.
Since the only values in our language are closures that pair code with a context, we can make a Galois connection between $\wp((L\times R)\cup R)$ and $\wp((\A{L}\times\A{R})\cup\A{R})$ given a function $\alpha:\Time\rightarrow\ATime$.

\begin{definition}[Extensions of abstraction]
  Given a function $\alpha:\Time\rightarrow\ATime$,
  \begin{itemize}
    \item Extend $\alpha$ to a function on $\Ctx(\Time)\rightarrow\Ctx(\ATime)$ by mapping $\alpha$ over all timestamps.
    \item Extend $\alpha$ to a function on $\Value(\Time)\rightarrow\Value(\ATime)$ by mapping $\alpha$ over all timestamps.
    \item Extend $\alpha$ to a function on $\Mem(\Time)\rightarrow\AMem(\ATime)$ by defining
          \[\alpha(\mem)\triangleq\bigcup_{t\in\mathsf{dom}(\mem)}[\alpha(t)\mapsto\{\alpha(\mem(t))\}]\]
    \item Extend $\alpha$ to a function on $\Result(\Time)\rightarrow\AResult(\ATime)$ by $\alpha(V,\mem,t)\triangleq(\alpha(V),\alpha(\mem),\alpha(t))$
    \item Extend $\alpha$ to a function on $L\rightarrow\A{L}$ by $\alpha(e,s)\triangleq(e,\alpha(s))$.
  \end{itemize}
\end{definition}

Then it is obvious that:
\begin{lem}[Galois connection]
  Given a function $\alpha:\Time\rightarrow\ATime$,
  \begin{itemize}
    \item Extend $\alpha$ by ${\alpha}(A)\triangleq\{\alpha(\rho)|\rho\in A\}\cup\{\alpha(\ell)\A\semarrow\alpha(\rho)|\ell\semarrow\rho\in A\}$.
    \item Define ${\gamma}$ by ${\gamma}(\A{A})\triangleq\{\rho|\alpha(\rho)\in\A{A}\}\cup\{\ell\semarrow\rho|\alpha(\ell)\A\semarrow\alpha(\rho)\in\A{A}\}$.
  \end{itemize}
  Then $\forall A\subseteq(L\times R)\cup R,\A{A}\subseteq(\A{L}\times\A{R})\cup\A{R}:{\alpha}(A)\subseteq\A{A}\Leftrightarrow A\subseteq{\gamma}(\A{A})$.
\end{lem}

The ordering between elements of $\wp((L\times R)\cup R)$ and $\wp((\A{L}\times\A{R})\cup\A{R})$ is the subset order, because currently the only thing we are abstracting is the \emph{time} component, which describes the control flow of the program.
That is, the abstract semantics can be viewed as a control flow graph of the program, with the notion of ``program points'' described by $\A\rho\in \A{R}$ and the edges described by $\A\semarrow$.
Then all we need to show is that the abstract semantics overapproximates the concrete semantics, i.e, that $\sembracket{e}(s)\subseteq\gamma(\A{\sembracket{e}}(\alpha(s)))$.
However, it is not the case that this holds for arbitrary $\alpha$.
It must be that, as emphasized constantly in the previous sections, that $\A\tick$ is a sound approximation of $\tick$ with respect to $\alpha$.

\begin{definition}[Tick-approximating abstraction]
  Given a concrete time $(\Time,\le,\tick)$ and an abstract time $(\ATime, \A\tick)$, a function $\alpha:\Time\rightarrow\ATime$ is said to be \emph{tick-approximating} if:
  \[
    \forall C,\mem,x,t,v:\alpha(\tick\:C\:\mem\:x\:t\:v)=\A\tick\:\alpha(C)\:\alpha(\mem)\:x\:\alpha(t)\:\alpha(v)
  \]
\end{definition}

Now we can prove that:
\begin{thm}[Soundness]
  Given a tick-approximating $\alpha:\Time\rightarrow\ATime$,
  \[
    \forall s\in\State(\Time):\sembracket{e}(s)\subseteq\gamma(\A{\sembracket{e}}(\alpha(s)))
  \]
\end{thm}

What's not obvious is that if the abstract time domain is finite, the analysis is guaranteed to terminate.
Since bindings for modules also exist in the stack $C$, showing that the state space given a finite $\ATime$ is finite is nontrivial.
However, since the \emph{syntax} of the program constrains how $C$ looks like, we can prove that:

\begin{thm}[Finiteness of time implies finiteness of abstraction]
  If $\ATime$ is finite,
  \[
    \forall e,\A{s}: |\A{\sembracket{e}}(\A{s})|<\infty
  \]
\end{thm}

\section{Separate Analysis}

\subsection{Addition of time domains}
For separate analysis, we need to define the linking operators in a way that soundly approximates the concrete version of linking.
Note that in concrete linking, the time domains were linked based on the fact that the timestamps are ordered by a total order.
Remember that the filtering operation determined whether the timestamp came \emph{before} or \emph{after} linking by comparing the first time component with the \emph{final} time before linking.
In the abstract semantics, such an approach is impossible, since the abstract timestamps do not preserve the order of the concrete timestamps.
Thus, in the abstract semantics, the linked timestamp must live in $\ATime_1+\ATime_2$.
The intuition is that the timestamps before linking and after linking is determined by their membership in each time domain.

Then the filtering operation for the context can naturally be defined as in Fig. \ref{fig:absfilter}, and the definition for the added time domain can be given.
\begin{figure}[h!]
  \footnotesize
  \[
    \A\filter_i(\A{C})\triangleq
    \begin{cases}
      []                                               & \A{C}=[]                                                \\
      (x,\A{t})\cons\A\filter_i(\A{C'})                & \A{C}=(x,\A{t})\cons \A{C'}\wedge \A{t}\in\A\Time_i     \\
      \A\filter_i(\A{C'})                              & \A{C}=(x,\A{t})\cons \A{C'}\wedge \A{t}\not\in\A\Time_i \\
      (M,\A\filter_i(\A{C'}))\cons\A\filter_i(\A{C''}) & \A{C}=(M, \A{C'})\cons \A{C''}
    \end{cases}
  \]
  \caption{Definition of the abstract filter operation ($i=1,2$).}
  \label{fig:absfilter}
\end{figure}

\begin{definition}[Addition of time domains]
  Let $(\ATime_1,\A\tick_1)$ and $(\ATime_2,\A\tick_2)$ be two abstract time domains.
  Given $\A{s}_1=(\A{C}_1,\A\mem_1,\A{t}_1)\in\AState{\ATime_1}$, define the $\A{\tick}_+(\A{s}_1)$ function as:
  \[
    \A\tick_{+}(\A{s}_1)(\A{C},\A\mem,\A{t},x,\A{v})\triangleq
    \begin{cases}
      \A{\tick}_1\:\A\filter_1(\A{C},\A\mem,\A{t},x,\A{v})                   & \A{t}\in\ATime_1 \\
      \A{\tick}_2\:\A\filter_2(\delete{\A{C}_1}{\A{C},\A\mem,\A{t},x,\A{v}}) & \A{t}\in\ATime_2
    \end{cases}
  \]

  Then we call the abstract time $(\ATime_1+\ATime_2,\A\tick_{+}(\A{s}_1))$ the linked time when $\A{s}_1$ is exported.
\end{definition}

Now the rest flows analogously to concrete linking.
First the injection operator that injects the exported state to the next time must be defined.

\begin{definition}[Injection of a configuration : $\A\rhd$]
  $\:$

  Given $\A{s}=(\A{C}_1,\A{\mem}_1,\A{t}_1)\in\AState{\ATime_1}$ and $\A{r}=(\A{V}_2,\A{\mem}_2,\A{t}_2)\in\AResult{\ATime_2}$,
  let $\A{s}\A\rhd \A{\mem}_2$ and $\A{s}\A\rhd \A{r}$:
  \[
    \A{s}\A\rhd\A{\mem}_2\triangleq
    \lambda \A{t}.
    \begin{cases}
      \A{\mem}_1(\A{t})                   & \A{t}\in\ATime_1 \\
      \inject{\A{C}_1}{\A{\mem}_2(\A{t})} & \A{t}\in\ATime_2
    \end{cases}
    \qquad
    \A{s}\A\rhd \A{r}\triangleq
    (\inject{\A{C}_1}{\A{V}_2},\A{s}\A\rhd \A{\mem}_2,\A{t}_2)
  \]

  Furthermore, when $\A\ell=(e,\A{s'})\in \A{L}_2$, and $\A{A}\subseteq (\A{L}_2\times \A{R}_2)\cup \A{R}_2$, we define:
  \[
    \A{s}\A\rhd\A\ell\triangleq(e,\A{s}\rhd \A{s'})\qquad
    \A{s}\A\rhd\A{A}\triangleq\{\A{s}\A\rhd\A\rho|\A\rho\in \A{A}\}\cup\{\A{s}\A\rhd\A\ell\A\semarrow \A{s}\A\rhd\A\rho|\A\ell\A\semarrow\A\rho\in \A{A}\}
  \]
\end{definition}

Then in the same manner as concrete linking, we have that:

\begin{lem}[Injection preserves timestamps under added time]
  \[
    \forall \A{s}\in\AState{\ATime_1},\A{s'}\in\AState{\ATime_2}:\A{s}\A\rhd{\A{\sembracket{e}}}(\A{s'})\subseteq\A{\sembracket{e}}(\A{s}\A\rhd\A{s'})
  \]
\end{lem}

We must also define the addition operator that recovers the semantics of the linked expression $e_2$ from the exported state $\A{s_1}$ and the \emph{separately} analyzed semantics of $e_2$.

\begin{definition}[Addition between exported configurations and separately analyzed results]
  $\:$

  Let $\A{s}_1$ be a configuration in $\ATime_1$, and let $\A{A}_2=\A{\sembracket{e}}(\A{s'})$ be the semantics of $e$ under $(\ATime_2,\A\tick_2)$.
  Define the ``addition'' between $\A{s}_1$ and $\A{A}_2$ as:
  \[
    \A{s}_1\oplus\A{A}_2\triangleq\mathsf{lfp}(\lambda\A{X}.\A{\mathsf{Step}}(\A{X})\cup(\A{s}_1\A\rhd\A{A}_2))
  \]
\end{definition}

Then because of the previous lemma, it is obvious that:
\begin{lem}[Addition of semantics equals semantics under added time]
  \[
    \A{s}\oplus\A{\sembracket{e}}(\A{s'}) = \A{\sembracket{e}}(\A{s}\A\rhd\A{s'})
  \]
\end{lem}

\subsection{Separating soundness}
The only thing that remains is the formulation of soundness between $\sembracket{\link{e_1}{e_2}}(s)$ under the linked time $(\underline{\Time_1}\uplus\underline{\Time_2},\le_+,\tick_{+}(s_1))$, when $s_1$ is the exported context, and the abstract semantics.

The tricky part is in the time $(t_1,0_2)$.
It is represented by \emph{both} $\alpha_1(t_1)\in\ATime_1$ and $\alpha_2(0_2)\in\ATime_2$, when $\alpha_1:\Time_1\rightarrow\ATime_1$ and $\alpha_2:\Time_2\rightarrow\ATime_2$ are tick-approximating.
Therefore, we cannot make a tick-approximating function between $\underline{\Time_1}\uplus\underline{\Time_2}$ and $\ATime_1+\ATime_2$.
Instead, we define a function $\alpha_+:\underline{\Time_1}\uplus\underline{\Time_2}\rightarrow\ATime_1+\ATime_2$ by using $\alpha_1$ and $\alpha_2$ which is not tick-approximating on the whole domain but is sound for all timestamps $t=(t_1,\_)$.
That is, we will define $\alpha_+$ so that the following holds:
\[
  \forall t\in\Time_2,C,\mem,x,v:\alpha_+(\tick_+\:C\:\mem\:(t_1,t)\:x\:v)=\A\tick_+\:\alpha_+(C)\:\alpha_+(\mem)\:\alpha_+(t_1,t)\:x\:\alpha_+(v)
\]

Fortunately, such an $\alpha_+$ is easy to find.
\begin{lem}[Linked abstraction]
  Let $s_1=(C_1,\mem_1,t_1)\in\State{\Time_1}$, and let $\alpha_1:\Time_1\rightarrow\ATime_1$.
  Also, let $\alpha_2:\Time_2\rightarrow\ATime_2$ be a tick-approximating abstraction.
  Now define $\alpha_+:\underline{\Time_1}\uplus\underline{\Time_2}\rightarrow\ATime_1+\ATime_2$ as:
  \[
    \alpha_+(t)\triangleq
    \begin{cases}
      \alpha_1(t.1) & t\in\underline{\Time_1} \\
      \alpha_2(t.2) & t\in\underline{\Time_2}
    \end{cases}
  \]
  Then $\alpha_+$ is tick-approximating on $\underline{\Time_2}$ between $(\underline{\Time_1}\uplus\underline{\Time_2},\le_+,\tick_+(s_1))$ and $(\ATime_1+\ATime_2,\A\tick_+(\alpha_1(s_1)))$.
\end{lem}

Since we gave up tick-approximation for the times before linking, we need to \emph{separate} the problem of finding a sound approximation of $\sembracket{e_1}(s)$ and finding a sound approximation of $\sembracket{e_2}(\Exp)$.

Finding a sound approximation of $\sembracket{e_1}(s)$ is easy.
From the results of the previous section, if we have a tick-approximating $\alpha_1$ between $\Time_1$ and $\ATime_1$, $\A{\sembracket{e_1}}(\alpha_1(s))$ is automatically a sound approximation.
The problem of finding a sound approximation for $\sembracket{e_2}(\Exp)$ is also easy if we have a sound approximation $\A\Exp$ of $\Exp$ that satisfies $\alpha_1(\Exp)\subseteq\A\Exp$.
Since $\alpha_1(s)\in\A\Exp$ for all $s\in\Exp$, if we merge $\A{s}\oplus\A{\sembracket{e_2}}(\A{0}_2)$ for all $\A{s}\in\A\Exp$, $\alpha_+(\sembracket{e_2}(\Exp))$ will be contained in the merged cache.
That is, if we write $\A{\Exp}\oplus\A{A}\triangleq\bigcup_{\A{s}\in\A\Exp}\A{s}\oplus\A{A}$, we have:
\begin{lem}[Separation of soundness]
  Given $s\in\State{\Time_1}$ and $\A\Exp\subseteq\AState{\ATime_1}$, assume:
  \begin{itemize}
    \item There exists an $\alpha_1:\Time_1\rightarrow\ATime_1$ satisfying $\alpha_1(s)\in\A{\Exp}$.
    \item There exists a time-approximating $\alpha_2:\Time_2\rightarrow\ATime_2$.
  \end{itemize}

  Then $\alpha_+(\sembracket{e_2}(s\rhd0_2))\subseteq\A\Exp\oplus\A{\sembracket{e_2}}(\A{0}_2)$.
\end{lem}

\subsection{Soundness of separate analysis}
Now, we may define the abstract linking operator that soundly approximates the concrete linking operator, using the same notation as in concrete linking.
\begin{definition}[Abstract linking operator]
  Given $e_1$, $e_2$, $\A{s}$, let $\A\Exp=\{\A{s}_1\A\rhd\A{0}_2|\A{s}_1\in\A{\underline{e_1}}(\A{s})\}$. Then:
  \[\A\Link\:e_1\:e_2\:\A{s}\triangleq\A{\sembracket{e_1}}(\A{s})\cup\A{\sembracket{e_2}}(\A\Exp)\cup(\link{e_1}{e_2},\A{s})\A\semarrow(\{(e_1,\A{s})\}\cup(e_2,\A\Exp)\cup\A{\underline{e_2}}(\A\Exp))\]
\end{definition}
Note that $\A{\sembracket{e_2}}(\A\Exp)$ can be computed by $\A{\underline{e_1}}(\A{s})\oplus\A{\sembracket{e_2}}(\A{0}_2)$, hence the analysis is separate.
Now we want to show that the abstract linking operation is a sound approximation of concrete linking.
However, as emphasized in the previous subsection, the statement of soundness cannot be achieved through just a single concretization function.
Since abstract linking approximates its concrete counterpart \emph{separately}, we need to concretize the part \emph{before} linking and \emph{after} linking separately.

\begin{thm}[Abstract linking]
  Let $\Time_i(i=1,2)$ be two concrete times, and let $\ATime_i(i=1,2)$ be two abstract times.
  Let $\alpha_i:\Time_i\rightarrow\ATime_i(i=1,2)$ be tick-approximating, and let $\A{s}=\alpha_1(s)$ approximate the initial state.
  Then, $\A\Link\:e_1\:e_2\:\A{s}$ is a sound approximation of $\Link\:e_1\:e_2\:s$.
  That is:
  \[\Link\:e_1\:e_2\:s\subseteq\gamma_1(\A{\sembracket{e_1}}(\A{s}))\cup\gamma_+(\A{\sembracket{e_2}}(\A\Exp)\cup(\link{e_1}{e_2},\A{s})\A\semarrow(\{(e_1,\A{s})\}\cup(e_2,\A\Exp)\cup\A{\underline{e_2}}(\A\Exp)))\]
  when the Galois pairs of $\alpha_1$ and $\alpha_+$, $\gamma_1$ and $\gamma_+$, are defined as in section 5.
\end{thm}

All is fine for linking two expressions.
The approximation for the exporting expression comes directly from the abstract semantics, and the approximation for the importing expression comes from linking the exporting set with the separately analyzed results.
However, the above theorem is not strong enough for linking more than two expressions.
This is because $\A\Link\:e_1\:e_2\:\A{s}$ does \emph{not} equal $\A{\sembracket{\link{e_1}{e_2}}}(\A{s})$, as $\A\tick_+$ cannot leap between $\ATime_1$ and $\ATime_2$.
Thus, $\A\Link\:\link{e_1}{e_2}\:e_3\:\A{s}$ does not mean that the semantics for $\link{e_1}{e_2}$ is computed separately.
Also, $\A\Link\:e_1\:\link{e_2}{e_3}\:\A{s}$ does not help much, since computing $\A{\sembracket{\link{e_2}{e_3}}}(\A{0})$ will be stuck before even reaching $e_3$.
To clarify on how to link an \emph{arbitrary} number of modules, we state the following theorem:
\begin{thm}[Compositionality]
  Given a sequence $\{e_n\}_{n\ge 0}$ and initial condition $s\in\State{\Time_0}$,

  \begin{itemize}
    \item Let $\ATime_n$ be abstract times connected with the concrete times by tick-approximating $\alpha_n$.
    \item Let the linked expressions $l_n$ be $l_0\triangleq e_0$, $l_{n+1}\triangleq\link{l_n}{e_{n+1}}$, and let $t_n$ be the final time of $\sembracket{l_n}(s)$.
    \item Define the linked abstraction functions $\alpha^{n}_+$ as:
          \[
            \alpha^0_+\triangleq\alpha_0
            \qquad
            \alpha^{n+1}_+(t)\triangleq
            \begin{cases}
              \alpha^n_+(t.1)   & t.1\neq t_n \\
              \alpha_{n+1}(t.2) & t.1=t_n
            \end{cases}
          \]
    \item Let $\A{s}=\alpha_0(s)$, and define $\A\Exp_n$ and $\A\Imp_n$ as:
          \[
            \A\Imp_0\triangleq\A{\sembracket{e_0}}(\A{s})\qquad
            \A\Exp_0\triangleq\{\A{s}_0\A\rhd\A{0}_1|\A{s}_0\in\A{\underline{e_0}}(\A{s})\}\qquad
            \A\Exp_{n}\triangleq\{\A{s}_n\A\rhd\A{0}_{n+1}|\A{s}_{n}\in\A{\underline{e_{n}}}(\A\Exp_{n-1})\}
          \]
          \[
            \A\Imp_{n+1}\triangleq\A{\sembracket{e_{n+1}}}(\A\Exp_n)\cup(l_{n+1},\A{s})\A\semarrow(\{(l_n,\A{s})\}\cup(e_{n+1},\A\Exp_n)\cup\A{\underline{e_{n+1}}}(\A\Exp_{n}))
          \]
  \end{itemize}

  Then:
  \[
    \sembracket{l_n}(s)\subseteq\bigcup_{i=0}^{n}{\gamma^i_+(\A\Imp_i)}
  \]
\end{thm}

What the above theorem means is that there exists a concrete $\tick$ function that can be covered separately by analyzing each component based only on the approximation of the exported context.
The fact that the analysis $\A\Imp_n$ can be computed without actually computing the final times $t_n$ is why this analysis can be called separate.
\bibliographystyle{ACM-Reference-Format}
\bibliography{citations}
\end{document}
%%% Local Variables: 
%%% coding: utf-8
%%% mode: latex
%%% TeX-engine: xetex
%%% End:
